{
  "jsonrpc": "2.0",
  "id": "8",
  "result": [
    {
      "description": "Neural style transfer implementation using Keras in python.\n\nThe procedure is applied for each table row. The input table is expected to contain \"Style\" and \"Content\" columns.",
      "name": "Style Transfer in python",
      "id": "*RaClvJ17zxcOPEQU",
      "type": "Other",
      "inPorts": [
        {
          "description": "Input data table",
          "name": "Input data table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "A column containing styled images",
          "name": "Styled images",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAcElEQVR4nGNgoDUwMDAQMDEx6TcyMmoA4gJyDFAAakwAsUGGDFIDQH6D+hHDn2gGTICqmWBsbByAbEADNjYuFyCLYWgCmrwfxAfS88kyAMbGpniYG5AAi0Zg4K2H0TDFoABFlsOIRooBUiIiCVPFcgAwM2Hob2VycwAAAABJRU5ErkJggg==",
      "description": "A Conditional Density Plot using a JavaScript based charting library. The view can be accessed either via the Interactive View action on the executed node or in the KNIME WebPortal.\r\n\r\nThe number of values in each category are counted and their histogram is plotted. The configuration lets you choose the category column (String column type) and the category column (double or integer column types). Besides the title, you can set the granularity of the x axis with the Number of Bins.",
      "name": "Conditional Density Plot",
      "id": "*SRCOr-NIvQc-cxfj",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "A table with at least one categorical column containing the categories as strings and at least one value column with numerical data of double or integer type.",
          "name": "Input Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAA3klEQVR4nL2S/Q2CQAzFGYERHOECx/+MwAhuABvIBt4GjuAIjuAIrGJ/5koewQ80xiYNba/v3fXRovilhRB2G7x8Cq7r+mreV1W1xy0+m188Nx/paZomrAhohj3GOGbCNoMGq7XUIOAi+6YFmCYOiGkmp9nPrXZUInotPujtEwDxyWpJ8sTTtQfMrIey+ys0ZxzNDdxZPizGoOBjwAypjDjPnDVYgoX55M9SDTx+KKAaYEhE2FJfoxe8IrkrbN+Qd6Hz2Ed8a/ors+K9irjJIGALWTBfro+NXcC/Av/NbnifZmUzsd9GAAAAAElFTkSuQmCC",
      "description": "This component computes the IRR (Internal Rate of Return) just like in spreadsheet tools like Microsoft Excel and Google Sheet. Adopt this component to track the profitability of one or more investment projects with periodic transactions/cash flows.\r\n\r\nThe component adopts the Java library ‘apache-poi’ version 5.2.3 (Apache license). More info available at: github.com/apache/poi\r\n\r\nDISCLAIMER: To adopt this library the component downloads on its first execution in a new workflow from dlcdn.apache.org. Make sure your KNIME has internet access when executing the component in a new workflow for the first time.\r\n\r\nThe component calculates the internal rate of return for a schedule of periodic cash flows. It starts from a series of cash flows to approximate the value of IRR for each of the defined portfolio/project that the cash flows are grouped by. Make sure that you have at least one column for the cash flows (for each portfolio/project the first transaction needs to be negative) and one column for the project/portfolio by which you want the transactions to be grouped by.\r\n\r\nMicrosoft Excel Docs: support.microsoft.com/en-us/office/irr-function-64925eaa-9988-495b-b290-3ad0c163c1bc\r\n\r\nGoogle Sheets Docs: support.google.com/docs/answer/3093231\r\n\r\nThis component, verified by KNIME, was developed by finance analytics experts at Mydral, KNIME Partner of the Year 2022: mydral.com/en/knime-uk",
      "name": "Internal Rate of Return (IRR)",
      "id": "*EqHflfbbKsmMMX37",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "A KNIME Table where each row represents a financial transaction. \r\nA column of type String is necessary to identify the financial project/portfolio. \r\nA column of type Double or Integer is necessary to identify the value of the financial transactions.",
          "name": "Investments Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "A table is returned with a column for the name of the project/portfolio and a column for the IRR value of each project.",
          "name": "IRR",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAsklEQVR4nGNgoBUwMDBwMDIyakDGIDFiNAqAFJuYmGAoBoonAPEEoBoFilwHNLyeaEMMIEABTUzA2Nh4PooA0Gn12JwN8jc2cZAYWBxoUgBQcwGQnoBiKgEDYGEFF4CGsgIooIgxAKYHOweLTegGE20AkkEGQC+uRzNgApwDDxQiAchFGOpRTMTvGlA0YqqFBmIBIc2wAMelQAFo+n5s6R4kBrKZqFQITR8omYmUMCIaAAD0RELelYkiBgAAAABJRU5ErkJggg==",
      "description": "Applies the Discrete Wavelet Transform (DWT) to selected input column with selected window sizes and steps for the selected wavelet.\r\n\r\nThe following wavelets are supported:\r\nHaar (haar)\r\nDaubechies (db)\r\nSymlets (sym)\r\nCoiflets (coif)\r\nBiorthogonal (bior)\r\nReverse biorthogonal (rbio)\r\nDiscrete FIR approximation of Meyer wavelet (dmey)\r\nGaussian wavelets (gaus)\r\nMexican hat wavelet (mexh)\r\nMorlet wavelet (morl)\r\nComplex Gaussian wavelets (cgau)\r\nShannon wavelets (shan)\r\nFrequency B-Spline wavelets (fbsp)\r\nComplex Morlet wavelets (cmor)\r\n\r\nNote: This component requires a Python environment with PyWavelets package installed.\r\n\r\nRequired extensions: \r\nKNIME Python Integration\r\n(https://hub.knime.com/knime/extensions/org.knime.features.python2/latest)\r\nKNIME Quick Forms \r\n(https://hub.knime.com/knime/extensions/org.knime.features.js.quickforms/latest)",
      "name": "Discrete Wavelet Transform (DWT)",
      "id": "*-wiE2SSEIBTxWmcn",
      "type": "Sink",
      "inPorts": [
        {
          "description": "Table containing numeric column to be transformed.",
          "name": "Data to Transform",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Result of low pass filter at each level.",
          "name": "Approximation Coeficents",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Result of high pass filter at each level.",
          "name": "Detail Coeficents",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAA3klEQVR4nL2S/Q2CQAzFGYERHOECx/+MwAhuABvIBt4GjuAIjuAIrGJ/5koewQ80xiYNba/v3fXRovilhRB2G7x8Cq7r+mreV1W1xy0+m188Nx/paZomrAhohj3GOGbCNoMGq7XUIOAi+6YFmCYOiGkmp9nPrXZUInotPujtEwDxyWpJ8sTTtQfMrIey+ys0ZxzNDdxZPizGoOBjwAypjDjPnDVYgoX55M9SDTx+KKAaYEhE2FJfoxe8IrkrbN+Qd6Hz2Ed8a/ors+K9irjJIGALWTBfro+NXcC/Av/NbnifZmUzsd9GAAAAAElFTkSuQmCC",
      "description": "This component computes the XNPV (Extended Net Present Value) just like in spreadsheet tools like Microsoft Excel and Google Sheet. Adopt this component to track the total value of one or more investment projects with non-periodic transactions/cash flows.\r\n\r\nThe metric computation is implemented using Group Loop, Column Expression and Date&Time Difference nodes.\r\n\r\nThe component calculates the net present value of an investment that is not periodic (different dates for each investment) by using a discount rate and a series of future payments (negative values) and income (positive values) defined as transactions. The calculation iterates for each of the defined portfolio/project IDs. Make sure that you have at least one Date column for the dates of the transactions, one single value column with the Interest rate, one column for the cash flows, and one column for the project/portfolio by which you want the transactions to be grouped.\r\n\r\nMicrosoft Excel Docs: support.microsoft.com/en-us/office/xnpv-function-1b42bbf6-370f-4532-a0eb-d67c16b664b7\r\n\r\nGoogle Sheets Docs: support.google.com/docs/answer/3093268\r\n\r\nThis component, verified by KNIME, was developed by finance analytics experts at Mydral, KNIME Partner of the Year 2022: mydral.com/en/knime-uk",
      "name": "Extended Net Present Value (XNPV)",
      "id": "*iCKd17Qm0OIWLfom",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "A KNIME Table where each row represents a financial transaction. \r\nA column of type String is necessary to identify the financial project/portfolio. \r\nA column of type Double or Integer is necessary to identify the value of the financial transactions.\r\nA single value column of type Double is necessary to identify the discount rate.\r\nA column of type Date to identify the date of the transaction.",
          "name": "Transactions Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "A table is returned with a column for the name of the project/portfolio and a column for the XNPV value of each project.",
          "name": "XNPV",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAf0lEQVR4nGNgGJTAwMBAgCIDjI2N5xsaGsqTbYCRkdEEIC4gSzPQ+Q4mJiYOIFeQa3sDiAYZAsLIckD+eaINAAUkjA1zGdBV6/GGDcz56IbB2FBDMcMGpAmkAFkDujdgciADQGx07+H1ErrLSAJQl00gSzMIUBSlMEBx0qYpAAAehidos81u4QAAAABJRU5ErkJggg==",
      "description": "This component flags input molecules upon their skin sensitization potential. The SMARTS encoding the potential reactive site and the domain/mechanism are based on the paper from Enoch et al. 2008 (1) and have been revised by the authors in July 2022. The new SMARTS are stored within the component. Substructure filtering and highlighting of reaction sites are based on RDKit nodes.\r\nThe expected input is data in SMILES, SDF, Mol or RDKit molecule format.\r\nThe first output port returns the input table appended with at least four additional columns: the molecule as an RDKit molecule column, a SVG column showing the highlighted potential reactive site, the alert name column and the alert domain column. In case the input molecule contains more than one potential reactive site, the latter three columns are appended for each of them. Molecules not matching any of the SMARTS patterns are returned in the lower part of the table with Alert Name 1 “Non”. \r\nThe second output port returns erroneous molecules that can’t be converted to a RDKit molecule. \r\n\r\n(1) Enoch SJ, Madden JC, Cronin MTD. Identification of mechanisms of toxic action for skin sensitisation using a SMARTS pattern based approach (2008) SAR QSAR Environ Res. 2008;19(5-6):555-78. doi: 10.1080/10629360802348985.",
      "name": "Tox Alert Skin Sensitization",
      "id": "*kfyRwavoH3A9A3vG",
      "type": "Other",
      "inPorts": [
        {
          "description": "Table containing chemical data in SMILES, SDF, Mol or RDKit format.",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Input data containing valid molecules, plus columns containing the flag(s). Three columns are appended for each alert the molecule matches. ",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Input molecules that could not be converted to a RDKit molecule. ",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAA3klEQVR4nL2S/Q2CQAzFGYERHOECx/+MwAhuABvIBt4GjuAIjuAIrGJ/5koewQ80xiYNba/v3fXRovilhRB2G7x8Cq7r+mreV1W1xy0+m188Nx/paZomrAhohj3GOGbCNoMGq7XUIOAi+6YFmCYOiGkmp9nPrXZUInotPujtEwDxyWpJ8sTTtQfMrIey+ys0ZxzNDdxZPizGoOBjwAypjDjPnDVYgoX55M9SDTx+KKAaYEhE2FJfoxe8IrkrbN+Qd6Hz2Ed8a/ors+K9irjJIGALWTBfro+NXcC/Av/NbnifZmUzsd9GAAAAAElFTkSuQmCC",
      "description": "This component creates the Excel file and writes the selected columns of the input table to the separate sheets of this file. Each sheet contains a subset of the data as defined by the categories in a selected column.",
      "name": "Categories to Excel Sheets",
      "id": "*jnDrUMnCDmnMc45y",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "The input table.",
          "name": "0",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAtUlEQVR4nK2S3Q3DIAyEM0JHYASLH4lHRsgIjJAROgIbtBt0hK4Wn2QkCwEFqSf5wST+zjo4jn/IWvtsi4geWwDdY9g59+6BdQ0BUAiB+DwvmfYAcn5xlZ47b/j9CZhpaYMqdjurs/c+LQM4TKPXlT7vABIc5VozMsE2Q4A41NByBeBbjNGgphnoAXb6cL1q32oEIAyp15iWAPLq8iSDS6AFGUiVHrgFGPzYu4UtYUhvsA2Y6QaZe2IxLfqnMAAAAABJRU5ErkJggg==",
      "description": "This Component transforms values of the columns to normalized values by using the pickled object provided at input. This Component has to be used along with the twin Component Python Transform. This Component outputs the standalone normalised values or appends them with Suffix to the original columns based on the selection in the configuration panel.    \r\n\r\nDATA INPUT REQUIREMENTS\r\n- The input data should have numerical columns that were used in the twin Component Python Transform. \r\n- The Python Pickled Object from the twin Component Python Transform.\r\n",
      "name": "Python Transform (Apply)",
      "id": "*EACR394uNrBosY-7",
      "type": "Manipulator",
      "inPorts": [
        {
          "description": "Python pickle object which can be used to normalize the columns based on the parameters used in the twin Component Python Transform. ",
          "name": "Port 0",
          "optional": false,
          "color": "#1eb9dc",
          "portTypeName": "Python"
        },
        {
          "description": "Input data with all the columns that were used in the twin Component Python Transform.",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Standalone Transformed columns or with added Suffix, as per the option selected in the Configuration panel. ",
          "name": "Port 0",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAuklEQVR4nKVT2w3DMAjMCB7BIyA//j1CRvAI3aDeoNmgHTWQYAlFAbvtSZYicxxnIMtiAACcFR8CBUpKqfwjADlnmCU7rNZGvBBCQ67XRHw/KPYiMp9nL6ImSxFMeFzvYozvqadQxbt7aibG6s8Caowttz4u/N5GAuzmvpmaAy5UDfMnaO696yLZTTeRXVRMWKWr4fgE8dh/qggnfO+LuWzXJUGBD7lgN5vg+W/cEIo1WhW8fYcD67feARH/PpXMRyZ9AAAAAElFTkSuQmCC",
      "description": "Nest this component inside another component to display a header in an interactive view. The header displays an image and title which should improve the user experience when opening the interactive view.\r\n\r\nYou can customize the colors, sizes and padding of certain elements via the component settings. Feel free however to also customize the additional CSS properties by unlinking the component and opening the CSS Editor node.\r\n\r\nThis component becomes especially useful when deployed in a data app that can be accessed remotely via any web browser. To deploy data apps you need to connect your KNIME Analytics Platform to KNIME Server, then move the workflow adopting the components from the LOCAL to the server mount point via the KNIME Explorer panel. The data app will then be accessible through KNIME WebPortal on the KNIME Server URL address.\r\n",
      "name": "Data App Header",
      "id": "*mAqVzHHv1HAnTh3L",
      "type": "Learner",
      "inPorts": [],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAf0lEQVR4nGNgGJTAwMBAgCIDjI2N5xsaGsqTbYCRkdEEIC4gSzPQ+Q4mJiYOIFeQa3sDiAYZAsLIckD+eaINAAUkjA1zGdBV6/GGDcz56IbB2FBDMcMGpAmkAFkDujdgciADQGx07+H1ErrLSAJQl00gSzMIUBSlMEBx0qYpAAAehidos81u4QAAAABJRU5ErkJggg==",
      "description": "This component takes a column containing biological sequences (DNA/RNA/Protein) and creates a one-hot encoded version of the sequences. Through the components configuration, it's possible to select a fitting alphabet as well as the way to handle characters/letters that are not in the selected alphabet. The chosen input column is either replaced or a new column is appended based on the user input during configuration. ",
      "name": "One-Hot Encoder (Biological Sequences)",
      "id": "*rmKbRI1gTMmqb4pj",
      "type": "Other",
      "inPorts": [
        {
          "description": "A table with sequences to be one-hot encoded ",
          "name": "Input table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "A table with a one-hot encoded column",
          "name": "Output table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoBYwMTFxMDIymgDEDdiwsbHxfAMDAwGcBgAVJRgaGsrjkZ8AlF+A0xBCBgBd2A/UbAB0yXqshsAMgHoFxfkgeaAmkHgCEBeAaJwGGEBAAhJGsQ3IVyBkgICFhYUCDJNsAC4vkG0ASANJBmBIoIFRA/AYAEyiAbgyEhqeAIopQhYRDQAHAltSvpTuDAAAAABJRU5ErkJggg==",
      "description": "Allows the search for life sciences and biomedical topics in PubMed, which is a free search engine developed and maintained by the National Center for Biotechnology Information (NCBI) at the National Library of Medicine (NLM)\r\n\r\nMore information can be found here:\r\nhttps://www.ncbi.nlm.nih.gov/pubmed/\r\n\r\nThe component requires the following extensions:\r\nText Processing \r\n(https://hub.knime.com/knime/extensions/org.knime.features.ext.textprocessing/latest)",
      "name": "PubMed Document Extractor",
      "id": "*D6oOvTV6dqja8CNB",
      "type": "Source",
      "inPorts": [],
      "outPorts": [
        {
          "description": "The output table which contains a document column.",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAtUlEQVR4nK2S3Q3DIAyEM0JHYASLH4lHRsgIjJAROgIbtBt0hK4Wn2QkCwEFqSf5wST+zjo4jn/IWvtsi4geWwDdY9g59+6BdQ0BUAiB+DwvmfYAcn5xlZ47b/j9CZhpaYMqdjurs/c+LQM4TKPXlT7vABIc5VozMsE2Q4A41NByBeBbjNGgphnoAXb6cL1q32oEIAyp15iWAPLq8iSDS6AFGUiVHrgFGPzYu4UtYUhvsA2Y6QaZe2IxLfqnMAAAAABJRU5ErkJggg==",
      "description": "This component inverts the signs of the values attached to given categories. You select the value column to invert the signs from, the categories with the values to be reverted, and finally the name for the newly appended column that contains the reverted values. Optionally, you can specify whether you want the result to be rounded to an integer number.",
      "name": "Invert Category Sign",
      "id": "*f6Cl-IllX9YXFN6P",
      "type": "Manipulator",
      "inPorts": [
        {
          "description": "Input data with at least a numerical and a categorical column.",
          "name": "Input data\t",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Output data with inverted values for selected categorical values.",
          "name": "Inverted data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAA3klEQVR4nL2S/Q2CQAzFGYERHOECx/+MwAhuABvIBt4GjuAIjuAIrGJ/5koewQ80xiYNba/v3fXRovilhRB2G7x8Cq7r+mreV1W1xy0+m188Nx/paZomrAhohj3GOGbCNoMGq7XUIOAi+6YFmCYOiGkmp9nPrXZUInotPujtEwDxyWpJ8sTTtQfMrIey+ys0ZxzNDdxZPizGoOBjwAypjDjPnDVYgoX55M9SDTx+KKAaYEhE2FJfoxe8IrkrbN+Qd6Hz2Ed8a/ors+K9irjJIGALWTBfro+NXcC/Av/NbnifZmUzsd9GAAAAAElFTkSuQmCC",
      "description": "Calculates one-period simple and log asset return series from asset price series.\r\n\r\nEach column selected in the configuration dialog is used to generate two new columns:\r\n* one-period simple return series\r\n* one-period log return series\r\n\r\nRequired extensions:\r\n- KNIME Expressions (https://hub.knime.com/knime/extensions/org.knime.features.expressions/latest)\r\n- KNIME Quick Forms (https://hub.knime.com/knime/extensions/org.knime.features.js.quickforms/latest)",
      "name": "Asset prices to one-period (log) returns",
      "id": "*z1shfX35em2nC7uo",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "Data table with one or more numeric columns. The column(s) selected in the configuration dialog are interpreted as price series.",
          "name": "Asset price series",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "The input data together with the (log) return series that are generated for each price series in the input.\r\n ",
          "name": "One-period simple and log return series",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAcElEQVR4nGNgoDUwMDAQMDEx6TcyMmoA4gJyDFAAakwAsUGGDFIDQH6D+hHDn2gGTICqmWBsbByAbEADNjYuFyCLYWgCmrwfxAfS88kyAMbGpniYG5AAi0Zg4K2H0TDFoABFlsOIRooBUiIiCVPFcgAwM2Hob2VycwAAAABJRU5ErkJggg==",
      "description": "This component displays a choropleth of world country vs. a numeric value such as population. You can hover over countries and see the name as well as the numeric value. The choropleth map is based on Google Charts and JQuery library\r\n\r\nWarning: Since Google Charts is loaded lazily, an internet connection is required when opening the view",
      "name": "Choropleth World Map",
      "id": "*Wc4SmCsP0c_XvWST",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "Table containing numeric value per country",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAlElEQVR4nGNgoAUwMDAQMDIyKgDiBiguAIopEKUZpNjExKQBZAi6gcbGxvmENCfgswkkh9MQoKQByAAiXJgAdKEDNokGQpqR1E6g1ABMtYPCAKLiGqQGZ2ADo2g+EbZjBiCy6UBDJoBoUOIxNDRcgJygiHIlSAMoJYL8CTRsAbKrkA0jCkCTtQNJmpBtA6VOsjSTAgCY9TAwIZkx9AAAAABJRU5ErkJggg==",
      "description": "This component can be added to a workflow to get a unique list of nodes used in the workflow and the version number of a KNIME feature containing those nodes. The results can be included to reports and data exports for documentation purposes.\r\n\r\nThe component only lists saved nodes in the workflow. In order to include recently added nodes, one should save the workflow first before executing this component. \r\n\r\n",
      "name": "Get Versions of Nodes in Workflow",
      "id": "*-kdcNyWxrybqSfAa",
      "type": "Learner",
      "inPorts": [],
      "outPorts": [
        {
          "description": "list of nodes and version number of their enclosing features.\r\n",
          "name": "Nodes",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAlElEQVR4nGNgoAUwMDAQMDIyKgDiBiguAIopEKUZpNjExKQBZAi6gcbGxvmENCfgswkkh9MQoKQByAAiXJgAdKEDNokGQpqR1E6g1ABMtYPCAKLiGqQGZ2ADo2g+EbZjBiCy6UBDJoBoUOIxNDRcgJygiHIlSAMoJYL8CTRsAbKrkA0jCkCTtQNJmpBtA6VOsjSTAgCY9TAwIZkx9AAAAABJRU5ErkJggg==",
      "description": "This component determines the best number of clusters (k) for k-Means according to the mean silhouette coefficient. \r\nThe component uses the Parameter Optimization Loop which retrains k-Means with a different k at each iteration.\r\nIn the dialog, select the columns used for k-Means, set the range of tested k's by choosing a start value, the maximum number of iterations and the step size taken at each iteration.\r\nThe data gets shuffled using the configured seed before passing it to k-Means to prevent bad initialization of the cluster centers in case the data is ordered.\r\nThe clustering algorithm uses the Euclidean distance on the selected attributes. The data is not normalized by the node (if required, you should consider to use the \"Normalizer\" as a preprocessing step).",
      "name": "Optimized K-Means (Silhouette Coefficient)",
      "id": "*UFxXVe9D4qWTa-WD",
      "type": "Learner",
      "inPorts": [
        {
          "description": "Table containing the data to be clustered.",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Table containing the different k-values and the mean silhoutte coefficient sorted according the best silhouette coefficient.",
          "name": "All parameters",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "The input data labeled with the cluster they are contained in. Output from k-Means for best k.",
          "name": "Labeled input",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "The created clusters from k-Means with best k.",
          "name": "Clusters",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "PMML cluster model from k-Means with best k.",
          "name": "PMML cluster model",
          "optional": false,
          "color": "#1469af",
          "portTypeName": "PMML"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAcElEQVR4nGNgoDUwMDAQMDEx6TcyMmoA4gJyDFAAakwAsUGGDFIDQH6D+hHDn2gGTICqmWBsbByAbEADNjYuFyCLYWgCmrwfxAfS88kyAMbGpniYG5AAi0Zg4K2H0TDFoABFlsOIRooBUiIiCVPFcgAwM2Hob2VycwAAAABJRU5ErkJggg==",
      "description": "This Component automatically visualizes data in a dashboard based on the most interesting statistical properties of the input columns.  A detailed explanation is available for each chart inside the dashboard. No configuration is necessary in order to automatically create the dashboard via the Component Composite View.\r\n\r\nThe Component runs a various statistical tests on the input data. Candidate columns are ranked for each visualization. The columns with highest rank are, when possible, visualized in a chart dedicated to precise statistical test.\r\n\r\nStatistical tests used:\r\n\r\n- Skewness, Kurtosis and Spikeyness tests of numerical column distribution\r\n- Correlation test between numerical columns\r\n- Correlation test between categorical columns\r\n- Correlation test between numerical and encoded categorical columns\r\n- Correlation test between categorical and encoded numerical columns\r\n- ANOVA test (between categorical and numerical)\r\n\r\nAt the bottom of the dashboard you can also select the columns to be removed from the data set.",
      "name": "Automated Visualization",
      "id": "*iHkzaTAGQ2SsqW9L",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "Unexplored data to be visualized.",
          "name": "Input Data to Visualize",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Input data with only the columns that were not removed in the interactive view.",
          "name": "Output Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoBYwMTFxMDIymgDEDdiwsbHxfAMDAwGcBgAVJRgaGsrjkZ8AlF+A0xBCBgBd2A/UbAB0yXqshsAMgHoFxfkgeaAmkHgCEBeAaJwGGEBAAhJGsQ3IVyBkgICFhYUCDJNsAC4vkG0ASANJBmBIoIFRA/AYAEyiAbgyEhqeAIopQhYRDQAHAltSvpTuDAAAAABJRU5ErkJggg==",
      "description": "This component extracts the most relevant English keywords in a corpus (a collection of documents) using three specific techniques:\r\n\r\n- Topic Extraction using LDA: this technique collects a set of keywords for each different topic which clusters documents in different groups.\r\n\r\n- Term Co-Occurrence: this other technique finds pair of keywords which appear together often in different documents.\r\n\r\n- Max(TF-IDF) measure: a ranking which measures the importance of terms throughout the corpus.\r\n\r\nThis component takes as input a column of Document type (from String to Document node) and it then identifies keywords in the corpus according to the hyper-parameters defined in configuration dialogue. The collected keywords are then provided in three tables at the output, one of each of the three techniques above.\r\n\r\nThe component by default is applying basic text pre-processing (e.g. stopwords and symbols removal) based on the English language. This pre-processing can be deactivated via the dialogue and performed outside of the component when working with other or multiple languages.",
      "name": "Keyword Search",
      "id": "*zKhB_pzgidXN703Z",
      "type": "Source",
      "inPorts": [
        {
          "description": "This component requires input of text columns in String format.",
          "name": "String input of Columns",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Output of nouns, adjectives and verbs along with weights defined by LDA in a olumn.",
          "name": "LDA Terms",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Output of nouns, adjectives and verbs along with counts of terms occurring in corpus.",
          "name": "Term Co-Occurrence count",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Table output of terms with highest TF-IDF between all documents.",
          "name": "TF-IDF",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAtUlEQVR4nK2S3Q3DIAyEM0JHYASLH4lHRsgIjJAROgIbtBt0hK4Wn2QkCwEFqSf5wST+zjo4jn/IWvtsi4geWwDdY9g59+6BdQ0BUAiB+DwvmfYAcn5xlZ47b/j9CZhpaYMqdjurs/c+LQM4TKPXlT7vABIc5VozMsE2Q4A41NByBeBbjNGgphnoAXb6cL1q32oEIAyp15iWAPLq8iSDS6AFGUiVHrgFGPzYu4UtYUhvsA2Y6QaZe2IxLfqnMAAAAABJRU5ErkJggg==",
      "description": "This Component transforms values of the user selected columns to normalized values by standardizing them across their mean values. The Component uses the Python Extension to perform the normalization with the Python Class “Standard Scaler preprocessing” in the Scikit learn library (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html). This Component outputs the normalized values along with the Python Pickled Object that contains the parameters used for normalisation.      \r\n\r\nDATA INPUT REQUIREMENTS\r\n- The input data should have numerical columns which can be transformed.\r\n",
      "name": "Python Transform",
      "id": "*BiBcaOffHPWUsRBd",
      "type": "Manipulator",
      "inPorts": [
        {
          "description": "Input Data. ",
          "name": "Port 0",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Transformed columns as per the user selection in the configuration panel.",
          "name": "Port 0",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Python Pickle Object which can be used to normalise the data, based on the normalisation parameters used in this Component.",
          "name": "Port 1",
          "optional": false,
          "color": "#1eb9dc",
          "portTypeName": "Python"
        }
      ]
    },
    {
      "name": "FileName_creation",
      "id": "*qNKuMT32RI-gVS9o",
      "type": "Other",
      "inPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#ff4b4b",
          "portTypeName": "Flow Variable"
        }
      ],
      "outPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#ff4b4b",
          "portTypeName": "Flow Variable"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAA3klEQVR4nL2S/Q2CQAzFGYERHOECx/+MwAhuABvIBt4GjuAIjuAIrGJ/5koewQ80xiYNba/v3fXRovilhRB2G7x8Cq7r+mreV1W1xy0+m188Nx/paZomrAhohj3GOGbCNoMGq7XUIOAi+6YFmCYOiGkmp9nPrXZUInotPujtEwDxyWpJ8sTTtQfMrIey+ys0ZxzNDdxZPizGoOBjwAypjDjPnDVYgoX55M9SDTx+KKAaYEhE2FJfoxe8IrkrbN+Qd6Hz2Ed8a/ors+K9irjJIGALWTBfro+NXcC/Av/NbnifZmUzsd9GAAAAAElFTkSuQmCC",
      "description": "This component computes the NPV (Net Present Value) just like in spreadsheet tools like Microsoft Excel and Google Sheet. Adopt this component to track the total value of one or more investment projects with periodic transactions/cash flows.\r\n\r\nThe metric computation is implemented using Group Loop, Math Formula and Column Expression nodes.\r\n\r\nThe component calculates the net present value of an investment by using a discount rate and a series of future payments (negative values) and income (positive values) defined as transactions. The calculation iterates for each of the defined portfolio/project IDs. Make sure that you have at least one single value column with the Interest rate, one column for the cash flows and one column for the project/portfolio by which you want the transactions to be grouped.\r\n\r\nDISCLAIMER: Similarly to when adopting the NPV() function in spreadsheet tools, the NPV component by default considers all input cash flows to be future cash flows. If you provide at the input also the current period “T_0” cash flows (usually negative), enable the check box “Current Period Transaction in Input”. When this is enabled the component outputs a second column “NPV+T_0” where the NPV on future cash flows is automatically summed to the current period cash flow.\r\n\r\nMicrosoft Excel Docs: support.microsoft.com/en-us/office/npv-function-8672cb67-2576-4d07-b67b-ac28acf2a568\r\n\r\nGoogle Sheets Docs: support.google.com/docs/answer/3093184\r\n\r\nThis component, verified by KNIME, was developed by finance analytics experts at Mydral, KNIME Partner of the Year 2022: mydral.com/en/knime-uk",
      "name": "Net Present Value (NPV)",
      "id": "*xASZNa_nEt3S9ywX",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "A KNIME Table where each row represents a financial transaction. \r\nA column of type String is necessary to identify the financial project/portfolio. \r\nA column of type Double or Integer is necessary to identify the value of the financial transactions. By the default this should be future transactions/cash flows. You can provide the first period value of each project, but you need to enable “Current Period Transaction in Input” in the configurations.\r\nA single value column of type Double is necessary to identify the discount rate.",
          "name": "Investments Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "A table is returned with a column for the name of the project/portfolio and a column for the NPV value of each project. If enabled the output additionally outputs “NPV&#43;T_0 &#39;&#39; where the project NPV is summed to its current period cash flow.",
          "name": "NPV",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAsklEQVR4nGNgoBUwMDBwMDIyakDGIDFiNAqAFJuYmGAoBoonAPEEoBoFilwHNLyeaEMMIEABTUzA2Nh4PooA0Gn12JwN8jc2cZAYWBxoUgBQcwGQnoBiKgEDYGEFF4CGsgIooIgxAKYHOweLTegGE20AkkEGQC+uRzNgApwDDxQiAchFGOpRTMTvGlA0YqqFBmIBIc2wAMelQAFo+n5s6R4kBrKZqFQITR8omYmUMCIaAAD0RELelYkiBgAAAABJRU5ErkJggg==",
      "description": "This component uses a heuristic approach to analyze the target series and fit a (S)ARIMA model for forecasting with automatically configured hyper-parameters.\n\nAn interactive view is produced to help interpret and visualize the model used and forecasts generated.\n\r\nBefore using this component verify that there are no missing values in your target series. If there are, you can impute them externally with the missing value node.\n\r\nTwo types of predictions are computed:  \r\n1. Forecast: forecast of the given time series h periods ahead.  \r\n2. In-Sample Prediction: generates prediction in the range of the training data.  \r\n\r\nIf you encoutner errors please verify that \nPreferances > KNIME > Python (labs) > Python environment configuration\nis set to bundled\r\n",
      "name": "Auto-SARIMA",
      "id": "*LIA_SzfW1EPZ9Lh_",
      "type": "Sink",
      "inPorts": [
        {
          "description": "Input table containing a column to be forecasted.",
          "name": "Input Series",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Future forecast values of target series.",
          "name": "Forecast",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Insample model prediction on input rows.",
          "name": "Insample Prediction",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Insample error metrics of output model.",
          "name": "Error Metrics",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAA3klEQVR4nL2S/Q2CQAzFGYERHOECx/+MwAhuABvIBt4GjuAIjuAIrGJ/5koewQ80xiYNba/v3fXRovilhRB2G7x8Cq7r+mreV1W1xy0+m188Nx/paZomrAhohj3GOGbCNoMGq7XUIOAi+6YFmCYOiGkmp9nPrXZUInotPujtEwDxyWpJ8sTTtQfMrIey+ys0ZxzNDdxZPizGoOBjwAypjDjPnDVYgoX55M9SDTx+KKAaYEhE2FJfoxe8IrkrbN+Qd6Hz2Ed8a/ors+K9irjJIGALWTBfro+NXcC/Av/NbnifZmUzsd9GAAAAAElFTkSuQmCC",
      "description": "This component shows the (cumulative) ARR or MRR by time and time-based cohort. Cohorts are used to group individual records by the characteristics that they share, which is their starting time in this case. Analysis of cohorts reveals trends and patterns that could not be identified from the individual records.\r\n\r\nA time-based cohort for each ID is defined based on the first time when the ID appears in the data.\r\n\r\nFour types of churn analysis are possible:\r\n1. The cumulative ARR by time and time-based cohort (stacked area chart)\r\n1. The cumulative MRR by time and time-based cohort (stacked area chart)\r\n2. The ARR in each time-based cohort over time (line plot)\r\n2. The MRR in each time-based cohort over time (line plot)\r\n\r\nRequired extensions:\r\n- KNIME Expressions \r\n(https://hub.knime.com/knime/extensions/org.knime.features.expressions/latest)\r\n- KNIME Plotly \r\n(https://hub.knime.com/knime/extensions/org.knime.features.js.plotly/latest)\r\n- KNIME Math Expression (JEP) \r\n(https://hub.knime.com/knime/extensions/org.knime.features.ext.jep/latest)\r\n- KNIME Quick Forms \r\n(https://hub.knime.com/knime/extensions/org.knime.features.js.quickforms/latest)",
      "name": "ARR and MRR by Time-based Cohort",
      "id": "*fDbxt1DTzpfGlLbk",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "- String or numeric column for the IDs of the records\r\n- Column of type Date&amp;Time for the time points of the records\r\n- Numeric column for values assigned to each time point and ID",
          "name": "Recurring values",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "If the &#34;Generate image&#34; option is enabled, the cohort chart is provided in SVG format. Otherwise the chart is only shown in the component&#39;s interactive view.",
          "name": "SVG image",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAf0lEQVR4nGNgGJTAwMBAgCIDjI2N5xsaGsqTbYCRkdEEIC4gSzPQ+Q4mJiYOIFeQa3sDiAYZAsLIckD+eaINAAUkjA1zGdBV6/GGDcz56IbB2FBDMcMGpAmkAFkDujdgciADQGx07+H1ErrLSAJQl00gSzMIUBSlMEBx0qYpAAAehidos81u4QAAAABJRU5ErkJggg==",
      "description": "This component reads DNA/RNA/Protein sequence files from a FASTA format file. The result is a three column table (ID, Sequence & SequenceLength), where individual sequence records are represented as rows.\r\n\r\nYou can read more about the FASTA file format at:\r\nhttps://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&PAGE_TYPE=BlastDocs&DOC_TYPE=BlastHelp\r\n\r\nThe component can handle multi-line FASTA entries. It can also directly read gzip compressed fasta files (.fa.gz). KNIME URLs such as \"knime://knime.workflow/../file.fasta\" are supported.\r\n\r\nThe component also has a histogram as its view, that shows the length distribution of sequences.",
      "name": "FASTA Reader",
      "id": "*1UQ-85D3jeY66HYF",
      "type": "Other",
      "inPorts": [],
      "outPorts": [
        {
          "description": "Sequence records per row",
          "name": "Sequence records",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAsklEQVR4nGNgoBUwMDBwMDIyakDGIDFiNAqAFJuYmGAoBoonAPEEoBoFilwHNLyeaEMMIEABTUzA2Nh4PooA0Gn12JwN8jc2cZAYWBxoUgBQcwGQnoBiKgEDYGEFF4CGsgIooIgxAKYHOweLTegGE20AkkEGQC+uRzNgApwDDxQiAchFGOpRTMTvGlA0YqqFBmIBIc2wAMelQAFo+n5s6R4kBrKZqFQITR8omYmUMCIaAAD0RELelYkiBgAAAABJRU5ErkJggg==",
      "description": "This component visualizes how different error metrics change as a forecast horizon grows. Use this component to better understand how far into the future your forecasting model is reliable.\r\n\r\nA line plot displays the error metrics changing over time.\r\n\r\nThe time on the x-axis is measured in forecast length. Each unit is equal to one record into the future. In fact this component only works on an equally spaced Time Series. For example, if input data is hourly, the forecast length 24 represents one day, 24 hours. If the input data is every two hours it would represent two days, 48 hours. Keep this in mind when interpreting the chart.\r\n\r\nMetrics on the y-axis displayed in the line plot are cumulative, while metrics displayed in the adjacent tile view are based on the entire input table. All metrics are exported at the output of the component by forecast length.",
      "name": "Forecast Horizon",
      "id": "*1rWOp_U7XwUn5nhR",
      "type": "Sink",
      "inPorts": [
        {
          "description": "Table with prediction and reference column. Must not contain missing values. No timestamp column is necessary but time slots in between predictions should be constant.",
          "name": "Predictions Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Table containing cumulative metrics by forecast length.",
          "name": "Metrics Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAlElEQVR4nGNgoAUwMDAQMDIyKgDiBiguAIopEKUZpNjExKQBZAi6gcbGxvmENCfgswkkh9MQoKQByAAiXJgAdKEDNokGQpqR1E6g1ABMtYPCAKLiGqQGZ2ADo2g+EbZjBiCy6UBDJoBoUOIxNDRcgJygiHIlSAMoJYL8CTRsAbKrkA0jCkCTtQNJmpBtA6VOsjSTAgCY9TAwIZkx9AAAAABJRU5ErkJggg==",
      "description": "This component can be used for the encoding layers of a U-Net for 2D data. The following layers are used: \n\n* 2D Convolution Layer\n* Dropout Layer\n* 2D Convolution Layer\n* Max Pooling 2D Layer\n\nAn input is required for:\n* Filter size for the Convolution layers, e.g. 16\n* Activation Function for the Convolution layers, e.g. ELU\n* Kernel Size for the Convolution layers, e.g. 3,3\n* Dropout Rate for the Dropout layer, e.g. 0.1\n* Random seed for the Dropout layer and for the Kernel Initializer in Convolution layers, e.g. 12345\n* Pool Size (and Strides) for the Max Pooling layer, e.g. 2,2\n\n\nThe following settings are fixed and passed to the U-Net 2D - Decoding Layer component:\n* Strides for the Convolution layers are set to 1,1\n* Padding for the Convolution layers is set to \"SAME\"\n* Kernel Initializer for the Convolution layers is set to \"He Normal\"\n\nThe corresponding U-Net 2D - Decoding Layer component can be used to create a complete U-Net.\n\nThe required extensions:\n-  KNIME Deep Learning -  Keras Integration",
      "name": "U-Net 2D - Encoding Layer",
      "id": "*VYYy0InTMj5m1CoW",
      "type": "Learner",
      "inPorts": [
        {
          "description": "Either a Keras Input Layer or a previous U-Net - Encoding Layer",
          "name": "Keras Model",
          "optional": false,
          "color": "#d00000",
          "portTypeName": "Keras Deep Learning Network"
        }
      ],
      "outPorts": [
        {
          "description": "Convoluted Keras Layers",
          "name": "Keras Model",
          "optional": false,
          "color": "#d00000",
          "portTypeName": "Keras Deep Learning Network"
        },
        {
          "description": "Convoluted and Max Pooling Keras Layers",
          "name": "Keras Model",
          "optional": false,
          "color": "#d00000",
          "portTypeName": "Keras Deep Learning Network"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAtUlEQVR4nK2S3Q3DIAyEM0JHYASLH4lHRsgIjJAROgIbtBt0hK4Wn2QkCwEFqSf5wST+zjo4jn/IWvtsi4geWwDdY9g59+6BdQ0BUAiB+DwvmfYAcn5xlZ47b/j9CZhpaYMqdjurs/c+LQM4TKPXlT7vABIc5VozMsE2Q4A41NByBeBbjNGgphnoAXb6cL1q32oEIAyp15iWAPLq8iSDS6AFGUiVHrgFGPzYu4UtYUhvsA2Y6QaZe2IxLfqnMAAAAABJRU5ErkJggg==",
      "description": "This component generates synthetic values into a nominal column based on the frequency distribution of the original nominal column. It’s also possible to generate synthetic data based on the multivariate frequency distribution of the nominal column and one or more dependency columns. The synthetic value of each row in the original data can be recognized by the row ID.\r\n\r\nIn addition, it is possible to exclude too few original examples from the data generation, and add random noise to the synthetic data.\r\n\r\nSynthetic data generation is used, for example, when the original data is confidential (anonymization) or difficult or expensive to collect.\r\n",
      "name": "Synthetic Data Generator (Nominal)",
      "id": "*SxZ9_5hr_eUGy0Gd",
      "type": "Manipulator",
      "inPorts": [
        {
          "description": "The original nominal column and possibly dependency columns",
          "name": "Original Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "The synthetic nominal column together with the original row IDs",
          "name": "Synthetic Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "The frequency distribution of the original nominal column and possibly the dependency columns",
          "name": "Statistics Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "The dependency group ID of each row ID in the original data ",
          "name": "Input Data Dependency Group Mapping",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAbUlEQVR4nGNgoCcwMTGpNzIyagDS/QYGBgIkGwDSDKUTDA0N5QeRAUD/KBgbG68HKQDRZBkAEkRWRLEBQJcEgNhQnECyAcguQRcbrgYAA20+NBrnQxUVIAViATRgF0DVLCArKeMESDaRhKliOQAZbVysPCQ3DwAAAABJRU5ErkJggg==",
      "description": "Using this component you can create a choropleth map that colors whole regions, such as countries, provinces, or states based on a numerical column.  \r\n\r\nThe component can display a world map or focus on single regions. When changing the region displayed (e.g. “Italy”) make sure to also provide the right resolution (“Italy” is a country itself so change the resolution setting to “provinces)”.  \r\n\r\nWarning: The choropleth map is based on Google Charts and JQuery library. Since Google Charts is loaded lazily, an internet connection is required when opening the view.  \r\n\r\nDisclaimer: To deploy this visualization on KNIME Server your KNIME Server admin needs to allow “google.com”, “gstatic.com”, and “googleapis.com” to serve content that violates the Content-Security-Policy (CSP). More info at: docs.knime.com/latest/server_admin_guide\r\n",
      "name": "Choropleth Map",
      "id": "*1SkeI4NbG7RelUkT",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "Should contain location information column (Country, City, State, Provinces)",
          "name": "Data table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAlElEQVR4nGNgoAUwMDAQMDIyKgDiBiguAIopEKUZpNjExKQBZAi6gcbGxvmENCfgswkkh9MQoKQByAAiXJgAdKEDNokGQpqR1E6g1ABMtYPCAKLiGqQGZ2ADo2g+EbZjBiCy6UBDJoBoUOIxNDRcgJygiHIlSAMoJYL8CTRsAbKrkA0jCkCTtQNJmpBtA6VOsjSTAgCY9TAwIZkx9AAAAABJRU5ErkJggg==",
      "description": "This component can be used for the decoding layers of a U-Net for 2D data (the corresponding encoding layers can be created using the U-Net 2D - Encoding Layer component). The following layers are used:\n\n* Transposed Convolution 2D Layer\n* Concatenate Layer\n* Convolution 2D Layer\n* Dropout Layer\n* Convolution 2D Layer\n\nThe following inputs should be passed from the U-Net 2D - Encoding Layer Component as flow variables:\n* Filter size for the Convolution layers\n* Activation Function for the Colnvolution layers\n* Kernel Size for the Convolution layers\n* Dropout Rate for the Dropout layer\n* Random seed for the Dropout layer and for the Kernel Initializer of the Convolution layers\n* Kernel size (and Strides) for the Transposed Convolution layer (correspondes to the Pool Size from the Max Pooling layer)\n* Strides for the Convolution layers\n* Padding for the Convolution layers\n* Kernel Initializer for the Convolution layers\n\nThe required extensions:\n- KNIME Deep Learning - Keras Integration",
      "name": "U-Net 2D - Decoding Layer",
      "id": "*K_xw5qTwOdv5SrnD",
      "type": "Learner",
      "inPorts": [
        {
          "description": "Convoluted Keras Layers",
          "name": "Port 1",
          "optional": false,
          "color": "#d00000",
          "portTypeName": "Keras Deep Learning Network"
        },
        {
          "description": "Convoluted and Max Pooling Keras Layers",
          "name": "Port 2",
          "optional": false,
          "color": "#d00000",
          "portTypeName": "Keras Deep Learning Network"
        }
      ],
      "outPorts": [
        {
          "description": "Encoded and Decoded U-Net ",
          "name": "Port 1",
          "optional": false,
          "color": "#d00000",
          "portTypeName": "Keras Deep Learning Network"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAf0lEQVR4nGNgGJTAwMBAgCIDjI2N5xsaGsqTbYCRkdEEIC4gSzPQ+Q4mJiYOIFeQa3sDiAYZAsLIckD+eaINAAUkjA1zGdBV6/GGDcz56IbB2FBDMcMGpAmkAFkDujdgciADQGx07+H1ErrLSAJQl00gSzMIUBSlMEBx0qYpAAAehidos81u4QAAAABJRU5ErkJggg==",
      "description": "This component implements substructure and similarity searches through ChEMBLdb using its API. More information can be found here: \r\nChEMBL webservices: https://chembl.gitbook.io/chembl-interface-documentation/web-services \t\r\nKNIME blog post: https://www.knime.com/blog/a-restful-way-to-find-and-retrieve-data \t\r\n",
      "name": "ChEMBL Structure Search",
      "id": "*17BHhkeogvzI7uNb",
      "type": "Other",
      "inPorts": [],
      "outPorts": [
        {
          "description": "Table containing identifiers, generic names, and structure of similar molecules",
          "name": "Details of similar molecules",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAsklEQVR4nGNgoBUwMDBwMDIyakDGIDFiNAqAFJuYmGAoBoonAPEEoBoFilwHNLyeaEMMIEABTUzA2Nh4PooA0Gn12JwN8jc2cZAYWBxoUgBQcwGQnoBiKgEDYGEFF4CGsgIooIgxAKYHOweLTegGE20AkkEGQC+uRzNgApwDDxQiAchFGOpRTMTvGlA0YqqFBmIBIc2wAMelQAFo+n5s6R4kBrKZqFQITR8omYmUMCIaAAD0RELelYkiBgAAAABJRU5ErkJggg==",
      "description": "This component checks whether the selected timestamp column is uniformly sampled in the selected time scale. Missing values will be inserted at skipped sampling times.\r\n\r\nRequired extensions: \r\nKNIME Quick Forms \r\n(https://hub.knime.com/knime/extensions/org.knime.features.js.quickforms/latest) \r\n\r\nTopics: IoT, Internet of Things, Signal Processing",
      "name": "Timestamp Alignment",
      "id": "*1rRGJh95ht97pUd2",
      "type": "Sink",
      "inPorts": [
        {
          "description": "Data table containing at least one column of datetime type (Local Date, Local Time, Local Date Time, Zoned Date Time).",
          "name": "Input data table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Data table containing the input data table with extra rows if skipped sampling times are found. If replace timestamp column boolean is checked, then the input timestamp column will be replaced with the new timestamp column with uniform sampling, Otherwise the new timestamp column will be appended to the input table.",
          "name": "Data table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "description": "Image deprocessing for VGG neural network.\n\nThe node expects a flow variable \"currentColumnName\" to define the column, which has to be preprocessed.\n\nMimic inverse operations compared to \"preprocess_input\" from\nhttps://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py",
      "name": "Image deprocessing for VGG",
      "id": "*mYP_BEwJYy5LkZh5",
      "type": "Other",
      "inPorts": [
        {
          "description": "Input data table",
          "name": "Input data table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Output data table",
          "name": "Output data table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoBYwMTFxMDIymgDEDdiwsbHxfAMDAwGcBgAVJRgaGsrjkZ8AlF+A0xBCBgBd2A/UbAB0yXqshsAMgHoFxfkgeaAmkHgCEBeAaJwGGEBAAhJGsQ3IVyBkgICFhYUCDJNsAC4vkG0ASANJBmBIoIFRA/AYAEyiAbgyEhqeAIopQhYRDQAHAltSvpTuDAAAAABJRU5ErkJggg==",
      "description": "This component can compute different metrics of topics created by the Topic Extractor (Parallel LDA) node and Topic Extractor (STM) component. We list below the metrics it can score provided a table or pre-processed documents and a table of weighted terms for each topic. Provide the topics of a single model or of multiple models. \r\n\r\nTake a look at the example workflows at the bottom of this page to learn how to concatenate topics from different models trained on the same corpus of documents or add a ‘model ID’ to the output of the Topic Extractor (Parallel LDA) node.\r\n\r\nDISCLAIMER: this verified component is currently marked as part of KNIME Labs (knime.com/knime-labs). Provide feedback at upskilling@knime.com\r\n\r\nTopic Semantic Coherence score:\r\nThis component calculates semantic coherence scores for each topic. Semantic coherence measures how coherent topics are by checking if the topics top terms appear together in the same documents more often than not. This experimental implementation is based on the paper by Mimno et al (2011) [dl.acm.org/doi/10.5555/2145432.2145462].\r\n\r\n\r\nTopic Exclusivity score:\r\nThis component calculates the exclusivity of topics. Exclusivity is computed using an experimental implementation of the FREX function by Bischof and Airoldi (2012) [dl.acm.org/doi/10.5555/3042573.3042578]. FREX does not take in consideration only how exclusive/unique terms are between different topics (top terms table), but also how rare those topics are in documents of the same topic (documents table). \r\n\r\nWhen comparing multiple models, documents can be assigned by different models to different topics and therefore exclusivity can be computed only using how unique terms are in the topics top terms table. Read more in the setting “Ignore Assigned Topic Column” description.\r\n\r\nTopic Neighbor Distance score:\r\nThis component computes an experimental distance between topics within the same model or between several models. To do this, topics are represented by a normalized vector by pivoting the top terms by topic table. A cosine distance between topic vectors is computed. For each topic the distance is used to show the closest and farthest topic within one or between more models.",
      "name": "Topic Scorer (Labs)",
      "id": "*5lttVZskfUiFwZJl",
      "type": "Source",
      "inPorts": [
        {
          "description": "The pre-processed documents from the corpus used to train the topic model. They can be the ones used in training or a hold-out sample. The documents should be in the KNIME Textprocessing format (use the Strings to Document node).",
          "name": "Documents Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "The topics top term table created either by the Topic Extractor (Parallel LDA) node or the Topic Extractor (STM) component (second table output). This table should list the top weighted terms for each topic for one or different models. If you concatenate topics from different models make sure to add a column for the model ID.",
          "name": "Top Terms by Topics Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "For each topic the measured metrics in a table.",
          "name": "Scored Topics",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAtUlEQVR4nK2S3Q3DIAyEM0JHYASLH4lHRsgIjJAROgIbtBt0hK4Wn2QkCwEFqSf5wST+zjo4jn/IWvtsi4geWwDdY9g59+6BdQ0BUAiB+DwvmfYAcn5xlZ47b/j9CZhpaYMqdjurs/c+LQM4TKPXlT7vABIc5VozMsE2Q4A41NByBeBbjNGgphnoAXb6cL1q32oEIAyp15iWAPLq8iSDS6AFGUiVHrgFGPzYu4UtYUhvsA2Y6QaZe2IxLfqnMAAAAABJRU5ErkJggg==",
      "description": "This Component loads the pickled object that is created by the Verified Component Python Transform [ kni.me/c/KwccMRKudBpcML_- ] and saved via the Python Object Writer node. The creation of the pickle object is defined by the distribution of the data available on its creation.\r\n\r\nThe output pickled object can be provided to the input of the Verified Component “Python Transform (Apply)” [ kni.me/c/7_E0qDd1UhpgSwZ4 ] to apply the same transformations in a new workflow. This is usually done in deployment settings : a REST API application deployed on KNIME Server where the Python transformations can be applied on demand on new data.",
      "name": "Python Transform (Load)",
      "id": "*V-C40570N4zeK8kq",
      "type": "Manipulator",
      "inPorts": [],
      "outPorts": [
        {
          "description": "Python pickled object containing parameters for transformation.",
          "name": "Port 0",
          "optional": false,
          "color": "#1eb9dc",
          "portTypeName": "Python"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAlElEQVR4nGNgoAUwMDAQMDIyKgDiBiguAIopEKUZpNjExKQBZAi6gcbGxvmENCfgswkkh9MQoKQByAAiXJgAdKEDNokGQpqR1E6g1ABMtYPCAKLiGqQGZ2ADo2g+EbZjBiCy6UBDJoBoUOIxNDRcgJygiHIlSAMoJYL8CTRsAbKrkA0jCkCTtQNJmpBtA6VOsjSTAgCY9TAwIZkx9AAAAABJRU5ErkJggg==",
      "description": "This component consumes Google's Custom Search Engine (CSE) API to return search results of a certain keyword. The configuration dialogue requires multiple inputs from the user. It is necessary to provide a CSE API key, Google Custom Search Engine ID and a query to receive results successfully.\r\n\r\nMore information on how to receive an API key can be found at developers.google.com/custom-search/v1/overview .\r\n\r\nThe component automatically loops calls to the Google CSE service, where each call returns a page of maximum 10 results. All the results are then collected page after page and provided at the output of the component as a table. Please note that if you are using a free version of CSE service, you can only query the first 10 pages/calls per day. You can limit the number of pages/calls the component collects via its dialogue.",
      "name": "Google URLs Extractor",
      "id": "*6_LByt7MSt1Z5VIe",
      "type": "Learner",
      "inPorts": [],
      "outPorts": [
        {
          "description": "Returns parsed meta data of search results.",
          "name": "Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAL9JREFUOI3NksENwjAMRe3f3mEDRsC1MkBGgBHYpBswAxswQgaoREZgBLi3SS8NClUrSg+Id3Til28rRH+JiGyX3sVUsSiKc1VVu9WCGOOTmY+rBCJiAVyZeb9KAMA2TeOY+WKMsfmZMeb2UZBo29aHEF4CEbExxvt4N2+CIb4jIvLeP8bJuq47jXeDIZpV1TrFz5pcPkaSqmqd6jw3QkJV6xCCK8uScvnkCHMAOEw1LxIAcMy8WfLQLN987d/TA7LzPNQeMwIBAAAAAElFTkSuQmCC",
      "description": "This component is based on the AlphaFold Protein Structure Database (see: alphafold.ebi.ac.uk).\nThe Alphafold AI system predicts a protein's 3D structure from its amino acid sequence. The component uses an existing already trained version of Alphafold to predict the 3D structure.\n\nThe component provides a simple search against the database by entering a search term. As a result, the name/description, UniProt IDs,  and organism from the search query will be displayed in a view as well as the 3D structure using the 3D Molecule Viewer component (Cartoon Style recommended). The results are available in the output table of the component, which also includes the UniProt Sequence. \n\nFor a simple search enter a protein name (e.g. fatty acid receptor), gene name (e.g. At1g58602), or Uniprot ID (e.g. Q5VSL9).\n\n\nFor more information see: \n\nJumper, J et al. Highly accurate protein structure prediction with AlphaFold. Nature (2021). \n\nVaradi, M et al. AlphaFold Protein Structure Database: massively expanding the structural coverage of protein-sequence space with high-accuracy models. Nucleic Acids Research (2021). \n",
      "name": "Alphafold Database Search",
      "id": "*fTURmdHrQmy_LtSL",
      "type": "Other",
      "inPorts": [],
      "outPorts": [
        {
          "description": "Name/Description, UniProt ID and Organism from the resulting query are included.",
          "name": "Result Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "name": "Accuracy",
      "id": "*KwvMmPzIK5FQ9Squ",
      "type": "Other",
      "inPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAbUlEQVR4nGNgoCcwMTGpNzIyagDS/QYGBgIkGwDSDKUTDA0N5QeRAUD/KBgbG68HKQDRZBkAEkRWRLEBQJcEgNhQnECyAcguQRcbrgYAA20+NBrnQxUVIAViATRgF0DVLCArKeMESDaRhKliOQAZbVysPCQ3DwAAAABJRU5ErkJggg==",
      "description": "This component will visualize a dot map based on latitude and longitude columns and value columns.\r\n\r\nColor mapping: A value column can be selected to be mapped into the marker color.\r\nSize mapping: A value column can be selected to be mapped into the marker size.\r\n\r\nThis component supports the latitude/longitude only in decimal format.\r\n\r\nWarning: The dotmap is based on Google Charts and JQuery library. Since Google Charts is loaded lazily, an internet connection is required when opening the view. \r\n\r\nDisclaimer: To deploy this visualization on KNIME Server your KNIME Server admin needs to allow “google.com”, “gstatic.com”, and “googleapis.com” to serve content that violates the Content-Security-Policy (CSP). More infos at: docs.knime.com/latest/server_admin_guide\r\n",
      "name": "Dot Map",
      "id": "*i6wGt97lGHrUxXIf",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "Must contain latitude and longitude columns in decimal format.",
          "name": "Data Table ",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoBYwMTFxMDIymgDEDdiwsbHxfAMDAwGcBgAVJRgaGsrjkZ8AlF+A0xBCBgBd2A/UbAB0yXqshsAMgHoFxfkgeaAmkHgCEBeAaJwGGEBAAhJGsQ3IVyBkgICFhYUCDJNsAC4vkG0ASANJBmBIoIFRA/AYAEyiAbgyEhqeAIopQhYRDQAHAltSvpTuDAAAAABJRU5ErkJggg==",
      "description": "Use this component to extract meaningful text from any web page.\n\nThis component uses a Java based library called BoilerPipe (boilerpipe-web.appspot.com) to detect and remove boilerplate text from a web page and only extract the main textual content. The Java library uses a heuristic based approach, based on this research paper: \n\nl3s.de/~kohlschuetter/publications/wsdm187-kohlschuetter.pdf\n\nThe component, before starting the analysis, automatically downloads inside your workflow the Java library from:\n\nstorage.googleapis.com/google-code-archive-downloads/v2/code.google.com/boilerpipe/boilerpipe-1.2.0-bin.tar.gz\n\nWhen processing a long list of URLs, the Java library might get stuck on a web address with a faulty (not a valid HTML body) or way too big web page. The component in those exceptional cases might fail or take too long, so if possible remove the faulty web addresses from the input table beforehand.",
      "name": "Web Text Scraper",
      "id": "*K6xnj4BKASYWlsbA",
      "type": "Source",
      "inPorts": [
        {
          "description": "Web Addresses as input.",
          "name": "Web Addresses",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Outputs an additional column with extracted texts.",
          "name": "Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAA3klEQVR4nL2S/Q2CQAzFGYERHOECx/+MwAhuABvIBt4GjuAIjuAIrGJ/5koewQ80xiYNba/v3fXRovilhRB2G7x8Cq7r+mreV1W1xy0+m188Nx/paZomrAhohj3GOGbCNoMGq7XUIOAi+6YFmCYOiGkmp9nPrXZUInotPujtEwDxyWpJ8sTTtQfMrIey+ys0ZxzNDdxZPizGoOBjwAypjDjPnDVYgoX55M9SDTx+KKAaYEhE2FJfoxe8IrkrbN+Qd6Hz2Ed8a/ors+K9irjJIGALWTBfro+NXcC/Av/NbnifZmUzsd9GAAAAAElFTkSuQmCC",
      "description": "This component computes the MIRR (Modified Internal Rate of Return) just like in spreadsheet tools like Microsoft Excel and Google Sheet. Adopt this component to analyze the attractiveness of one or more investment projects with periodic transactions/cash flows.\r\n\r\nThe metric computation is implemented using Group Loop, Math Formula and GroupBy nodes.\r\n\r\nThe component calculates the modified internal rate of return for a schedule of cash flows taking into account both discount rate and reinvestment rate for future cash flows. Make sure that you have at least one column for the cash flows (for each portfolio/project the first transaction needs to be negative), one column containing the Reinvestment rate (should be the same for each investment group), one column for the Finance rate (should be the same for each investment group) and one column for the project/portfolio by which you want the transactions to be grouped by.\r\n\r\nMicrosoft Excel Docs: support.microsoft.com/en-us/office/mirr-function-b020f038-7492-4fb4-93c1-35c345b53524\r\n\r\nGoogle Sheets Docs: support.google.com/docs/answer/3093180\r\n\r\nThis component, verified by KNIME, was developed by finance analytics experts at Mydral, KNIME Partner of the Year 2022: mydral.com/en/knime-uk",
      "name": "Modified Internal Rate of Return (MIRR)",
      "id": "*XQgIFBho4g6zp5s_",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "A KNIME Table where each row represents a financial transaction with the following columns:\r\nA column of type String is necessary to identify the financial project/portfolio. \r\nA column of type Double or Integer is necessary to identify the value of the financial transactions.\r\nA single value column of type Double that represents the Reinvestment rate.\r\nA single value column of type Double that represents the Finance rate.",
          "name": "Investments Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "A table is returned with a column for the name of the project/portfolio and a column for the MIRR value of each project.",
          "name": "MIRR",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAtUlEQVR4nK2S3Q3DIAyEM0JHYASLH4lHRsgIjJAROgIbtBt0hK4Wn2QkCwEFqSf5wST+zjo4jn/IWvtsi4geWwDdY9g59+6BdQ0BUAiB+DwvmfYAcn5xlZ47b/j9CZhpaYMqdjurs/c+LQM4TKPXlT7vABIc5VozMsE2Q4A41NByBeBbjNGgphnoAXb6cL1q32oEIAyp15iWAPLq8iSDS6AFGUiVHrgFGPzYu4UtYUhvsA2Y6QaZe2IxLfqnMAAAAABJRU5ErkJggg==",
      "description": "This KNIME component allows you to apply various data cleaning steps interactively. Default configuration will implement cleaning of missing values and outliers.\r\n\r\nAvailble pre-processing steps:\r\n- Automatic type guessing: determine the most specific type in each string column and change the column types accordingly.\r\n- Treatment of missing values: separate configurations for missing values in string and number columns.\r\n- Outlier removal: configuration on how to treat outliers.\r\n\r\nAll preprocessing steps have a \"Do nothing\" option, that will allow to skip the corresponding step.\r\n\r\nIn addition, you can select and (optionally) rename a subset of columns to be used in the following. If no columns are selected, whole data table will be used.\r\n\r\nThere is also a summary of the input data presented at the bottom of the page to drive decisions about pre-processing steps.\r\n\r\nUse WebPortal/JS View to configure this components",
      "name": "Interactive Data Cleaning",
      "id": "*SktDsN8OHaYdz8oG",
      "type": "Manipulator",
      "inPorts": [
        {
          "description": "Input data table",
          "name": "Input data table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Processed data table",
          "name": "Processed data table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAf0lEQVR4nGNgGJTAwMBAgCIDjI2N5xsaGsqTbYCRkdEEIC4gSzPQ+Q4mJiYOIFeQa3sDiAYZAsLIckD+eaINAAUkjA1zGdBV6/GGDcz56IbB2FBDMcMGpAmkAFkDujdgciADQGx07+H1ErrLSAJQl00gSzMIUBSlMEBx0qYpAAAehidos81u4QAAAABJRU5ErkJggg==",
      "description": "This component extracts data from the latest version of ChEMBLdb by connecting to ChEMBL API via REST. Information about either compounds, assays or targets can be selected.\r\nMore information can be found here: \r\nChEMBL webservices: https://chembl.gitbook.io/chembl-interface-documentation/web-services \t\r\nKNIME blog post: https://www.knime.com/blog/a-restful-way-to-find-and-retrieve-data \t\r\n",
      "name": "ChEMBL Details",
      "id": "*Iui40xmCBJC8ZQHU",
      "type": "Other",
      "inPorts": [],
      "outPorts": [
        {
          "description": "Table containing detailed information about compounds, assays or targets.",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAcElEQVR4nGNgoDUwMDAQMDEx6TcyMmoA4gJyDFAAakwAsUGGDFIDQH6D+hHDn2gGTICqmWBsbByAbEADNjYuFyCLYWgCmrwfxAfS88kyAMbGpniYG5AAi0Zg4K2H0TDFoABFlsOIRooBUiIiCVPFcgAwM2Hob2VycwAAAABJRU5ErkJggg==",
      "description": "This component generates a Small Multiples chart: a series of similar plots to be compared. In this component we offer three chart types: line plots, bar charts and scatter plots. Each small multiple visualizes a partition of your input data based on a given categorical column. \r\n\r\nDISCLAIMER: if a partition contains more than 10k rows its small multiple is going to show an empty chart for performance reasons. Consider in this case sampling your data before applying this component.\r\n\r\nThis component is implemented using plotly.js library (version 1.47.4).",
      "name": "Small Multiples View",
      "id": "*gib9c_qixsVRI4dD",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "Should contain at least one categorical column.",
          "name": "Input Data Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAShJREFUOI2lk8ttwzAQRB9JFaAS1EEWKxjwzXIHKUGpIC4hJaiEpIK4BB0NWCKUDlSCKyBzMGUYiSUbyZwILOftLD/wTxkAVX37WQghNMMwnO4Bsmnhvb9ARCR3zjWqOi6ZL55bCVarlahqPWeePNnchuPxOKhqpaoN8GsUY8xmEZAiNn9OcK2yLJ9jjAJgrW27rmun2iJARAprbQ1svPdbESmA6nrPvQSFtbYNISAitbU2N8aMs4DUccf50MYQwgjn61qv1wXA4XCYB6SO+67r2rIsP51zJ+DjlnEOcIoxvqpqFWP8CiG0WbY8ZQZgjClUtfbevwMvVyNVAKq6A3IgN8a0qZxD+gtzEpHCObcDnvq+36YzqlIj7gImpSddTAn6vt8/4ntI38/oaqnXds3PAAAAAElFTkSuQmCC",
      "description": "This component generates example data for a clustering task based on the make_blobs() function in the Python scikit-learn library.\n\nFor more information see the sklearn documentation:\n\nscikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html\n\nNote: This component requires a Python environment. In this blog post we explain how to setup the KNIME Python extension:\n\nknime.com/blog/setting-up-the-knime-python-extension-revisited-for-python-30-and-20\n",
      "name": "Synthetic Data Generator (Clustering)",
      "id": "*pTUNvEZIQ7DQIAKe",
      "type": "Manipulator",
      "inPorts": [],
      "outPorts": [
        {
          "description": "Cluster data",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoDYwMDBwMDIyaoBhID+AaM1ADQUmJiYOQE0CMDEQ39jYeD1QTIGgZlyKQAYaGhouwOdsA6ABCfgsABkOsgSX7Q14nUdI3cAbAAppEManGW8YQE2fgBx92GzHG5UgSWzxDTIUpBkUjfgsQLYpATklQtOHACwtEGUIHlcOIkMIxRrRAABplTOgJ4UUigAAAABJRU5ErkJggg==",
      "description": "Counterfactual Explanations describe the smallest changes to the feature values required to change the prediction outcome. Those values should be intuitive to explain any prediction as they point out what feature values should be improved to go from a negative class to a positive class.\r\n\r\nThis component generates the Counterfactual Explanations for Binary Classification models using the Python Library “alibi” (docs.seldon.io/projects/alibi). The component outputs a table listing for each input row a counterfactual explanation followed by the original prediction and the new prediction. The new prediction is relative to the counterfactual instance obtained by summing the explanation values to the original instance. In case the component couldn't find any explanation for an original instance, null values will be listed in the relative row at the component output. \r\n\r\nDATA INPUT REQUIREMENTS\r\n- The input data should be instances that you would like to explain. Those instances must have all the columns that were used while training the model.\r\n\r\nDATA PRE-PROCESSING REQUIREMENTS \r\n\r\n- The data preprocessing should be provided as a Python pickled object defined by a custom Python class.\r\n- The custom Python class should be present in the workflow folder where the component is executed.\r\n- The custom Python class should be called “custom_class_data_processing.py”. \r\n- The default Python class as well as Jupyter Notebooks to understand how to use it are available on the following KNIME Hub space: \r\n\r\n---> kni.me/s/hLLRgZLzgSNv8Z6M\r\n\r\nBLACK BOX MODEL REQUIREMENTS\r\n\r\n- The model should be trained on normalized numerical features only: no other kind of data preparation is supported, unless you edit the custom Python class defining the pre-processing.\r\n- The model has to be trained using the Python libraries Keras or scikit-learn. \r\n- The model can be trained in Python outside of KNIME Analytics Platform or inside using either KNIME Deep Learning Integration or KNIME Python Integration. \r\n- If the model is trained with scikit-learn, it has to be provided as a pickled object.\r\n- If the model was trained with Keras (either Tensorflow 1 or 2) it has to be provided in h5 format.\r\n- The counterfactual library ‘alibi’ only supports differentiable black box models. This means in our case you cannot explain any scikit-learn tree ensemble (e.g. Random Forest).",
      "name": "Counterfactual Explanations (Python)",
      "id": "*oAAe5rXU6TZvhdHI",
      "type": "Learner",
      "inPorts": [
        {
          "description": "Trained Model either from Keras Network Learner, Python Learner or Python Object Reader.",
          "name": "Trained Model",
          "optional": false,
          "color": "#9b9b9b",
          "portTypeName": "Generic Port"
        },
        {
          "description": "Pre-Processing Pickled Object from Python Object Reader or Data Preprocessing for Keras Model Component.",
          "name": "Pre-Processing Pickled Object",
          "optional": false,
          "color": "#9b9b9b",
          "portTypeName": "Generic Port"
        },
        {
          "description": "Row instances to be explained. Those rows should be in raw format: not normalized before the preprocessing Python script was applied.",
          "name": "Input Instances",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "The component outputs a table listing for each input row a counterfactual explanation followed by the original prediction and the new prediction. The new prediction is relative to the counterfactual instance obtained by summing the explanation values to the original instance. In case the component couldn&#39;t find any explanation for an original instance, null values will be listed in the relative row at the component output.",
          "name": "Counterfactual Explanations",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAsklEQVR4nGNgoBUwMDBwMDIyakDGIDFiNAqAFJuYmGAoBoonAPEEoBoFilwHNLyeaEMMIEABTUzA2Nh4PooA0Gn12JwN8jc2cZAYWBxoUgBQcwGQnoBiKgEDYGEFF4CGsgIooIgxAKYHOweLTegGE20AkkEGQC+uRzNgApwDDxQiAchFGOpRTMTvGlA0YqqFBmIBIc2wAMelQAFo+n5s6R4kBrKZqFQITR8omYmUMCIaAAD0RELelYkiBgAAAABJRU5ErkJggg==",
      "description": "Trains AutoRegressive Integrated Moving Average (ARIMA) models and returns the best model according to the search criterion (AIC, BIC) within the provided constraints (max p,d,q). ARIMA model captures temporal structures in time series data in the following components:\r\n- AR: Relationship between the current observation and a number (p) of lagged observations \r\n- I: Degree (d) of differencing required to make the time series stationary\r\n- MA: Time series mean and the relationship between the current forecast error and a number (q) of lagged forecast errors\r\n\r\nAdditionally, coefficent statistics and residuals are provided as table outputs.\r\n*Note that the (p,d,q) values of the selected model can be found in the model summary output table.\r\n\r\nModel Summary metrics:\r\nRMSE (Root Mean Square Error)\r\nMAE (Mean Absolute Error)\r\nMAPE (Mean Absolute Percentage Error) \r\n*will be missing if zeroes in target\r\nR2 (Coefficient of Determination)\r\nLog Likelihood\r\nAIC (Akaike Information Criterion)\r\nBIC (Bayesian Information Criterion)\r\n\r\nIf you encoutner errors please verify that \nPreferances > KNIME > Python (labs) > Python environment configuration\nis set to bundled",
      "name": "Auto ARIMA Learner",
      "id": "*JmBY9IxmytQd5w1i",
      "type": "Sink",
      "inPorts": [
        {
          "description": "Table containing numeric target column to fit the ARIMA model.",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "ARIMA model.",
          "name": "Port 1",
          "optional": false,
          "color": "#1eb9dc",
          "portTypeName": "Python"
        },
        {
          "description": "Table containing the selected ARIMA (p,d,q) model, coefficient statistics, and the following evaluation metrics of the ARIMA model:\r\nRMSE\r\nMAE\r\nMAPE\r\nR2\r\nLog Likelihood\r\nAIC\r\nBIC",
          "name": "Port 2",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Table containing the residuals.",
          "name": "Port 3",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoDYwMDBwMDIyaoBhID+AaM1ADQUmJiYOQE0CMDEQ39jYeD1QTIGgZlyKQAYaGhouwOdsA6ABCfgsABkOsgSX7Q14nUdI3cAbAAppEManGW8YQE2fgBx92GzHG5UgSWzxDTIUpBkUjfgsQLYpATklQtOHACwtEGUIHlcOIkMIxRrRAABplTOgJ4UUigAAAABJRU5ErkJggg==",
      "description": "This component is able to compute Global Feature Importance for classification models with up to 4 different techniques. \r\n\r\nThe component additionally offers an optional interactive view to explore the results (Right Click > Open Interactive View).\r\n\r\nThe model to be explained needs to be captured within a Workflow Object via Integrated Deployment. \r\n\r\nThe data provided should contain instances the model is able to process to compute predictions. It would be best to provide a sample similar to a test or validation set: representative of the entire distribution and never used during training.\r\n\r\nPlease notice that it is not recommended to use a surrogate model to explain either a GLM or Logistic Regression, a Decision Tree or a Random Forest, but it is still possible. \r\n\r\nAvailable Global Feature Importance methods/techniques:\r\n\r\nA) GLOBAL SURROGATE MODELS: \r\n\r\nSurrogate models are simply interpretable models that are trained to mimic the behaviour of the original model by overfitting its predictions. The intuition is that if the surrogate and interpretable model is able to make the exact same predictions of the original model, then it can be used to understand how the input features are connected to those predictions. The quality of the surrogate models is estimated with the user-defined performance metric.\r\n\r\nBefore training the surrogate models: \r\n- the data rows are cleaned by replacing the missing values with the categorical column most frequent value or the mean for the numerical columns;\r\n- optionally the categorical columns with too many unique values can be removed based on a user-defined parameter; \r\n- numerical features are converted to double and normalized using min-max normalization.\r\n\r\nThree interpretable models are available:\r\n\r\nA1) Surrogate Generalized Linear Model (GLM):\r\nGLM is trained with the KNIME H2O Machine Learning Integration with optimized parameters “lambda” and “alpha”. The family (model type) is either binomial or multinomial for binary or multinomial classification, respectively. GLM coefficient measures feature importance. If there are categorical features, surrogate GLM is not trained due to decreasing interpretability.\r\n\r\nA2) Surrogate Decision Tree Model:\r\nDecision Tree is trained with optimized parameter “Min number records per node”. The Decision Tree structure indicates the importance of the top-level level features since they separate the data into classes in the best way.\r\n\r\nA3) Surrogate Random Forest Model:\r\nRandom Forest is trained with optimized parameters “Tree Depth”, “Number of models” and “Minimum child node size”. Feature importance is calculated by counting how many times it has been selected for a split and at which rank (level) among all available features (candidates) in the trees of the random forest.\r\n\r\nB) PERMUTATION FEATURE IMPORTANCE:\r\n\r\nPermutation feature importance measures the difference between the model performance score estimated on predictions using all the original features and the model performance score estimated on predictions using all the original features except one which was randomly permuted. If a feature was permuted several times, the average difference is calculated. The process is repeated for each feature. The score difference standard deviation from permutations is provided as an additional output.\r\n\r\nMore information at: \r\nMolnar, Christoph. \"Interpretable machine learning\", 2019.\r\nchristophm.github.io/interpretable-ml-book",
      "name": "Global Feature Importance",
      "id": "*RjsV8Hzf9LGIl23o",
      "type": "Learner",
      "inPorts": [
        {
          "description": "Production Workflow containing input model, stored as a Workflow Object via Integrated Deployment nodes",
          "name": "Input Model",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Workflow Port Object"
        },
        {
          "description": "Data from Test Set Partition with available Target (Ground Truth) column",
          "name": "Data from Test Set Partition",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Table with Global Feature Importance measured by different techniques.",
          "name": "Feature Importance",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAA3klEQVR4nL2S/Q2CQAzFGYERHOECx/+MwAhuABvIBt4GjuAIjuAIrGJ/5koewQ80xiYNba/v3fXRovilhRB2G7x8Cq7r+mreV1W1xy0+m188Nx/paZomrAhohj3GOGbCNoMGq7XUIOAi+6YFmCYOiGkmp9nPrXZUInotPujtEwDxyWpJ8sTTtQfMrIey+ys0ZxzNDdxZPizGoOBjwAypjDjPnDVYgoX55M9SDTx+KKAaYEhE2FJfoxe8IrkrbN+Qd6Hz2Ed8a/ors+K9irjJIGALWTBfro+NXcC/Av/NbnifZmUzsd9GAAAAAElFTkSuQmCC",
      "description": "This component shows the (cumulative) customer count or churn rate by time and time-based cohort. Cohorts are used to group individual records by the characteristics that they share, which is their starting time in this case. Analysis of cohorts reveals trends and patterns that could not be identified from the individual records.\r\n\r\nA time-based cohort for each ID is defined based on the first time when the ID appears in the data.\r\n\r\nFour types of churn analysis are possible:\r\n1. The cumulative customer count by time and time-based cohort (stacked area chart)\r\n1. The cumulative churn rate by time and time-based cohort (stacked area chart)\r\n2. The customer count in each time-based cohort over time (line plot)\r\n2. The churn rate in each time-based cohort over time (line plot)\r\n\r\nRequired extensions:\r\n- KNIME Expressions \r\n(https://hub.knime.com/knime/extensions/org.knime.features.expressions/latest)\r\n- KNIME Plotly \r\n(https://hub.knime.com/knime/extensions/org.knime.features.js.plotly/latest)\r\n- KNIME Math Expression (JEP) \r\n(https://hub.knime.com/knime/extensions/org.knime.features.ext.jep/latest)\r\n- KNIME Quick Forms \r\n(https://hub.knime.com/knime/extensions/org.knime.features.js.quickforms/latest)",
      "name": "Customer Count and Churn Rate by Time-based Cohort",
      "id": "*PyqHJUoqxLKoUJkj",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "- String or numeric column for the IDs of the records\r\n- Column of type Date&amp;Time for the time points of the records",
          "name": "Recurring values",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "If the &#34;Generate image&#34; option is enabled, the cohort chart is provided in SVG format. Otherwise the chart is only shown in the component&#39;s interactive view.",
          "name": "SVG image",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAsklEQVR4nGNgoBUwMDBwMDIyakDGIDFiNAqAFJuYmGAoBoonAPEEoBoFilwHNLyeaEMMIEABTUzA2Nh4PooA0Gn12JwN8jc2cZAYWBxoUgBQcwGQnoBiKgEDYGEFF4CGsgIooIgxAKYHOweLTegGE20AkkEGQC+uRzNgApwDDxQiAchFGOpRTMTvGlA0YqqFBmIBIc2wAMelQAFo+n5s6R4kBrKZqFQITR8omYmUMCIaAAD0RELelYkiBgAAAABJRU5ErkJggg==",
      "description": "Trains a Seasonal AutoRegressive Integrated Moving Average (SARIMA) model. SARIMA models capture temporal structures in time series data in the following components:\r\n- AR: Relationship between the current observation and a number (p) of lagged observations \r\n- I: Degree (d) of differencing required to make the time series stationary\r\n- MA: Time series mean and the relationship between the current forecast error and a number (q) of lagged forecast errors\n\n*Seasonal versions of these operate similarly with lag intervals equal to the seasonal period (S).\r\n\r\nAdditionally, coefficent statistics and residuals are provided as table outputs.\r\n\r\nModel Summary metrics:\r\nRMSE (Root Mean Square Error)\r\nMAE (Mean Absolute Error)\r\nMAPE (Mean Absolute Percentage Error)\r\n*will be missing if zeroes in target\r\nR2 (Coefficient of Determination)\r\nLog Likelihood\r\nAIC (Akaike Information Criterion)\r\nBIC (Bayesian Information Criterion)\r\n\r\nIf you encoutner errors please verify that \nPreferances > KNIME > Python (labs) > Python environment configuration\nis set to bundled\r\n",
      "name": "SARIMA Learner",
      "id": "*99XoaszWhL5vXN4g",
      "type": "Sink",
      "inPorts": [
        {
          "description": "Table containing numeric target column to fit the SARIMA model.",
          "name": "Input data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "SARIMA model",
          "name": "SARIMA Model",
          "optional": false,
          "color": "#1eb9dc",
          "portTypeName": "Python"
        },
        {
          "description": "Table containing the coefficient statistics and the following evaluation metrics of the SARIMA model:\r\nRMSE\r\nMAE\r\nMAPE\r\nR2\r\nLog Likelihood\r\nAIC\r\nBIC",
          "name": "SARIMA Model Summary",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Table containing the residuals",
          "name": "Residuals",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAA3klEQVR4nL2S/Q2CQAzFGYERHOECx/+MwAhuABvIBt4GjuAIjuAIrGJ/5koewQ80xiYNba/v3fXRovilhRB2G7x8Cq7r+mreV1W1xy0+m188Nx/paZomrAhohj3GOGbCNoMGq7XUIOAi+6YFmCYOiGkmp9nPrXZUInotPujtEwDxyWpJ8sTTtQfMrIey+ys0ZxzNDdxZPizGoOBjwAypjDjPnDVYgoX55M9SDTx+KKAaYEhE2FJfoxe8IrkrbN+Qd6Hz2Ed8a/ors+K9irjJIGALWTBfro+NXcC/Av/NbnifZmUzsd9GAAAAAElFTkSuQmCC",
      "description": "Calculates k-period log return series from one-period log return series using the following formula:\r\nr(k) = r_1+r_2+...+r_k\r\n\r\nMissing values are treated as zeros.\r\n\r\nRequired extensions:\r\n- KNIME Quick Forms (https://hub.knime.com/knime/extensions/org.knime.features.js.quickforms/latest)",
      "name": "One-period log returns to multi-period log returns",
      "id": "*5dFnHRQKje4xZ0_A",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "One or more numeric columns. Each selected column is interpreted as one-period log return series.",
          "name": "One-period log return series",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "k-period log return series calculated using the one-period log return series and window length k that are provided in the input.",
          "name": "k-period log return series",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoBYwMTFxMDIymgDEDdiwsbHxfAMDAwGcBgAVJRgaGsrjkZ8AlF+A0xBCBgBd2A/UbAB0yXqshsAMgHoFxfkgeaAmkHgCEBeAaJwGGEBAAhJGsQ3IVyBkgICFhYUCDJNsAC4vkG0ASANJBmBIoIFRA/AYAEyiAbgyEhqeAIopQhYRDQAHAltSvpTuDAAAAABJRU5ErkJggg==",
      "description": "The component trains an STM topic model via unsupervised learning. It integrates with the R implementation of Structural Topic Models (STM), following Roberts, Stewart and Tingley, Journal of Statistical Software (2019) (cran.r-project.org/web/packages/stm/vignettes/stmVignette.pdf), via the R library 'stm' (cran.r-project.org/web/packages/stm). \r\n\r\nOn its first execution the component is set up to automatically install R and all the required libraries. For this to work you need to install Conda (we recommend via \"docs.conda.io/en/latest/miniconda.html\"). KNIME Analytics Platform can automatically find the default path of where Conda is installed.  You can make sure KNIME Analytics Platform is using the correct path via \"File > Preferences > KNIME > Conda\". \r\n\r\nDISCLAIMER: this component won't work on Apple M1 systems as the 'stm' package is not available for 'osx-arm64' via 'conda-forge' (\"anaconda.org/conda-forge/r-stm\"). For Apple Intel systems manual installation of additional software might be required after the Conda Environment Propagation node executes. For details visit: docs.knime.com/latest/r_installation_guide\r\n\r\nUse the component settings to select a document in the column type from the KNIME Textprocessing Extension. Simply apply the Strings to Document node and any other preprocessing required (stopwords removal, stemming, ...) upstream of this component.\r\n\r\nGiven K, the number of topics  to be created, it returns the predicted topic for each document as well as a set of terms representing each of the K topics.\r\n\r\nOptionally you can provide metadata columns and fields to the algorithm. Metadata fields are extracted from the document column type. Metadata columns are simply additional columns you provide at the input. \r\n\r\nMake sure to provide an operator (+. -, / ,*) for the automated 'Prevalence Formula' when you provide more than one metadata field/column.",
      "name": "Topic Extractor (STM)",
      "id": "*2zwchITc80S6P_m4",
      "type": "Source",
      "inPorts": [
        {
          "description": "Data table with the document collection to analyze in the KNIME Textprocessing column type (use the &#39;Strings to Document&#39; node first). Each row contains one document. Documents can be pre-processed (stopwords removal, stemming, ...).",
          "name": "Document Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "The R object with the trained model. Use the component &#34;Topic Assigner (STM)&#34; to apply this model to new documents.",
          "name": "R Model",
          "optional": false,
          "color": "#9b9b9b",
          "portTypeName": "R Workspace"
        },
        {
          "description": "The document collection with topic assignments and the probability for each document to belong to a certain topic. Such probabilities are taken from the gamma/theta matrix returned by the &#39;stm_tidiers&#39; R function. Missing values are listed for rows with missing text or selected metadata fields/columns.",
          "name": "Document with Topics Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "The topic models with the terms and their weight per topic. The weight is taken from the beta matrix returned by the &#39;stm_tidiers&#39; R function. The table lists a maximum number of terms per topic based on the component setting.",
          "name": "Terms of Topics",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "A table listing metrics for the model on an automatically held-out partition of documents. One row for each K tested is provided if the &#34;Optimal K Search&#39;&#39; is enabled. No precise method exists for selecting the best K automatically. Despite this four metrics can help in making this decision: exclusivity, coherence, residual variance, and held-out likelihood. The higher the exclusivity the more each topic is composed of terms unique between topics. The higher the semantic coherence the more similar words are included in the individual topics. The lower the residual variance the better the model fits. The higher the held-out likelihood the better model predicts new documents. Increasing K should decrease coherence, increase exclusivity, decrease residual variance, but can lead to overfitting, reducing the held-out likelihood.",
          "name": "Scores Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAA3klEQVR4nL2S/Q2CQAzFGYERHOECx/+MwAhuABvIBt4GjuAIjuAIrGJ/5koewQ80xiYNba/v3fXRovilhRB2G7x8Cq7r+mreV1W1xy0+m188Nx/paZomrAhohj3GOGbCNoMGq7XUIOAi+6YFmCYOiGkmp9nPrXZUInotPujtEwDxyWpJ8sTTtQfMrIey+ys0ZxzNDdxZPizGoOBjwAypjDjPnDVYgoX55M9SDTx+KKAaYEhE2FJfoxe8IrkrbN+Qd6Hz2Ed8a/ors+K9irjJIGALWTBfro+NXcC/Av/NbnifZmUzsd9GAAAAAElFTkSuQmCC",
      "description": "This component provides three different ways for calculating and visualizing the ARR:\r\n1. calculating the total ARR in each month and visualizing it in a line plot\r\n2. calculating the total ARR in each month and year, and comparing the years in a line plot\r\n3. calculating the ARR in total and at a customer level in a selected month, e.g. the current month, and creating the interactive tile view for the further analysis.",
      "name": "ARR Analysis",
      "id": "*a1gEMZ16CFydgGyV",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "The input table containing the recurring values in each month based on the contract period and contract value.",
          "name": "Input table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Output table with the total ARR in each month",
          "name": "Output table with the total ARR in each month",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Pivot table with the total ARR in each month and year",
          "name": "Pivot table with the total ARR in each month",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Total ARR for the selected month",
          "name": "Total ARR for the selected month",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "ARR at a customer level for the selected month plus a column identifying if the customer was selected in the interactive tile view",
          "name": "Filtered table for the selected month",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAuklEQVR4nKVT2w3DMAjMCB7BIyA//j1CRvAI3aDeoNmgHTWQYAlFAbvtSZYicxxnIMtiAACcFR8CBUpKqfwjADlnmCU7rNZGvBBCQ67XRHw/KPYiMp9nL6ImSxFMeFzvYozvqadQxbt7aibG6s8Caowttz4u/N5GAuzmvpmaAy5UDfMnaO696yLZTTeRXVRMWKWr4fgE8dh/qggnfO+LuWzXJUGBD7lgN5vg+W/cEIo1WhW8fYcD67feARH/PpXMRyZ9AAAAAElFTkSuQmCC",
      "description": "This component generates a view to showcase the progress of a process for which the steps are pre-determined. For example, imagine the delivery of a parcel where the different steps from warehouse to destination are known.\r\n\r\nA horizontal progress bar and circular nodes for each “step” in the process are rendered in the composite view. The active step in the process is denoted by an open circle, while already completed and future steps are closed. The colors of the base progress bar and the completed steps can be configured in the dialogue settings.\r\n\r\nBy entering an ID number corresponding to a specific subject in a process (ex: Order ID, Customer ID, Case ID, Patient ID, etc.), the user can visually interpret how many steps the process is, track how far along the subject is, and see the names and dates of each step in the journey.\r\n\r\nThe view can be used to inspect data in a local workflow or in a data app deployed online and accessible by anyone via web browser. The second option allows the user of the data app to drill down into the progress of a given subject undergoing a sequence of pre-determined steps from any device.\r\n\r\nDISCLAIMER: The component does not show any progress for processes with more than 10 steps.",
      "name": "Progress Tracker View",
      "id": "*FKeR1yfauaGWr-k_",
      "type": "Learner",
      "inPorts": [
        {
          "description": "A KNIME Table where each row represents a step in a process for a given subject. Four Columns of data are necessary to describe each step: an “ID” column (String) to uniquely identify the subject; a “Step Name” column (String) to describe the name of the step; a “Status” column (Boolean) to denote whether or not this step has been completed; a “Date/Time” column (Date or Date &amp; Time) to describe when the step occurred. These values may be missing for rows with “false” status.",
          "name": "Data Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAsklEQVR4nGNgoBUwMDBwMDIyakDGIDFiNAqAFJuYmGAoBoonAPEEoBoFilwHNLyeaEMMIEABTUzA2Nh4PooA0Gn12JwN8jc2cZAYWBxoUgBQcwGQnoBiKgEDYGEFF4CGsgIooIgxAKYHOweLTegGE20AkkEGQC+uRzNgApwDDxQiAchFGOpRTMTvGlA0YqqFBmIBIc2wAMelQAFo+n5s6R4kBrKZqFQITR8omYmUMCIaAAD0RELelYkiBgAAAABJRU5ErkJggg==",
      "description": "Re-add seasonality back into the input data.\r\n\r\nRequired extensions: \r\nKNIME Quick Forms \r\n(https://hub.knime.com/knime/extensions/org.knime.features.js.quickforms/latest)\r\nKNIME Math Expression (JEP)\r\n(https://hub.knime.com/knime/extensions/org.knime.features.ext.jep/latest)",
      "name": "Return Seasonality",
      "id": "*NDS5FwoeqkZlLOIp",
      "type": "Sink",
      "inPorts": [
        {
          "description": "Table containing at least one numeric column to re-add seasonality to.",
          "name": "Input data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Table containing at least one numeric column as seasonality. ",
          "name": "Input data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Table with new column containing input data with re-added seasonality.",
          "name": "Output table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAShJREFUOI2lk8ttwzAQRB9JFaAS1EEWKxjwzXIHKUGpIC4hJaiEpIK4BB0NWCKUDlSCKyBzMGUYiSUbyZwILOftLD/wTxkAVX37WQghNMMwnO4Bsmnhvb9ARCR3zjWqOi6ZL55bCVarlahqPWeePNnchuPxOKhqpaoN8GsUY8xmEZAiNn9OcK2yLJ9jjAJgrW27rmun2iJARAprbQ1svPdbESmA6nrPvQSFtbYNISAitbU2N8aMs4DUccf50MYQwgjn61qv1wXA4XCYB6SO+67r2rIsP51zJ+DjlnEOcIoxvqpqFWP8CiG0WbY8ZQZgjClUtfbevwMvVyNVAKq6A3IgN8a0qZxD+gtzEpHCObcDnvq+36YzqlIj7gImpSddTAn6vt8/4ntI38/oaqnXds3PAAAAAElFTkSuQmCC",
      "description": "This component generates example data for a regression task based on the make_regression() function in the Python scikit-learn library.It is possible to control the strength of the linear relationship by adding noise into the generated predictor features.\n\nFor more information see the sklearn documentation:\n\nscikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html\n\nNote: This component requires a Python environment. In this blog post we explain how to setup the KNIME Python extension:\n\nknime.com/blog/setting-up-the-knime-python-extension-revisited-for-python-30-and-20\n",
      "name": "Synthetic Data Generator (Regression)",
      "id": "*FaEzXLfnTaee6AYT",
      "type": "Manipulator",
      "inPorts": [],
      "outPorts": [
        {
          "description": "Regression Data",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "name": "_Fetch_Experiment_Details_from_PubChem",
      "id": "*H9Noxl51T2r4wf7M",
      "type": "Other",
      "inPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAsklEQVR4nGNgoBUwMDBwMDIyakDGIDFiNAqAFJuYmGAoBoonAPEEoBoFilwHNLyeaEMMIEABTUzA2Nh4PooA0Gn12JwN8jc2cZAYWBxoUgBQcwGQnoBiKgEDYGEFF4CGsgIooIgxAKYHOweLTegGE20AkkEGQC+uRzNgApwDDxQiAchFGOpRTMTvGlA0YqqFBmIBIc2wAMelQAFo+n5s6R4kBrKZqFQITR8omYmUMCIaAAD0RELelYkiBgAAAABJRU5ErkJggg==",
      "description": "This component calculates autocorrelation with Pearson Correlation for lagged copies of time series. Additionally, it produces an interactive view that displays the Autocorrelation Function (ACF) Plot, Partial Autocorrelation Function (PACF) Plot, and detects the first local maximum of correlation for sign of dominant seasonality.\r\n\r\nIf you encoutner errors please verify that \nPreferances > KNIME > Python (labs) > Python environment configuration\nis set to bundled\r\n\r\n",
      "name": "Inspect Seasonality",
      "id": "*nGFg5UpfkrkagERG",
      "type": "Sink",
      "inPorts": [
        {
          "description": "Data containing selected column for the Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) analysis.",
          "name": "Input Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "This table contains a list of detected local maximum, their corresponding correlation, and lag value.",
          "name": "Data Table of detected local maximum",
          "optional": false,
          "color": "#ff4b4b",
          "portTypeName": "Flow Variable"
        },
        {
          "description": "This flow variable contains the lag value where the dominant seasonality might occur.",
          "name": "Flow Variable containing seasonality lag",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAsklEQVR4nGNgoBUwMDBwMDIyakDGIDFiNAqAFJuYmGAoBoonAPEEoBoFilwHNLyeaEMMIEABTUzA2Nh4PooA0Gn12JwN8jc2cZAYWBxoUgBQcwGQnoBiKgEDYGEFF4CGsgIooIgxAKYHOweLTegGE20AkkEGQC+uRzNgApwDDxQiAchFGOpRTMTvGlA0YqqFBmIBIc2wAMelQAFo+n5s6R4kBrKZqFQITR8omYmUMCIaAAD0RELelYkiBgAAAABJRU5ErkJggg==",
      "description": "This nodes performs a Fast Fourier Transform in a desired numeric timeseries data column. It requires the KNIME Python extensions with Python 3 set up.\r\n\r\nThe dataset cannot contain missing values.\r\n\r\nAdditionally, the component produces an interactive view displaying the normalized power spectrum of the signal.\r\n\r\nIf you encoutner errors please verify that \nPreferances > KNIME > Python (labs) > Python environment configuration\nis set to bundled",
      "name": "Fast Fourier Transform (FFT)",
      "id": "*mBfuP6U6PM4E2b3t",
      "type": "Sink",
      "inPorts": [
        {
          "description": "The Input data. It should contain a numeric time series column.",
          "name": "Input Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Output a table containing the original columns and two adittional columns with the resolved frequencies and their normalized power. Normalization is performed by dividing the raw amplitudes by the length of the signal. ",
          "name": "Transformed table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAf0lEQVR4nGNgGJTAwMBAgCIDjI2N5xsaGsqTbYCRkdEEIC4gSzPQ+Q4mJiYOIFeQa3sDiAYZAsLIckD+eaINAAUkjA1zGdBV6/GGDcz56IbB2FBDMcMGpAmkAFkDujdgciADQGx07+H1ErrLSAJQl00gSzMIUBSlMEBx0qYpAAAehidos81u4QAAAABJRU5ErkJggg==",
      "description": "This component flags input molecules according to the Rapid Elimination of Swill (REOS) filter rules, which are listed below.\r\nThe expected input is data in SMILES, SDF, Mol or RDKit molecule format.\r\nIn case a molecule violates one or more of the rules listed below, the according flags and abbreviations will be returned in a collection output column.\r\nThe component also allows checking for structural alerts as defined in various sources (see below). In case one or several structural alert rule sets are checked in the component's configuration window and a molecule contains such a structural alert, the first substructure from the list is highlighted in an additional output column. Note that the component only displays the first matching structural alert from the first selected rule set. Note that checking for structural alerts might take a while.\r\nIn case the input molecule matches neither a rule nor any structural alert, it will be flagged with \"true\" in the pass column.\r\n\r\n\r\nMW: Molecular weight between 200 and 500\r\nLogP: LogP between -5.0 and +5.0\r\nHBD: H-bond donor count between 0 and 5\r\nHBA: H-bond acceptor count between 0 and 10\r\nFC: Formal charge between -2 and +2\r\nRotB: Rotatable bond count between 0 and 8\r\nHAC: Heavy atom count between 15 and 50\r\n\r\nLINKS TO RULE SETS:\r\n* Bristol-Myers Squibb HTS Deck Filters - europepmc.org/article/MED/16711725\r\n* University of Dundee NTD Screening Library Filters - europepmc.org/article/MED/18064617\r\n* Glaxo Wellcome Hard Filters - europepmc.org/article/MED/10529988\r\n* Pfizer LINT filters - europepmc.org/article/MED/16787349\r\n* NIH MLSMR Excluded Functionality Filters - yumpu.com/en/document/read/12367541/mlsmr-excluded-functionality-filters-nih-molecular-libraries-\r\n* Pan Assay Interference Compounds (PAINS) Filters - europepmc.org/article/MED/20131845\r\n* SureChEMBL - surechembl.org/knowledgebase/169485-non-medchem-friendly-smarts\r\n\r\nOTHER INTERESTING LINKS:\r\n* Pat Walters's blog post about structural alerts: practicalcheminformatics.blogspot.com/2018/08/filtering-chemical-libraries.html\r\n* List of structural alerts used here (credits to Pat Walters): raw.githubusercontent.com/PatWalters/rd_filters/master/rd_filters/data/alert_collection.csv\r\n* ChEMBL blog posts with links to other structural alerts: chembl.blogspot.com/2015/02/chembl-20-released.html\r\n\r\n\r\nAll websites have been accessed in April 2022",
      "name": "REOS Tagger",
      "id": "*PeaGkiWdz5yaKSL-",
      "type": "Other",
      "inPorts": [
        {
          "description": "Table containing chemical data in SMILES, SDF or Mol format.",
          "name": "Input",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Input data containing valid molecules, plus columns containing the flag(s). If the input molecules match a structural alert from the chosen list(s), the first matching substructure is returned.  ",
          "name": "Output Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Input molecules that  could not be converted to a RDKit molecule. ",
          "name": "Output Port 2",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAf0lEQVR4nGNgGJTAwMBAgCIDjI2N5xsaGsqTbYCRkdEEIC4gSzPQ+Q4mJiYOIFeQa3sDiAYZAsLIckD+eaINAAUkjA1zGdBV6/GGDcz56IbB2FBDMcMGpAmkAFkDujdgciADQGx07+H1ErrLSAJQl00gSzMIUBSlMEBx0qYpAAAehidos81u4QAAAABJRU5ErkJggg==",
      "description": "This component performs a ChEMBL ID lookup by connecting to ChEMBL API via REST.\r\nMore information can be found here: \r\nChEMBL webservices: https://chembl.gitbook.io/chembl-interface-documentation/web-services \t\r\nKNIME blog post: https://www.knime.com/blog/a-restful-way-to-find-and-retrieve-data \t\r\n",
      "name": "ChEMBL Lookup",
      "id": "*Bx8dgfCOyTzUUorM",
      "type": "Other",
      "inPorts": [
        {
          "description": "Table containing ChEMBL IDs.",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Table containing ChEMBL ID, entity type and resource URL",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAlElEQVR4nGNgoAUwMDAQMDIyKgDiBiguAIopEKUZpNjExKQBZAi6gcbGxvmENCfgswkkh9MQoKQByAAiXJgAdKEDNokGQpqR1E6g1ABMtYPCAKLiGqQGZ2ADo2g+EbZjBiCy6UBDJoBoUOIxNDRcgJygiHIlSAMoJYL8CTRsAbKrkA0jCkCTtQNJmpBtA6VOsjSTAgCY9TAwIZkx9AAAAABJRU5ErkJggg==",
      "description": "This component extracts information from a workflow summary XML file that can be obtained from either  the File > Export > Workflow Summary (JSON/XML)… menu in KNIME Analytics Platform, or from a KNIME Server's REST API. \r\n\r\nOn the KNIME Analytics Platform, a workflow summary is extracted for the currently opened, executed and saved workflow in the workflow editor.\r\n\r\nThis component extracts the node names, node configurations, predecessor and successor nodes, execution status, node type, if the node is deprecated, and if it’s a metanode/component, names of the nodes and their occurrences, and the reader and writer nodes and the corresponding data locations, into a table representation based on the workflow summary file in XML format. If the “Include execution information“ option is checked when creating the workflow summary XML file, also the execution environment and installed plugins will be provided in the component’s table outputs.\r\n\r\nLarge workflows with lots of nested components and metanodes will inherently result in large workflow summary XML files. Analyzing such large summaries could take a long time and the resulting tables could be too big. In such cases, limiting the depth of analysis for nested components/metanodes with the component dialog is recommended. ",
      "name": "Analyze Workflow Summary",
      "id": "*DV77UWA0V6AbutQi",
      "type": "Learner",
      "inPorts": [
        {
          "description": "A table containing one XML column, typically an output from XML Reader node",
          "name": "Input table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Information about nodes and their settings as well as connection details",
          "name": "Node details",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Workflow metadata  and its execution environment (such as OS)",
          "name": "Environment and WF Metadata",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Plugins Installed at the time of workflow execution",
          "name": "Installed Plugins",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "A summary of nodes in the workflow",
          "name": "Nodes Summary",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Reader/Writer nodes and the corresponding file locations",
          "name": "In/Out Files",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAlElEQVR4nGNgoAUwMDAQMDIyKgDiBiguAIopEKUZpNjExKQBZAi6gcbGxvmENCfgswkkh9MQoKQByAAiXJgAdKEDNokGQpqR1E6g1ABMtYPCAKLiGqQGZ2ADo2g+EbZjBiCy6UBDJoBoUOIxNDRcgJygiHIlSAMoJYL8CTRsAbKrkA0jCkCTtQNJmpBtA6VOsjSTAgCY9TAwIZkx9AAAAABJRU5ErkJggg==",
      "description": "Component to allow a user to save a data table into the workflow file for easier sharing.\n\nThis component will \n\t1. Take a data table as an input\n\t2. Create the relative-to-the-workflow directory knime://knime.workflow/data\n\t3. Write your data in KNIME table format into that directory with whatever name you configure in the component window (if not specified, will default to data.table)\n\t4. Final path: knime://knime.workflow/data/<INPUT>.table\n\n\nThis helps for both \n\t1. Portability of the workflow (so you can send data with the .knwf file) \n\t2. Isolation/relativity (the data will always be in this location for you to pull from)",
      "name": "Embed Data Into Workflow",
      "id": "*gvIIKi21c9753VTU",
      "type": "Learner",
      "inPorts": [
        {
          "description": "Input data. The format will be saved as KNIME .table format",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "The path to the data stored (optional)",
          "name": "Port 1",
          "optional": false,
          "color": "#ff4b4b",
          "portTypeName": "Flow Variable"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoDYwMDBwMDIyaoBhID+AaM1ADQUmJiYOQE0CMDEQ39jYeD1QTIGgZlyKQAYaGhouwOdsA6ABCfgsABkOsgSX7Q14nUdI3cAbAAppEManGW8YQE2fgBx92GzHG5UgSWzxDTIUpBkUjfgsQLYpATklQtOHACwtEGUIHlcOIkMIxRrRAABplTOgJ4UUigAAAABJRU5ErkJggg==",
      "description": "This Component is able to create a Local Interpretable Model-agnostic Explanation (LIME) to explain the predictions of any machine learning model in KNIME.\r\n\r\nYou have to use this component together with LIME Loop Start node from the KNIME Machine Learning Interpretability Extension. \r\nPlease install KNIME H2O Machine Learning Integration.\r\n\r\nhttps://hub.knime.com/knime/extensions/org.knime.features.ext.h2o/latest\r\n\r\nThe workflow within the Component will go through the following steps:\r\n1. Using LASSO to select relevant features.\r\n2. Training a local surrogate Generalized Linear Model (GLM) using Weighted Least Squares (WLS).\r\n3. Output the coefficients of the local model able to explain the original instance prediction.\r\n\r\nMore info about LIME at: \r\n\r\nhomes.cs.washington.edu/~marcotcr/blog/lime",
      "name": "Compute LIME",
      "id": "*XclAuq8DhT2gr-s-",
      "type": "Learner",
      "inPorts": [
        {
          "description": "A table with a Double Type prediction column of the sampled instances. Such prediction column can be created scoring the LIME Loop Start top ouput table with the predictor node of your model. \r\n\r\nIf your model is solving a classification task make sure to output a pobability column of Double Type.",
          "name": "Predicted Samples",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "This table contains the data used to learn a local surrogate model including a weight column and it is produced by Loop Start node bottom port. ",
          "name": "Test Set Row Instances",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "A table containing the explanation. Each column with a feature column name holds the single value of the coefficient of the trained local surrogate linear model.\r\n \r\nAdditionally the columns &#34;Target&#34;, &#34;Intercept&#34; and &#34;RMSE&#34; are added. &#34;Target&#34; describes which prediction column of the orginal model is explained. &#34;Intercept&#34; shows the value of the intecept of the trained linear model. &#34;RMSE&#34; refers to the precision of the explanation. The lower, the better as it is computed using the weighted root mean squared error comparing the original predictions and the predictions created by the linear surrogate model.\r\n",
          "name": "Explanation Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAsklEQVR4nGNgoBUwMDBwMDIyakDGIDFiNAqAFJuYmGAoBoonAPEEoBoFilwHNLyeaEMMIEABTUzA2Nh4PooA0Gn12JwN8jc2cZAYWBxoUgBQcwGQnoBiKgEDYGEFF4CGsgIooIgxAKYHOweLTegGE20AkkEGQC+uRzNgApwDDxQiAchFGOpRTMTvGlA0YqqFBmIBIc2wAMelQAFo+n5s6R4kBrKZqFQITR8omYmUMCIaAAD0RELelYkiBgAAAABJRU5ErkJggg==",
      "description": "Computes predictions from an estimated Seasonal AutoRegressive Integrated Moving Average (SARIMA) model. \r\n\r\nTwo types of predictions are computed:\r\n1. Forecast: forecast of the given time series h periods ahead.\r\n2. In-Sample Prediction: generates prediction in the range of the training data.\r\n\t* If Dynamic is enabled lagged predictions are used, otherwise lagged true values are used.\r\n\t* Level setting determines whether in-sample differenced or original values are output. If no differencing in ARIMA model, this setting has no effect.\r\n\r\nIf you encoutner errors please verify that \nPreferances > KNIME > Python (labs) > Python environment configuration\nis set to bundled",
      "name": "SARIMA Predictor",
      "id": "*p80EuSTAEzmh71v3",
      "type": "Sink",
      "inPorts": [
        {
          "description": "SARIMA Model.",
          "name": "SARIMA Model",
          "optional": false,
          "color": "#1eb9dc",
          "portTypeName": "Python"
        }
      ],
      "outPorts": [
        {
          "description": "Forecasted values and their standard errors.",
          "name": "Forecast",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "In sample prediction from the SARIMA model, only populated if training with no seasonal terms.",
          "name": "In-Sample",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoDYwMDBwMDIyaoBhID+AaM1ADQUmJiYOQE0CMDEQ39jYeD1QTIGgZlyKQAYaGhouwOdsA6ABCfgsABkOsgSX7Q14nUdI3cAbAAppEManGW8YQE2fgBx92GzHG5UgSWzxDTIUpBkUjfgsQLYpATklQtOHACwtEGUIHlcOIkMIxRrRAABplTOgJ4UUigAAAABJRU5ErkJggg==",
      "description": "This component generates a view to interactively execute a model on an artificial data point. The view updates a visualization of the model output based on a new input manually inserted by the user. Adopt the view to either test a hypothesis or to deploy the model as a data app on KNIME WebPortal.\r\n\r\nThe component works for any classification or regression model captured in a workflow object via the KNIME Integrated Deployment Extension. Supported types for the input feature columns are: “Number (double)”, “Number (integer)” and “String”. For testing this component we recommend connecting its input model port with the “AutoML” classification component (kni.me/c/33fQGaQzuZByy6hE) or the “AutoML (Regression)” component (https://kni.me/c/5kzQcySUa8oukv0Y).\r\n\r\nIn order to work you also need to provide a sample of data with all the input feature columns of the model. The sample is used to compute the range of possible values (upper/lower bounds and string categories) that the user can change in the view. Constant numeric columns are not supported.\r\n\r\nFor deployment purposes you can also save the last input and prediction by adding more nodes to the component output.\r\n\r\nThis component was released as part of the Verified Components project (knime.com/verified-components).",
      "name": "Model Simulation View",
      "id": "*ppneWNiPuiKs8doL",
      "type": "Learner",
      "inPorts": [
        {
          "description": "A classification or regression model Workflow Object captured with KNIME Integrated Deployment.",
          "name": "Workflow Object",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Workflow Port Object"
        },
        {
          "description": "Sample table with all input feature columns. The sample is adopted to define the range of possible values the user can input via the displayed widgets.",
          "name": "Sample Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "The input and output of the model on its last execution.",
          "name": "Last Execution Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAlElEQVR4nGNgoAUwMDAQMDIyKgDiBiguAIopEKUZpNjExKQBZAi6gcbGxvmENCfgswkkh9MQoKQByAAiXJgAdKEDNokGQpqR1E6g1ABMtYPCAKLiGqQGZ2ADo2g+EbZjBiCy6UBDJoBoUOIxNDRcgJygiHIlSAMoJYL8CTRsAbKrkA0jCkCTtQNJmpBtA6VOsjSTAgCY9TAwIZkx9AAAAABJRU5ErkJggg==",
      "description": "This Component automatically trains supervised machine learning models for regression. The component is able to automate the whole ML cycle by performing some data preparation, parameter optimization with cross validation, scoring, evaluation and selection. The component also captures the entire end-to-end process and outputs the deployment workflow using the KNIME Integrated Deployment Extension. \r\n\r\nFor solving an ML classification task, check instead the “AutoML” component (kni.me/c/33fQGaQzuZByy6hE). \r\n\r\nSTEP-BY-STEP GUIDE: \r\n- Drag&drop the Component from KNIME Hub to KNIME Analytics Platform. \r\n- Connect with your data table of features and target column. Consider using a subsample first. \r\n- IMPORTANT! Execute all up-stream nodes. \r\n- Double click Component to open its dialogue. \r\n- Save your settings with “OK” and execute the Component. \r\n- Wait for models to train, tune, validate, etc. and the best one to be selected and exported. \r\n- Connect the Workflow Executor/Writer node to the Component output to reuse the model. \r\n- (OPTIONAL) Right click Component : “Component” > “Open” to inspect our implementation for you to customize. \r\n- (IF PREVIOUSLY ENABLED) Right click Component : “Open Interactive View: AutoML” to inspect all trained models. Selecting one manually (with “Apply&Close” in local View bottom right corner controls) unfortunately requires training all models again. \r\n\r\nDATA PREPARATION: \r\nBefore training the models the data is cleaned by replacing the missing values with the categorical column most frequent value or the mean for the numerical columns. Optionally the categorical data can be one-hot encoded and columns with too many unique values are removed based on a user-defined parameter. Numerical features and the target are all converted to double, normalized using Z-score normalization. The data is automatically split into the two train and test partitions using stratified sampling technique on the target class and 80% split. The data preparation models are stored for deployment both for pre-processing and post-processing the data around the model predictor. \r\n\r\nMODEL TRAINING: \r\nEach model has a number of parameters to be tuned using cross validation and the user-defined evaluation metric on train data. The extent of the parameter optimization, the optimization strategy as well as other settings of the model can be changed directly in the Component. \r\n- Regression Tree: trained with optimized parameter “Min number records per node” \r\n- Linear Regression: trained with default parameters \r\n- Polynomial Regression: trained with optimized parameter “Polynomial degree” \r\n- H2O Generalized Linear Model: trained with the KNIME H2O Machine Learning Integration trained with optimized parameters “alpha” and “lambda” \r\n- XGBoost Linear Ensemble: trained with optimized parameters “alpha” and “lambda” \r\n- XGBoost Tree Ensemble: trained with optimized parameters “eta” and “max depth” \r\n- Gradient Boosted Trees: trained with optimized parameter “Number of trees” \r\n- Random Forest: trained with optimized parameters “Tree Depth”, “Number of models” and “Minimum child node size” \r\n- Deep Learning (Keras): trained with KNIME Deep Learning - Keras Integration with no parameter optimization and a simple architecture for regression determined with a few simple heuristics. \r\n- H2O AutoML: trained with the KNIME H2O Machine Learning Integration and uses the H2O AutoML to train a group of models and select the best one \r\n\r\nMODEL SCORING AND SELECTION: \r\nAfter the training of the specified models is completed and all models are stored in a single table, the system applies the model to the test set. The predictions of all models are scored against the ground truth and several performance metrics are computed. The best model is selected using the performance metric specified by the user. \r\n\r\nDEPLOYMENT WORKFLOW: \r\nThe data pre-processing, the best model and the data post-processing are captured via the KNIME Integrated Deployment Extension. The end-to-end encapsulated workflow is provided at the output of the Component and it can be used to score raw new data in deployment. Connect to the Workflow Writer node or the Workflow Executor node to reuse the trained model wherever needed. \r\n\r\nAUTOML OUTPUT METADATA: \r\nThe Component additionally outputs flow variables for advanced users. \r\n- \"metric_auto\" (String) : the name of the user-defined performance metric. \r\n- \"target_column\" (String) : the name of the user-defined target column. \r\n- \"exported_model\" (String) : the best model that was selected. \r\n- \"exported_model_params” (String Array) : list of the optimized parameters names and values for the exported model. \r\n- \"trained_models\" (String Array) : list of all the selected models that were successfully trained and ranked by \"metric_auto\" metric. \r\n- \"trained_metrics\" (Double Array) : list of the \"metric_auto\" metrics for all “trained_models”. \r\n- \"failed_models\" (String Array) : list of all selected models failed during training or testing. \r\n- \"extreme_preds_models\" (String Array) : models that had at least one prediction out of range are additionally listed here when the “Remove Extreme Predictions” setting is on. ",
      "name": "AutoML (Regression)",
      "id": "*7WfOM_MOjUE2Q2Ti",
      "type": "Learner",
      "inPorts": [
        {
          "description": "A KNIME Table with data rows with input features and ground truth.",
          "name": "Data to Train and Test Models",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "The best trained model stored in a Workflow Object port of KNIME Integrated Deployment Extension. Connect this output port to either the Workflow Writer or Workflow Executor node.",
          "name": "Trained Model",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Workflow Port Object"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoBYwMTFxMDIymgDEDdiwsbHxfAMDAwGcBgAVJRgaGsrjkZ8AlF+A0xBCBgBd2A/UbAB0yXqshsAMgHoFxfkgeaAmkHgCEBeAaJwGGEBAAhJGsQ3IVyBkgICFhYUCDJNsAC4vkG0ASANJBmBIoIFRA/AYAEyiAbgyEhqeAIopQhYRDQAHAltSvpTuDAAAAABJRU5ErkJggg==",
      "description": "The Document Similarity Predictor applies the model obtained by the Document Similarity Learner to a test document. It computes the cosine similarity between the original corpus of documents table and the test document. ",
      "name": "Document Similarity Predictor",
      "id": "*4HCCQ315cj13Etyu",
      "type": "Source",
      "inPorts": [
        {
          "description": "An input table containing the original corpus with the related document vectors.",
          "name": "Corpus of Documents",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "A model containing node settings as well as column names of the term feature space.",
          "name": "Document Vector Model",
          "optional": false,
          "color": "#9b9b9b",
          "portTypeName": "DocumentVectorPortObject"
        },
        {
          "description": "An input table containing the new test document. ",
          "name": "Test Document",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "A table containing the selected similar documents",
          "name": "Selected Similar Documents",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "A single variable set to the count of matching documents per input document",
          "name": "Count of Most Similar Documents per Input Document",
          "optional": false,
          "color": "#ff4b4b",
          "portTypeName": "Flow Variable"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoDYwMDBwMDIyaoBhID+AaM1ADQUmJiYOQE0CMDEQ39jYeD1QTIGgZlyKQAYaGhouwOdsA6ABCfgsABkOsgSX7Q14nUdI3cAbAAppEManGW8YQE2fgBx92GzHG5UgSWzxDTIUpBkUjfgsQLYpATklQtOHACwtEGUIHlcOIkMIxRrRAABplTOgJ4UUigAAAABJRU5ErkJggg==",
      "description": "This is an implementation of the model explanation technique developed by H2O.ai called K-LIME using the KNIME H2O Machine Learning Integration. To find more informations about the K-LIME machine learning interpretability technique please refer to the H2O.ai documentation:\r\n\r\nh2o.ai/wp-content/uploads/2017/09/driverlessai/interpreting.html#k-lime\r\n\r\nThe component allows to cluster input data and build local linear models to explain predictions of a complex black-box-like model. The optimal number of clusters is defined by the optimal value of R^2 value summed over all models in clusters. The number of linear models built is much lower than the corresponding number in the LIME algorithm, where a model is build in the neighbourhoud of each explanation instance. Thus, the algorithm is expected to be faster for large data samples.\r\n\r\nNote, that this implementation of K-LIME can not handle missing values and all rows with missing values will be dropped. Thus, no explanations for those will be available. If you want to get explanations for all input rows, please, fill missing values before fedding the data into the app.\r\nAlso note, that all but the selected column with predictions will be used to interpret prediction. Therefore, you have to filter out all irrelevant columns as well as the original target column prioir to feeding a table to the input.\r\n\r\nCategorical features will be converted into numerical representation using One-Hot Encoding (OHE) (also called \"dummy\" or \"binary\"). Numerical features will be scaled as required by linear models. The only pre-processing steps that might be required from the user is to remove outliers and fill missing values, as those might bias surrogate models that are used by the algorithm.",
      "name": "K-means LIME",
      "id": "*EyBAgtSLjhNMIUhv",
      "type": "Learner",
      "inPorts": [
        {
          "description": "Table with features and predictions.",
          "name": "Input data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Original and surrogate predictions as well as individual feature contributions.",
          "name": "Predictions and feature contributions",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Cluster and global prediction per input row.",
          "name": "Surrogate predictions",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAlElEQVR4nGNgoAUwMDAQMDIyKgDiBiguAIopEKUZpNjExKQBZAi6gcbGxvmENCfgswkkh9MQoKQByAAiXJgAdKEDNokGQpqR1E6g1ABMtYPCAKLiGqQGZ2ADo2g+EbZjBiCy6UBDJoBoUOIxNDRcgJygiHIlSAMoJYL8CTRsAbKrkA0jCkCTtQNJmpBtA6VOsjSTAgCY9TAwIZkx9AAAAABJRU5ErkJggg==",
      "description": "This component creates interactive visualizations to provide insights about a selected aspect of a workflow and the flow of data within the workflow. It does so by utilizing the Workflow Summary exported as XML file which can be accessed via either the File > Export > Workflow Summary (JSON/XML)… menu in KNIME Analytics Platform, or from a KNIME Server's REST API. \r\n\r\nThe exported XML first needs to be analyzed by the verified component Extract Workflow Summary whose first output port contains a list of nodes in the workflow and their detailed properties. This component takes this data as input and performs network analysis of the workflow in question and creates different visualizations as a network in which interesting bits and pieces are highlighted. Currently only top level nodes and components are taken under consideration.\r\n",
      "name": "Data Lineage View",
      "id": "*ZQPYBXfo_4PTNm-I",
      "type": "Learner",
      "inPorts": [
        {
          "description": "Data Table coming from the first output port of the verified component Extract Workflow Summary. It Contains a list of nodes and their details extracted from a workflow summary XML.",
          "name": "Node Details Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoBYwMTFxMDIymgDEDdiwsbHxfAMDAwGcBgAVJRgaGsrjkZ8AlF+A0xBCBgBd2A/UbAB0yXqshsAMgHoFxfkgeaAmkHgCEBeAaJwGGEBAAhJGsQ3IVyBkgICFhYUCDJNsAC4vkG0ASANJBmBIoIFRA/AYAEyiAbgyEhqeAIopQhYRDQAHAltSvpTuDAAAAABJRU5ErkJggg==",
      "description": "This component allows you to query the News API (newsapi.org) in order to return the list of news sources (e.g. TechCrunch) currently registered with the News API.\r\n\r\nThe component can be used to get detailed information about sources from the News API and map articles from other News API components to the source list.\r\n\r\nPlease notice that a valid API Key for the News API is required.\r\n\r\nAlso notice that this component works best together with the other News API components available on the KNIME Hub in the Verified Components repository for Text Processing (hub.knime.com/knime/spaces/Examples/latest/00_Components/Text%20Processing).\r\n\r\nSee newsapi.org/docs for additional documentation for the News API.",
      "name": "News API Sources",
      "id": "*LC2hI1_Nw8K4E0c9",
      "type": "Source",
      "inPorts": [],
      "outPorts": [
        {
          "description": "Sources registered with the News API.",
          "name": "Sources",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAsklEQVR4nGNgoBUwMDBwMDIyakDGIDFiNAqAFJuYmGAoBoonAPEEoBoFilwHNLyeaEMMIEABTUzA2Nh4PooA0Gn12JwN8jc2cZAYWBxoUgBQcwGQnoBiKgEDYGEFF4CGsgIooIgxAKYHOweLTegGE20AkkEGQC+uRzNgApwDDxQiAchFGOpRTMTvGlA0YqqFBmIBIc2wAMelQAFo+n5s6R4kBrKZqFQITR8omYmUMCIaAAD0RELelYkiBgAAAABJRU5ErkJggg==",
      "description": "This component copies column values from preceding rows into the current row in a Spark DataFrame/RDD. The component can be used to\r\n\r\n- make a copy of the selected column and shift the cells I steps up (I = lag interval)\r\n- make L copies of the selected column and shift the cells of each copy I, 2I, 3I, ... L*I steps up (L = lag)\r\n\r\nRequired extensions: \r\nKNIME Data Generation\r\n(https://hub.knime.com/knime/extensions/org.knime.features.datageneration/latest)\r\nKNIME Extension for Apache Spark\r\n(https://hub.knime.com/knime/extensions/org.knime.features.bigdata.spark/latest)\r\nKNIME Quick Forms\r\n(https://hub.knime.com/knime/extensions/org.knime.features.js.quickforms/latest)",
      "name": "Spark Lag Column",
      "id": "*Bv4TULUXFoZkGOvS",
      "type": "Sink",
      "inPorts": [
        {
          "description": "Spark DataFrame containing at least the value column and a numeric or timestamp column for sorting purpose.",
          "name": "Spark Input data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Spark Data"
        }
      ],
      "outPorts": [
        {
          "description": "Spark DataFrame with input data and additional columns copying the values from preceding rows. ",
          "name": "Lag input table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Spark Data"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAShJREFUOI2lk8ttwzAQRB9JFaAS1EEWKxjwzXIHKUGpIC4hJaiEpIK4BB0NWCKUDlSCKyBzMGUYiSUbyZwILOftLD/wTxkAVX37WQghNMMwnO4Bsmnhvb9ARCR3zjWqOi6ZL55bCVarlahqPWeePNnchuPxOKhqpaoN8GsUY8xmEZAiNn9OcK2yLJ9jjAJgrW27rmun2iJARAprbQ1svPdbESmA6nrPvQSFtbYNISAitbU2N8aMs4DUccf50MYQwgjn61qv1wXA4XCYB6SO+67r2rIsP51zJ+DjlnEOcIoxvqpqFWP8CiG0WbY8ZQZgjClUtfbevwMvVyNVAKq6A3IgN8a0qZxD+gtzEpHCObcDnvq+36YzqlIj7gImpSddTAn6vt8/4ntI38/oaqnXds3PAAAAAElFTkSuQmCC",
      "description": "This component generates example data for a multilabel classification task based on the make_multilabel_classification() function in the Python scikit-learn library.\nIt generates class columns with 0s/1s that indicate the absence/presence of the respective label. The average number of labels assigned to each row can be regulated. \n\nFor more information see the sklearn documentation:\n\nscikit-learn.org/stable/modules/generated/sklearn.datasets.make_multilabel_classification.html\n\nNote: This component requires a Python environment. In this blog post we explain how to setup the KNIME Python extension:\n\nknime.com/blog/setting-up-the-knime-python-extension-revisited-for-python-30-and-20\n",
      "name": "Synthetic Data Generator (Multilabel Classification)",
      "id": "*fRTHxJQF8GPTiTBV",
      "type": "Manipulator",
      "inPorts": [],
      "outPorts": [
        {
          "description": "Multi-class Classification Data",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAuklEQVR4nKVT2w3DMAjMCB7BIyA//j1CRvAI3aDeoNmgHTWQYAlFAbvtSZYicxxnIMtiAACcFR8CBUpKqfwjADlnmCU7rNZGvBBCQ67XRHw/KPYiMp9nL6ImSxFMeFzvYozvqadQxbt7aibG6s8Caowttz4u/N5GAuzmvpmaAy5UDfMnaO696yLZTTeRXVRMWKWr4fgE8dh/qggnfO+LuWzXJUGBD7lgN5vg+W/cEIo1WhW8fYcD67feARH/PpXMRyZ9AAAAAElFTkSuQmCC",
      "description": "This Component generates a view by comparing the performance of two models captured by Integrated Deployment. The Component displays the performance of a new model starting from the date chosen by the user in the configuration dialogue, while the performance of the original model is displayed for all the dates in the input data. In a deployment scenario, this component compares the performance of the previous deployed model with the recently retrained model given the chosen evaluation metric.\r\n\r\nThe view works for machine learning classifiers for binary as well as multiclass targets.  The Component requires the deployment data with timestamps (dates) and target columns in order to showcase the performance over time. \r\n\r\nIn the Interactive View generated, the performance metric is plotted with respect to the time axis, and further, a trend line is plotted based on this performance of each model.  A “Deploy” button has been provided in the view. Based on the model performance the user can decide if deployment is necessary of the model provided in the second input port. This deployment decision is given at the output of the component via a flow variable. Connect the flow variable output to the workflow branch which deploys the model. Such a branch should execute only if the user checked the box in the view and applied its settings (Apply&Close lower right corner).\r\n\r\nCAPTURED MODEL REQUIREMENTS (Top and Middle Port)\r\nWe recommend using the \"AutoML\" components with this component. All you need is connect the two components via the black integrated deployment port. \r\n \r\nYou can also monitor customly trained models with this component. When providing models not trained by the “AutoML” components, you need to satisfy the below black box requirements:\r\n\r\n- The models should be captured with Integrated Deployment and have a single input and single output of type Data.\r\n\r\n- All features columns have to be provided at the model input.\r\n\r\n- Any other additional columns that are not features can be provided at the model input.\r\n\r\n- The model output should store all the model input data (features and non-features) and present attached the output predictions columns.\r\n\r\n- The model output predictions should be one String type and “n” Double type, where “n” is the number of classes in the target column.\r\n\r\n- The String type prediction column should be named “Prediction([T])” where [T] is the name of your target class (e.g. “Prediction (Churn)”).\r\n\r\n- The Double type prediction columns should be named “P ([T]=[C1])”, “P ([T]=[C2])”, …, “P (T=[Cn])”, where [Cn] is the name of the class that probability is predicting (e.g. “P (Churn=not churned)” and ”P (Churn=churned)” in the binary case).\r\n\r\nAdditionally, if you are not using the AutoML component, you need to provide a flow variable called “target_column” of type String with the name of your ground truth/target column in the model ports of the “Model Monitor View (Compare)“ Component.\r\n\r\n\r\nINPUT DEPLOYMENT TABLE REQUIREMENTS (Bottom Port)\r\n- All features columns that were used in the training of the captured models\r\n- Availability of target column and timestamp column. Each record timestamp tracks the date in which the currently deployed model (first input) was applied on that data row. The timestamp should be of “Date&Time” column Types. “Time” and “String” types are not supported. Use the “String to Date&Time” node. The timestamp column should be uniformly distributed across the sample: time ranges in between dates where samples are missing should be somewhat constant.",
      "name": "Model Monitor View (Compare)",
      "id": "*YYmlgxnGr_xR7E33",
      "type": "Learner",
      "inPorts": [
        {
          "description": "The currently deployed model captured with Integrated Deployment.",
          "name": "First Model",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Workflow Port Object"
        },
        {
          "description": "The new model, also captured with the Integrated Deployment, to be compared with the original, and optionally deployed.",
          "name": "Second Model",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Workflow Port Object"
        },
        {
          "description": "Deployment data with target/ground truth and timestamp:\r\n\r\n- A table of instances gathered after the deployment where the currently deployed model (first input) was previously applied.\r\n- The collected afterwards ground truth (also called target) column should also be available. \r\n- The timestamp needs to be already converted to either &#34;Date&amp;Time&#34; Column Type or similar as long as it has a date and it is not String Column Type.",
          "name": "Deployment data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Flow variable to activate downstream workflow branch for deployment update.",
          "name": "Scored deployment data",
          "optional": false,
          "color": "#ff4b4b",
          "portTypeName": "Flow Variable"
        }
      ]
    },
    {
      "description": "Image preprocessing for VGG neural network.\n\nThe node expects a flow variable \"currentColumnName\" to define the column, which has to be preprocessed.\n\nMimic \"preprocess_input\" from\nhttps://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py",
      "name": "Image preprocessing for VGG",
      "id": "*I5gzCZ4-YB5kUBKh",
      "type": "Other",
      "inPorts": [
        {
          "description": "Input data table",
          "name": "Input data table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Output table with one column of images preprocessed according to VGG requirements",
          "name": "Output data table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAf0lEQVR4nGNgGJTAwMBAgCIDjI2N5xsaGsqTbYCRkdEEIC4gSzPQ+Q4mJiYOIFeQa3sDiAYZAsLIckD+eaINAAUkjA1zGdBV6/GGDcz56IbB2FBDMcMGpAmkAFkDujdgciADQGx07+H1ErrLSAJQl00gSzMIUBSlMEBx0qYpAAAehidos81u4QAAAABJRU5ErkJggg==",
      "description": "This component allows you to select a subset of molecules based on the input data and molecular properties calculated using the RDKit Descriptor Calculation node. The Interactive View depicts the molecular properties in a parallel coordinates plot, and the molecules' structural formula as tiles. The selected molecules are provided in the component output. Note that columns from the input table will be by default propagated to the parallel ccordinates plot. ",
      "name": "Molecular Properties Filter",
      "id": "*OFU_uOSJcOtr12-M",
      "type": "Other",
      "inPorts": [
        {
          "description": "Data input, needs to contain a molecule column (SMILES, SDF, etc.)",
          "name": "0",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Rows selected in the Interactive View",
          "name": "0",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Rows not selected in the Interactive View",
          "name": "1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAL9JREFUOI3NksENwjAMRe3f3mEDRsC1MkBGgBHYpBswAxswQgaoREZgBLi3SS8NClUrSg+Id3Til28rRH+JiGyX3sVUsSiKc1VVu9WCGOOTmY+rBCJiAVyZeb9KAMA2TeOY+WKMsfmZMeb2UZBo29aHEF4CEbExxvt4N2+CIb4jIvLeP8bJuq47jXeDIZpV1TrFz5pcPkaSqmqd6jw3QkJV6xCCK8uScvnkCHMAOEw1LxIAcMy8WfLQLN987d/TA7LzPNQeMwIBAAAAAElFTkSuQmCC",
      "description": "The component can be used to visualize molecular data using the JavaScript library 3Dmol.js (https://3dmol.csb.pitt.edu/index.html). \nThe required input data types are either PDB, SDF or Molfile. \n\nThe view provides the following options for the user to select:\n- atom styles (e.g. Stick, Line, Cross, Sphere and for PDB data types also Cartoon)\n- show heteroatoms for PDB data and select heteroatom style (Stick, Line, Cross and Sphere)\n\nIf the component is used alone, simple paging through the rows of the input table is possible by unchecking the \"subscribe to selection\" box. If combined in a component with another KNIME JavaScript View, e.g. the Table View, the 3D Molecule Viewer component will visualize selected rows from the Table View if the \"subscribe to selection\" box is checked.\n",
      "name": "3D Molecule Viewer",
      "id": "*sVeWadW5ysuLa7dX",
      "type": "Other",
      "inPorts": [
        {
          "description": "data table containing PDB, SDF or Molfile column types",
          "name": "data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAsklEQVR4nGNgoBUwMDBwMDIyakDGIDFiNAqAFJuYmGAoBoonAPEEoBoFilwHNLyeaEMMIEABTUzA2Nh4PooA0Gn12JwN8jc2cZAYWBxoUgBQcwGQnoBiKgEDYGEFF4CGsgIooIgxAKYHOweLTegGE20AkkEGQC+uRzNgApwDDxQiAchFGOpRTMTvGlA0YqqFBmIBIc2wAMelQAFo+n5s6R4kBrKZqFQITR8omYmUMCIaAAD0RELelYkiBgAAAABJRU5ErkJggg==",
      "description": "Trains an AutoRegressive Integrated Moving Average (ARIMA) model. ARIMA model captures temporal structures in time series data in the following components:\r\n- AR: Relationship between the current observation and a number (p) of lagged observations \r\n- I: Degree (d) of differencing required to make the time series stationary\r\n- MA: Time series mean and the relationship between the current forecast error and a number (q) of lagged forecast errors\r\n\r\nAdditionally, coefficent statistics and residuals are provided as table outputs.\r\n\r\nModel Summary metrics:\r\nRMSE (Root Mean Square Error)\r\nMAE (Mean Absolute Error)\r\nMAPE (Mean Absolute Percentage Error)\r\n*will be missing if zeroes in target\r\nR2 (Coefficient of Determination)\r\nLog Likelihood\r\nAIC (Akaike Information Criterion)\r\nBIC (Bayesian Information Criterion)\r\n\r\nIf you encoutner errors please verify that \nPreferances > KNIME > Python (labs) > Python environment configuration\nis set to bundled",
      "name": "ARIMA Learner",
      "id": "*mfpi0uzbMwWO1jE9",
      "type": "Sink",
      "inPorts": [
        {
          "description": "Table containing numeric target column to fit the ARIMA model.",
          "name": "Input data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "ARIMA model",
          "name": "ARIMA Model",
          "optional": false,
          "color": "#1eb9dc",
          "portTypeName": "Python"
        },
        {
          "description": "Table containing the coefficient statistics and the following evaluation metrics of the ARIMA model:\r\nRMSE\r\nMAE\r\nMAPE\r\nR2\r\nLog Likelihood\r\nAIC\r\nBIC",
          "name": "ARIMA Model Summary",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Table containing the residuals",
          "name": "Residuals",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAsklEQVR4nGNgoBUwMDBwMDIyakDGIDFiNAqAFJuYmGAoBoonAPEEoBoFilwHNLyeaEMMIEABTUzA2Nh4PooA0Gn12JwN8jc2cZAYWBxoUgBQcwGQnoBiKgEDYGEFF4CGsgIooIgxAKYHOweLTegGE20AkkEGQC+uRzNgApwDDxQiAchFGOpRTMTvGlA0YqqFBmIBIc2wAMelQAFo+n5s6R4kBrKZqFQITR8omYmUMCIaAAD0RELelYkiBgAAAABJRU5ErkJggg==",
      "description": "Computes predictions from an estimated AutoRegressive Integrated Moving Average (ARIMA) model. \r\n\r\nTwo types of predictions are computed:\r\n1. Forecast: forecast of the given time series h periods ahead.\r\n2. In-Sample Prediction: generates prediction in the range of the training data.\r\n\t* If Dynamic is enabled lagged predictions are used, otherwise lagged true values are used.\r\n\t* Level setting determines whether in-sample differenced or original values are output. If no differencing in ARIMA model, this setting has no effect.\r\n\r\nIf you encoutner errors please verify that \nPreferances > KNIME > Python (labs) > Python environment configuration\nis set to bundled",
      "name": "ARIMA Predictor",
      "id": "*YxgcRs9Q_fPnUliz",
      "type": "Sink",
      "inPorts": [
        {
          "description": "ARIMA Model.",
          "name": "ARIMA Model",
          "optional": false,
          "color": "#1eb9dc",
          "portTypeName": "Python"
        }
      ],
      "outPorts": [
        {
          "description": "Forecasted values and their standard errors.",
          "name": "Forecast",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Model predictions on data points in the training data. \r\nCaclulated according to Level and Type configurations.",
          "name": "In-Sample Predictions",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAL9JREFUOI3NksENwjAMRe3f3mEDRsC1MkBGgBHYpBswAxswQgaoREZgBLi3SS8NClUrSg+Id3Til28rRH+JiGyX3sVUsSiKc1VVu9WCGOOTmY+rBCJiAVyZeb9KAMA2TeOY+WKMsfmZMeb2UZBo29aHEF4CEbExxvt4N2+CIb4jIvLeP8bJuq47jXeDIZpV1TrFz5pcPkaSqmqd6jw3QkJV6xCCK8uScvnkCHMAOEw1LxIAcMy8WfLQLN987d/TA7LzPNQeMwIBAAAAAElFTkSuQmCC",
      "description": "This component determines the effect of genetic variants using Ensembl's Variant Effect Predictor (VEP) via their REST API (https://rest.ensembl.org/#VEP). \nThe output table contains the most severe predicted effect of the variant and the associated gene symbol. In addition, the minor allele frequency from the 1000 genomes project, frequency information from the Genome Aggregation Database (gnomAD), and the SIFT score are extracted (if available). The SIFT Score indicates whether an amino acid substitution affects protein function (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC168916/), it ranges from 0 to 1, with low scores indicating a damaging effect. Those effects are calculated per transcript, therefore transcript information (Ensembl ID) is included as well.\nIn the interactive view the user can filter variants by minor allele frequencies and SIFT score and select variants of interest. If nothing is selected all data will be available at the output port. The view also contains an explanatory image of the variant consequences taken from http://www.ensembl.info/2012/08/06/variation-consequences/.",
      "name": "Variant Effect Predictor",
      "id": "*VN1bA3lrB1zRfKCH",
      "type": "Other",
      "inPorts": [
        {
          "description": "Input table with variants.",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Output table containing the most severe consequence of the variant, variant frequencies from the 1000 genomes project and gnomAD, and the SIFT score.",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "name": "Details for Group",
      "id": "*ZMYHcTHn08XKgh0v",
      "type": "Other",
      "inPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "name": "Port 2",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "name": "Port 3",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "name": "Port 2",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAcElEQVR4nGNgoDUwMDAQMDEx6TcyMmoA4gJyDFAAakwAsUGGDFIDQH6D+hHDn2gGTICqmWBsbByAbEADNjYuFyCLYWgCmrwfxAfS88kyAMbGpniYG5AAi0Zg4K2H0TDFoABFlsOIRooBUiIiCVPFcgAwM2Hob2VycwAAAABJRU5ErkJggg==",
      "description": "This component generates a view to explore processes. A vertical flowchart and range slider are rendered in the composite view. \r\n\r\nUsing the slider you can filter out activities that occur up to the selected relative frequency, that is the percentage of how often that trace occurs over all other possible traces. To filter processes based on a timestamp or other metrics, consider building a custom workflow before this component. \r\n\r\nHow to interpret the flowchart:\r\n\r\n- Each node represents the process/trace state. Links between process states represent the transaction from the state above to the one below. \r\n\r\n- The transaction between states maps to an activity that has been carried out in the process. \r\n\r\n- The number on the links represent the number of processes/traces that went through that transaction between states. \r\n\r\n- The nodes S and E are added to each process and represent the start and end of the process, respectively. \r\n\r\n- The number on the nodes, between brackets “<” and “>”, represents the number of processes that include such a state. \r\n\r\n- The color of the node, from light yellow to dark orange, depends on the displayed number: the higher the number the darker the color.\r\n\r\nThe flowchart was implemented using the JavaScript library “mermaid.js” (github.com/mermaid-js/mermaid), MIT License (MIT), Copyright (c) 2014 - 2022 Knut Sveidqvist.\r\n",
      "name": "Process Mining View",
      "id": "*AirSH3LGfvq2W7td",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "Event Data refers to a data table containing the log information of a specific process. Each row represents a specific activity that has been carried out in a specific time by a case.",
          "name": "Event Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAcElEQVR4nGNgoDUwMDAQMDEx6TcyMmoA4gJyDFAAakwAsUGGDFIDQH6D+hHDn2gGTICqmWBsbByAbEADNjYuFyCLYWgCmrwfxAfS88kyAMbGpniYG5AAi0Zg4K2H0TDFoABFlsOIRooBUiIiCVPFcgAwM2Hob2VycwAAAABJRU5ErkJggg==",
      "description": "This component performs hierarchical clustering on numeric input data. The results are displayed in a composite interactive view containing a dendrogram and a heatmap. The rows of the heatmap are sorted by the associated clusters. The dendrogram view can be used to change the number of clusters.\r\n\r\nRequired extensions: \r\nKNIME JavaScript Views (Labs) \r\nhttps://hub.knime.com/knime/extensions/org.knime.features.js.views.labs/latest",
      "name": "Hierarchical Clustering and Heatmap",
      "id": "*_A422zmPjDkRGM30",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "Input table with numeric columns that are used to calculate the distances for the clustering. Row names will be used for the x-axis of the dendrogram. Row- and column names will be displayed in the heatmap accordingly.",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Input table with column containing associated cluster names",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAA3klEQVR4nL2S/Q2CQAzFGYERHOECx/+MwAhuABvIBt4GjuAIjuAIrGJ/5koewQ80xiYNba/v3fXRovilhRB2G7x8Cq7r+mreV1W1xy0+m188Nx/paZomrAhohj3GOGbCNoMGq7XUIOAi+6YFmCYOiGkmp9nPrXZUInotPujtEwDxyWpJ8sTTtQfMrIey+ys0ZxzNDdxZPizGoOBjwAypjDjPnDVYgoX55M9SDTx+KKAaYEhE2FJfoxe8IrkrbN+Qd6Hz2Ed8a/ors+K9irjJIGALWTBfro+NXcC/Av/NbnifZmUzsd9GAAAAAElFTkSuQmCC",
      "description": "Calculates k-period simple return series from one-period simple return series using the following formula:\r\nR(k) = (1+R_t)*(1+R_(t-1))*...*(1+R_(t-k+1)) - 1\r\n\r\nMissing values in the one-period return series are treated as zeros.\r\n\r\nRequired extensions: \r\n- KNIME Math Expression (JEP) (https://hub.knime.com/knime/extensions/org.knime.features.ext.jep/latest)\r\n- KNIME Quick Forms (https://hub.knime.com/knime/extensions/org.knime.features.js.quickforms/latest)",
      "name": "One-period returns to multi-period returns",
      "id": "*fJZa0ehH2nf9g7nF",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "One or more numeric columns. Each selected column is interpreted as single period simple return series.",
          "name": "One-period return series",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "k-period simple return series calculated using the one-period simple return series and window length k that are provided in the input.",
          "name": "k-period simple return series",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoBYwMTFxMDIymgDEDdiwsbHxfAMDAwGcBgAVJRgaGsrjkZ8AlF+A0xBCBgBd2A/UbAB0yXqshsAMgHoFxfkgeaAmkHgCEBeAaJwGGEBAAhJGsQ3IVyBkgICFhYUCDJNsAC4vkG0ASANJBmBIoIFRA/AYAEyiAbgyEhqeAIopQhYRDQAHAltSvpTuDAAAAABJRU5ErkJggg==",
      "description": "This component allows you to query the News API (newsapi.org) in order to return news articles for specific search terms and parameters.\r\n\r\nThe component can be used for finding articles related to a specific topic, company, or combination of search terms. The results can be used for text analysis models, business applications, and web scraping projects.\r\n\r\nPlease notice that a valid API Key for the News API is required.\r\n\r\nAlso notice that this component works best together with the other News API components available on the KNIME Hub in the Verified Components repository for Text Processing (hub.knime.com/knime/spaces/Examples/latest/00_Components/Text%20Processing).\r\n\r\nSee newsapi.org/docs for additional documentation for the News API.",
      "name": "News API Advanced Search",
      "id": "*_abUmSh8bmjc68dE",
      "type": "Source",
      "inPorts": [],
      "outPorts": [
        {
          "description": "Search results from the News API.",
          "name": "Search Results",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoDYwMDBwMDIyaoBhID+AaM1ADQUmJiYOQE0CMDEQ39jYeD1QTIGgZlyKQAYaGhouwOdsA6ABCfgsABkOsgSX7Q14nUdI3cAbAAppEManGW8YQE2fgBx92GzHG5UgSWzxDTIUpBkUjfgsQLYpATklQtOHACwtEGUIHlcOIkMIxRrRAABplTOgJ4UUigAAAABJRU5ErkJggg==",
      "description": "This Component is required to sample the data to be visualized in the Partial Dependence/ICE Plot (JavaScript) node.\r\n\r\nYou can select only numerical features of Double Type feature columns. \r\n\r\nThe Component will create for you the desired number of samples for each selected feature and for each instance row. The linear sampling technique will range between the lower and upper bound found in the input Table Spec. You can use Edit Numeric Domain node to customize the Table Spec bounds and the resulting sampling performed by the component.",
      "name": "Partial Dependence Pre-processing",
      "id": "*4Zz2dN58yqbCrff4",
      "type": "Learner",
      "inPorts": [
        {
          "description": "A table with rows from your test/validation set. Make sure to include all the feature columns of your model. Also the categorical columns (String type) should be in this table if you have any.",
          "name": "Test/Validation set Rows",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "A table containing in each row a different sample relative to a test/validation set row where only a single feature was changed.\r\n \r\nFor each different row in the input table we sampled the desired number of samples for each selected numerical feature column. In fact the size of this table is: \r\n\r\n(number of samples) X (number of selected feature columns) X (number of rows in input table)",
          "name": "Samples Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAA3klEQVR4nL2S/Q2CQAzFGYERHOECx/+MwAhuABvIBt4GjuAIjuAIrGJ/5koewQ80xiYNba/v3fXRovilhRB2G7x8Cq7r+mreV1W1xy0+m188Nx/paZomrAhohj3GOGbCNoMGq7XUIOAi+6YFmCYOiGkmp9nPrXZUInotPujtEwDxyWpJ8sTTtQfMrIey+ys0ZxzNDdxZPizGoOBjwAypjDjPnDVYgoX55M9SDTx+KKAaYEhE2FJfoxe8IrkrbN+Qd6Hz2Ed8a/ors+K9irjJIGALWTBfro+NXcC/Av/NbnifZmUzsd9GAAAAAElFTkSuQmCC",
      "description": "This component helps to analyze the overdue invoices. It calculates:\r\n1. the due date of an invoice\r\n2. number of days till the due date from today (or any other selected date)\r\n3. the due status of the invoice as defined by the following categories:\r\n\t• Paid\r\n\t• Pending\r\n\t• Due during next 30 days\r\n\t• 1-30 Days overdue\r\n\t• 30-45 Days overdue\r\n\t• 45-60 Days overdue\r\n\t• 60-90 Days overdue\r\n\t• 90+ Days overdue",
      "name": "Overdue Invoices Status",
      "id": "*dvcU8G61H5FlMoEE",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "Input table containing the issue date and payment terms columns and optionally a payment date column",
          "name": "0",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Output table containing the original table and the appended Planned date of payment, Due from today, and Due status columns",
          "name": "Output table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAtUlEQVR4nK2S3Q3DIAyEM0JHYASLH4lHRsgIjJAROgIbtBt0hK4Wn2QkCwEFqSf5wST+zjo4jn/IWvtsi4geWwDdY9g59+6BdQ0BUAiB+DwvmfYAcn5xlZ47b/j9CZhpaYMqdjurs/c+LQM4TKPXlT7vABIc5VozMsE2Q4A41NByBeBbjNGgphnoAXb6cL1q32oEIAyp15iWAPLq8iSDS6AFGUiVHrgFGPzYu4UtYUhvsA2Y6QaZe2IxLfqnMAAAAABJRU5ErkJggg==",
      "description": "This component implements quantile normalization, which is a technique to make two distributions identical in statistical properties. See https://en.wikipedia.org/wiki/Quantile_normalization for further information.\r\nOnly numeric columns are used. There should be at least 1 numeric (interget, long, double types) column selected.\r\nAll non-numeric columns as well as not selected numeric columns are kept in the output table.",
      "name": "Quantile Normalization",
      "id": "*4_jxdHVZ4hkXbia7",
      "type": "Manipulator",
      "inPorts": [
        {
          "description": "Input table with at least one numeric column",
          "name": "Input table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Table with numeric columns having similar statistical properties.",
          "name": "Output table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAsklEQVR4nGNgoBUwMDBwMDIyakDGIDFiNAqAFJuYmGAoBoonAPEEoBoFilwHNLyeaEMMIEABTUzA2Nh4PooA0Gn12JwN8jc2cZAYWBxoUgBQcwGQnoBiKgEDYGEFF4CGsgIooIgxAKYHOweLTegGE20AkkEGQC+uRzNgApwDDxQiAchFGOpRTMTvGlA0YqqFBmIBIc2wAMelQAFo+n5s6R4kBrKZqFQITR8omYmUMCIaAAD0RELelYkiBgAAAABJRU5ErkJggg==",
      "description": "This component analyzes the residuals of an ARIMA (AutoRegressive Integrated Moving Average) model by \r\n1. visualizing auto correlation of the residuals\r\n2. performing Ljung-Box test of autocorrelation at lags 1-10\r\n3. visualizing residuals in a line plot\r\n4. calculating the four first central moments of the residuals\r\n5. performing Jarque-Bera test of normality\r\n\r\nIf you encoutner errors please verify that \nPreferances > KNIME > Python (labs) > Python environment configuration\nis set to bundled",
      "name": "Analyze ARIMA Residuals",
      "id": "*065p0UloLWV3g8Ta",
      "type": "Sink",
      "inPorts": [
        {
          "description": "ARIMA model",
          "name": "ARIMA Model",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAtUlEQVR4nK2S3Q3DIAyEM0JHYASLH4lHRsgIjJAROgIbtBt0hK4Wn2QkCwEFqSf5wST+zjo4jn/IWvtsi4geWwDdY9g59+6BdQ0BUAiB+DwvmfYAcn5xlZ47b/j9CZhpaYMqdjurs/c+LQM4TKPXlT7vABIc5VozMsE2Q4A41NByBeBbjNGgphnoAXb6cL1q32oEIAyp15iWAPLq8iSDS6AFGUiVHrgFGPzYu4UtYUhvsA2Y6QaZe2IxLfqnMAAAAABJRU5ErkJggg==",
      "description": "This component allows to filter columns and rename column names of a dataset. The workflow processes automatically all columns and shows them in the output port if nothing has been selected.\r\nSelected column names will be excluded from the dataset.\r\nThe column names can be changed directly in the table view.\r\n\r\nAll this can be done using the interactive view of the component or as part of a workflow in the Web Portal.",
      "name": "Column Name Editor",
      "id": "*gJMJHjHgF3HfAYk5",
      "type": "Manipulator",
      "inPorts": [
        {
          "description": "Data table",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Data table with edited columns and column names.",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAA3klEQVR4nL2S/Q2CQAzFGYERHOECx/+MwAhuABvIBt4GjuAIjuAIrGJ/5koewQ80xiYNba/v3fXRovilhRB2G7x8Cq7r+mreV1W1xy0+m188Nx/paZomrAhohj3GOGbCNoMGq7XUIOAi+6YFmCYOiGkmp9nPrXZUInotPujtEwDxyWpJ8sTTtQfMrIey+ys0ZxzNDdxZPizGoOBjwAypjDjPnDVYgoX55M9SDTx+KKAaYEhE2FJfoxe8IrkrbN+Qd6Hz2Ed8a/ors+K9irjJIGALWTBfro+NXcC/Av/NbnifZmUzsd9GAAAAAElFTkSuQmCC",
      "description": "This component computes the XIRR (Extended Internal Rate of Return) just like in spreadsheet tools like Microsoft Excel and Google Sheet. Adopt this component to track the profitability of one or more investment projects with non-periodic transactions/cash flows.\r\n\r\nThe component adopts the Java library ‘java-xirr’ version 1.2 (MIT license). More info available at: github.com/RayDeCampo/java-xirr\r\n\r\nDISCLAIMER: To adopt this library the component downloads on its first execution in a new workflow from search.maven.org. Make sure your KNIME has internet access when executing the component in a new workflow for the first time.\r\n\r\nDISCLAIMER: The adopted library does not perform well with multiple negative cash flows.\r\n\r\nThe component calculates the internal rate of return for a schedule of cash flows that is not necessarily periodic. It starts from a series of cash flows and their date to approximate the value of XIRR for each of the defined portfolio/project that the cash flows are grouped by. Make sure that you have at least one column for the dates of the transactions in a date format, one column for the cash flows (for each portfolio/project the first transaction needs to be negative), and one column for the project/portfolio by which you want the transactions to be grouped by.\r\n\r\nMicrosoft Excel Docs: support.microsoft.com/en-us/office/xirr-function-de1242ec-6477-445b-b11b-a303ad9adc9d\r\n\r\nGoogle Sheets Docs: support.google.com/docs/answer/3093266\r\n\r\nThis component, verified by KNIME, was developed by finance analytics experts at Mydral, KNIME Partner of the Year 2022: mydral.com/en/knime-uk",
      "name": "Extended Internal Rate of Return (XIRR)",
      "id": "*LAO92Jxhr-L6WdQQ",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "A KNIME Table where each row represents a financial transaction. \r\nA column of type String is necessary to identify the financial project/portfolio. \r\nA column of type Double or Integer is necessary to identify the value of the financial transactions. \r\nA column of type Zoned/Local Date (Time) is necessary to identify the date of the transaction. ",
          "name": "Investments Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "A table is returned with a column for the name of the project/portfolio and a column for the XIRR value of each project.",
          "name": "XIRR",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAf0lEQVR4nGNgGJTAwMBAgCIDjI2N5xsaGsqTbYCRkdEEIC4gSzPQ+Q4mJiYOIFeQa3sDiAYZAsLIckD+eaINAAUkjA1zGdBV6/GGDcz56IbB2FBDMcMGpAmkAFkDujdgciADQGx07+H1ErrLSAJQl00gSzMIUBSlMEBx0qYpAAAehidos81u4QAAAABJRU5ErkJggg==",
      "description": "The Component uses IDs from several data sources to create an interactive pathway analysis based on the web service of Reactome.\nThe input for the pathway enrichment analysis can either be a column that can be selected from the input table or IDs that can be inserted directly in the component configuration.\nIf you use an input column and additionally paste IDs in the cofiguration window, the two input columns will be concatenated.\n\nAllowed identifier types are for example:\n\nUniProt identifiers: P30304\nChEBI identifiers: 15422\nCOMPOUND identifiers: C00002\nGene Ontology (GO) acession numbers: GO:0030060\nEnzyme Classification (EC) numbers: 1.1.1.37\nNCBI Gene: 4171\nProtein Data Bank (PDB) identifiers: 1cbs\nEnsembl identifiers: ENSG00000141736\n\nFor more information about available identifiers visit: \n\nhttps://reactome.org/linking-to-us\n\n\nIn the final view it is possible to select pathways in the bar chart and have it displayed in a table view. The selected pathways, associated genes, IDs and p-values will then serve as output for the component. If nothing is selected all found results will serve as output. \n\n\nFor more infos about Reactome visit:\n\nhttps://reactome.org/\nhttps://www.ncbi.nlm.nih.gov/pubmed/28249561\nhttps://www.ncbi.nlm.nih.gov/pubmed/29145629",
      "name": "Pathway Enrichment Analysis",
      "id": "*nAAPjkDm98mrfIdd",
      "type": "Other",
      "inPorts": [
        {
          "description": "Input table containing an ID column.\r\nIf you only want to paste  IDs in the configuration, connect an empty table as input.\r\nThe maximum is 1000 IDs.",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Output table with selected rows from JavaScript view.",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAf0lEQVR4nGNgGJTAwMBAgCIDjI2N5xsaGsqTbYCRkdEEIC4gSzPQ+Q4mJiYOIFeQa3sDiAYZAsLIckD+eaINAAUkjA1zGdBV6/GGDcz56IbB2FBDMcMGpAmkAFkDujdgciADQGx07+H1ErrLSAJQl00gSzMIUBSlMEBx0qYpAAAehidos81u4QAAAABJRU5ErkJggg==",
      "description": "This component performs a query for chemical structure searches using the SMILES notation. The component is based on the RCSB PDB RESTful WebServices.\r\n\r\nThe chemical structure search query results in a list of PDB IDs and the associated ligand information (chemicalID). Additionally information like  chemical name, smiles, molecular weight, formula, InChiKey and InChI of the respective ligand is provided.  The output table also includes, a column with combined score of results from different services (sequence, seqmotif, strucmotif, structure, chemical, and text) and results are sorted in decreasing order of this score.\r\n\r\nThe following search types are possible with the component: \r\n\t• graph-strict\r\n\t• graph-relaxed\r\n\t• graph-relaxed-stereo\r\n\t• fingerprint-similarity\r\n\r\nDocumentation about the RESTful WebService from PDB can be found here: \r\nhttps://search.rcsb.org/index.html#search-services\r\n\r\nGeneral information about the RCSB PDB database can be found here:\r\nhttps://academic.oup.com/nar/article/28/1/235/2384399",
      "name": "PDB Chemical Structure Search",
      "id": "*rMKsdkhmrtCn6RUN",
      "type": "Other",
      "inPorts": [],
      "outPorts": [
        {
          "description": "Output table contains information about protein structures and their ligands that matched the search query.",
          "name": "Output port",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAShJREFUOI2lk8ttwzAQRB9JFaAS1EEWKxjwzXIHKUGpIC4hJaiEpIK4BB0NWCKUDlSCKyBzMGUYiSUbyZwILOftLD/wTxkAVX37WQghNMMwnO4Bsmnhvb9ARCR3zjWqOi6ZL55bCVarlahqPWeePNnchuPxOKhqpaoN8GsUY8xmEZAiNn9OcK2yLJ9jjAJgrW27rmun2iJARAprbQ1svPdbESmA6nrPvQSFtbYNISAitbU2N8aMs4DUccf50MYQwgjn61qv1wXA4XCYB6SO+67r2rIsP51zJ+DjlnEOcIoxvqpqFWP8CiG0WbY8ZQZgjClUtfbevwMvVyNVAKq6A3IgN8a0qZxD+gtzEpHCObcDnvq+36YzqlIj7gImpSddTAn6vt8/4ntI38/oaqnXds3PAAAAAElFTkSuQmCC",
      "description": "This component generates example data for classification tasks based on the make_classification() function in the Python scikit-learn library.\n\nThe predictor features are randomly drawn from the standard normal distribution. If desired, some of the features can be redundant or duplicated.  The samples are assigned into one or more clusters within each class. Furthermore, it is possible to regulate the class separation within the feature space.\n\nFor more information see the sklearn documentation:\n\nscikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html\n\nNote: This component requires a Python environment. In this blog post we explain how to setup the KNIME Python extension:\n\nknime.com/blog/setting-up-the-knime-python-extension-revisited-for-python-30-and-20\n",
      "name": "Synthetic Data Generator (Classification)",
      "id": "*cSKT-HlcacyOWHfy",
      "type": "Manipulator",
      "inPorts": [],
      "outPorts": [
        {
          "description": "Classification Data",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAyklEQVR4nLVS2w3CMAzsCN2AjJCnlE9GYISMwAawCd2kIzBCR8gI4JNcKVAnaZGwZKVVfI+6Nwz/KGttcs7NdC5ofk5doNZaee+fANB5jjEqNL1fqCfqBTM18IgBAt5rArhjklGyfaPLR88lnNDsVoSZdY8AMzSbJfu5gpHE8sdnYDFwsJcAf8YYc2qzVordviRbs7icrXoSlx1C0OxClWpf6qqZBWZH+tI6DOLCejMnpQrSiAjnMjgr2a5ClEHQVWw5IfD1J/CRegMH4FAYUtBTpwAAAABJRU5ErkJggg==",
      "description": "Adopt this component to optimize any number of parameters of any binary or multiclass classification model. The component optionally offers an interactive view to visualize the parameter search performed by the component. \r\n\r\nThis component requires the parameter ranges listed in a table, the training data partition and the workflow object with the learner and predictor nodes of the classification model you are optimizing. \r\n\r\nThe output of the component is a flow variable with the optimized parameter values. Connect the flow variable to the learner node and select those values in its flow variable panel to adopt the optimized parameters combination when training the final model.\r\n\r\nVarious settings are available: for example you can define the performance metric to be maximized (e.g. accuracy), or the optimization criteria,(e.g.  brute-force/grid-search). Inside the component, cross validation takes place for each combination of parameters to avoid overfitting. \r\n\r\nThe former version of this component, “Parameter Optimization” (kni.me/c/A_91QC387NtvJ6g8), was hardcoded on Random Forest and two of its parameters. To understand how to use this new version on any classification model, data, and set of parameters (and without editing the workflow inside) inspect the example workflow referenced at the bottom of this page.",
      "name": "Parameter Optimization (Table)",
      "id": "*iE5x70ofXOBaBy-f",
      "type": "Learner",
      "inPorts": [
        {
          "description": "The parameter table should list one row for each parameter to be optimized and four columns in total: 2 string columns with the name of the parameter and its numerical type, either Number (integer) or Number (double); 3 numerical columns with start, stop and stepping of the parameter search.",
          "name": "Parameters Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "The training data with the target column to be classified and the feature columns to be learned.",
          "name": "Training Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "The workflow object captured with KNIME Integrated Deployment Capture nodes. The workflow object should have 3 inputs: parameter combination flow variable, train partition table, validation partition table. The workflow segment captured in a workflow object should contain the learner and the predictor node. The learner node should have one one flow variable controlling for each of the parameters.",
          "name": "Workflow Object with Learner and Predictor",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Workflow Port Object"
        }
      ],
      "outPorts": [
        {
          "description": "A flow variable that contains values with the best parameters found during the optimization process and the corresponding performance with the selected metric.",
          "name": "Best Parameters",
          "optional": false,
          "color": "#ff4b4b",
          "portTypeName": "Flow Variable"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAA3klEQVR4nL2S/Q2CQAzFGYERHOECx/+MwAhuABvIBt4GjuAIjuAIrGJ/5koewQ80xiYNba/v3fXRovilhRB2G7x8Cq7r+mreV1W1xy0+m188Nx/paZomrAhohj3GOGbCNoMGq7XUIOAi+6YFmCYOiGkmp9nPrXZUInotPujtEwDxyWpJ8sTTtQfMrIey+ys0ZxzNDdxZPizGoOBjwAypjDjPnDVYgoX55M9SDTx+KKAaYEhE2FJfoxe8IrkrbN+Qd6Hz2Ed8a/ors+K9irjJIGALWTBfro+NXcC/Av/NbnifZmUzsd9GAAAAAElFTkSuQmCC",
      "description": "This component automatically sends emails to managers about invoices that require some particular action. The email body is shown below. It will be customized by the manager name, invoice ID, action item, and invoice due status as provided in the input table. The example email looks as follows:\r\n\r\n\"Dear Felix,\r\nfor the Item: IN-02.94 please take the following action: Sell to factoring\r\n\r\nCurrent Due Status: 90+ Days\r\n\r\n*This message is generated by a KNIME workflow, please do not respond to this email!*\"\r\n\r\nTo enable SMTP server, for example, Gmail SMTP server, you will need to allow less secure apps under Google Account > Security > Less secure app access. Be aware that less secure apps can make your account more vulnerable. Other requirements might be needed for other mail providers.",
      "name": "Overdue Invoices Email Notification",
      "id": "*rsPi31deKx5EPPUV",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "The input data table containing at least 5 string columns for the manager name and email address, invoice ID and due status, and the required action.",
          "name": "0",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAyklEQVR4nLVS2w3CMAzsCN2AjJCnlE9GYISMwAawCd2kIzBCR8gI4JNcKVAnaZGwZKVVfI+6Nwz/KGttcs7NdC5ofk5doNZaee+fANB5jjEqNL1fqCfqBTM18IgBAt5rArhjklGyfaPLR88lnNDsVoSZdY8AMzSbJfu5gpHE8sdnYDFwsJcAf8YYc2qzVordviRbs7icrXoSlx1C0OxClWpf6qqZBWZH+tI6DOLCejMnpQrSiAjnMjgr2a5ClEHQVWw5IfD1J/CRegMH4FAYUtBTpwAAAABJRU5ErkJggg==",
      "description": "This component reduces the number of columns in the input data by linear discriminant analysis. Linear discriminant analysis is based on separating two or more classes in the data. Therefore, one string column has to be selected as the target column. Numeric columns are projected into their linear combinations, linear discriminants, that best separate the different target classes.\r\n\r\nThis component can be used for dimensionality reduction, for example, before training a machine learning model. Linear discriminant analysis also works as a classifier: the linear discriminants separate the normally distributed data into two or more target classes. \r\n\r\nLinear discriminant analysis can only create as many linear discriminants as there are target classes minus one, or if smaller, the number of numeric columns in the input data. Linear discriminant analysis may fail due to high dimensional input data and few target classes. In such case, it is recommended to first reduce dimensions by PCA, and then apply linear discriminant analysis to the principal components. This method is applied inside this component.\r\n\r\nNotice that the input data of the component have to be normalized, and missing value handling is recommended.\r\n\r\nIf you want to apply the dimensionality reduction model to new data, for example, a test set, the LDA model is available in the table in the second output port of the node. If the LDA model cannot be applied directly, the table also contains a PCA model, normalizer model, and the number of dimensions for PCA. You are supposed to apply the PCA model to the new data using the number of dimensions given in the “PCA-dimensions” column, and then use the normalizer model to normalize the reduced dimensions, i.e. principal components. Finally, you can then apply LDA to the reduced, normalized dimensions.\r\n\r\nRequired extensions:\r\n-KNIME Ensemble Learning Wrappers \r\n(https://hub.knime.com/knime/extensions/org.knime.features.ensembles/latest)\r\n-KNIME Data Generation \r\n(https://hub.knime.com/knime/extensions/org.knime.features.datageneration/latest)\r\n-KNIME Math Expression (JEP) \r\n(https://hub.knime.com/knime/extensions/org.knime.features.ext.jep/latest)\r\n-KNIME Quick Forms \r\n(https://hub.knime.com/knime/extensions/org.knime.features.js.quickforms/latest)\r\n-KNIME Statistics Nodes (Labs) \r\n(https://hub.knime.com/knime/extensions/org.knime.features.stats2/latest)",
      "name": "Dimensionality Reduction (LDA)",
      "id": "*qeoNxEAJY_1s4an5",
      "type": "Learner",
      "inPorts": [
        {
          "description": "Data that contain at least one string column and one numeric column\r\n\r\nOne string column is selected as the target column\r\nNumeric columns in the data will be reduced to linear discriminants\r\n\r\nNumeric columns have to be normalized\r\n",
          "name": "Data to reduce dimensions",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Linear discriminants together with the original string columns in the input data",
          "name": "Data with numeric columns reduced to linear discriminants",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "LDA model\r\n\r\nAdditional output columns, if LDA cannot be applied directly: \r\n- PCA model to apply to the data before LDA \r\n- Normalizer model to apply to the principal components before applying LDA\r\n- Number of dimensions for PCA",
          "name": "Model(s)",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAcElEQVR4nGNgoDUwMDAQMDEx6TcyMmoA4gJyDFAAakwAsUGGDFIDQH6D+hHDn2gGTICqmWBsbByAbEADNjYuFyCLYWgCmrwfxAfS88kyAMbGpniYG5AAi0Zg4K2H0TDFoABFlsOIRooBUiIiCVPFcgAwM2Hob2VycwAAAABJRU5ErkJggg==",
      "description": "This component generates an animated bar chart where the bars race over time, increasing in range. This animated visualization is popular to visualize different entities competing or simply changing over time on a selected metric. Examples are stock prices of different companies, disease confirmed cases by country, social media activity by users, ... all of those over time.\r\n\r\nThe visualization is defined via the Generic JavaScript node using d3.js, but settings are available in the component dialogue to customize:\r\n- the title above the chart;\r\n- the label displaying the time and its size and position;\r\n- bins with too small values;\r\n- the cumulative sum over time;\r\n- which are the 3 columns storing the metric values, the categories and the timestamps.\r\n\r\nAdditional settings can be customized by editing the workflow or even the JavaScript code: simply remove the link of the shared component and edit the nodes inside.",
      "name": "Animated Bar Chart",
      "id": "*LHM1wiGqiYygGg05",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "The input table should provide for each row the category (to be represented as a colored bar), an integer or double value (to be represented via the size of the bar) and a timestamp (to define the time axis for the animation). If a category is missing for a given time unit the component will consider the category value to be zero at that point in time. The timestamps should be provided in the dedicated KNIME column type via the String to Date&amp;Time node. Timestamps should be uniformly distributed in time and of identical format: if a timestamp is missing for all categories, the visualization won’t pause but it will proceed to the next available timestamp.",
          "name": "Metric Over Category Over Time",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    },
    {
      "name": "Download dataset and store locally",
      "id": "*bsbrkRrBR86kFy48",
      "type": "Other",
      "inPorts": [],
      "outPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#ff4b4b",
          "portTypeName": "Flow Variable"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAuklEQVR4nKVT2w3DMAjMCB7BIyA//j1CRvAI3aDeoNmgHTWQYAlFAbvtSZYicxxnIMtiAACcFR8CBUpKqfwjADlnmCU7rNZGvBBCQ67XRHw/KPYiMp9nL6ImSxFMeFzvYozvqadQxbt7aibG6s8Caowttz4u/N5GAuzmvpmaAy5UDfMnaO696yLZTTeRXVRMWKWr4fgE8dh/qggnfO+LuWzXJUGBD7lgN5vg+W/cEIo1WhW8fYcD67feARH/PpXMRyZ9AAAAAElFTkSuQmCC",
      "description": "This Component should be nested within another Component to generate a flowchart header at the top of the Composite View. This visual graphic is key to give an overview of the user journey to the data app end user who controls the workflow from the KNIME WebPortal.\r\n\r\nOpen the dialogue settings to define the flowchart appearance describing the steps of the data app and if you want even a shortcut skipping a few steps that are optional in the data app. Precise example workflows on how to use this component should be available on KNIME Hub to easily understand how the component works.",
      "name": "Data App Flowchart",
      "id": "*9f4g4Me4puMtm-Sh",
      "type": "Learner",
      "inPorts": [
        {
          "description": "A table with one String column and at least one Integer column. The string column should list in order the steps in the data app. The first integer column should store a &#34;1&#34; for the active step and &#34;0&#34; for all other steps. The second integer column is optional and should show a &#34;1&#34; for exactly two not-connected steps, and &#34;0&#34; for all other steps. The shortcut is connecting two steps, skipping a number of them in between.",
          "name": "Flowchart Metadata",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAsklEQVR4nGNgoBUwMDBwMDIyakDGIDFiNAqAFJuYmGAoBoonAPEEoBoFilwHNLyeaEMMIEABTUzA2Nh4PooA0Gn12JwN8jc2cZAYWBxoUgBQcwGQnoBiKgEDYGEFF4CGsgIooIgxAKYHOweLTegGE20AkkEGQC+uRzNgApwDDxQiAchFGOpRTMTvGlA0YqqFBmIBIc2wAMelQAFo+n5s6R4kBrKZqFQITR8omYmUMCIaAAD0RELelYkiBgAAAABJRU5ErkJggg==",
      "description": "This component aggregates values in a selected numeric or string column by timestamps extracted from a column of type Date&Time. The granularity of the timestamps and the aggregation method are defined by the user.\r\n\r\nIf the selected granularity indicates time, the extracted timestamps will have the same column type as the input column. For other granularities (days, months, etc.), the timestamps will appear in a column of type Local Date.\r\n\r\nFor Quarter and Week granularity, the first date of the corresponding period (quarter or week) will be returned as a column of Local Date type in the output table.\r\n\r\nNote: For Legacy Date&Time column please convert it first to Date&Time using the Legacy Date&Time to Date&Time node. \r\n\r\nThe available granularities are:\r\nYears\r\nMonths\r\nDays\r\nHours\r\nMinutes\r\nSeconds \r\n\r\nThe supported Date&Time types are:\r\nLocal Date Time\r\nZoned Date Time\r\nLocal Date\r\nLocal Time\r\n\r\nThe available aggregation methods are:\r\nMean\r\nMode\r\nMin\r\nMax\r\nSum\r\nVariance\r\nCount\r\n\r\nRequired extensions: \r\nKNIME Quick Forms \r\n(https://hub.knime.com/knime/extensions/org.knime.features.js.quickforms/latest)\r\n",
      "name": "Aggregation Granularity",
      "id": "*H50Xrt0Jqb8_kabq",
      "type": "Sink",
      "inPorts": [
        {
          "description": "A data table containing at least one numeric or string column and one Date&amp;Time column.",
          "name": "Input data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "A data table containing the extracted timestamps, aggregated values, and a constant value column containing the selected granularity as string.\r\n\r\nFor Quarter and Week granularity, 2 extra columns will be added: Firstly, a &#34;Year&#34; column containing year values, and secondly, a timestamp as the first date of the corresponding period (quarter or week).",
          "name": "Output data table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAuklEQVR4nKVT2w3DMAjMCB7BIyA//j1CRvAI3aDeoNmgHTWQYAlFAbvtSZYicxxnIMtiAACcFR8CBUpKqfwjADlnmCU7rNZGvBBCQ67XRHw/KPYiMp9nL6ImSxFMeFzvYozvqadQxbt7aibG6s8Caowttz4u/N5GAuzmvpmaAy5UDfMnaO696yLZTTeRXVRMWKWr4fgE8dh/qggnfO+LuWzXJUGBD7lgN5vg+W/cEIo1WhW8fYcD67feARH/PpXMRyZ9AAAAAElFTkSuQmCC",
      "description": "This node performs threshold analysis for binary classification or retrieval results with confidence values. It allows to calculate Accuracy, Precision, Recall and F1 measures depending on varying threshold on confidence/probability values.",
      "name": "Classification Threshold Analysis",
      "id": "*bUQXNkCgGD1e9DAh",
      "type": "Learner",
      "inPorts": [
        {
          "description": "Input data",
          "name": "Input data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Table containing evaluation metrics for a set of thresholds on probabilities.",
          "name": "Table with metrics for different thresholds",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAf0lEQVR4nGNgGJTAwMBAgCIDjI2N5xsaGsqTbYCRkdEEIC4gSzPQ+Q4mJiYOIFeQa3sDiAYZAsLIckD+eaINAAUkjA1zGdBV6/GGDcz56IbB2FBDMcMGpAmkAFkDujdgciADQGx07+H1ErrLSAJQl00gSzMIUBSlMEBx0qYpAAAehidos81u4QAAAABJRU5ErkJggg==",
      "description": "This component extracts bioactivities  from the latest version of ChEMBLdb by connecting to ChEMBL API via REST.\r\nMore information can be found here: \r\nChEMBL webservices: https://chembl.gitbook.io/chembl-interface-documentation/web-services \t\r\nKNIME blog post: https://www.knime.com/blog/a-restful-way-to-find-and-retrieve-data \t\r\n",
      "name": "ChEMBL Bioactivities",
      "id": "*w9-Au-lnFU3-IIpi",
      "type": "Other",
      "inPorts": [
        {
          "description": "Table containing a column with ChEMBL IDs and one with the entity type.",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Table with bioactivities.",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoDYwMDBwMDIyaoBhID+AaM1ADQUmJiYOQE0CMDEQ39jYeD1QTIGgZlyKQAYaGhouwOdsA6ABCfgsABkOsgSX7Q14nUdI3cAbAAppEManGW8YQE2fgBx92GzHG5UgSWzxDTIUpBkUjfgsQLYpATklQtOHACwtEGUIHlcOIkMIxRrRAABplTOgJ4UUigAAAABJRU5ErkJggg==",
      "description": "In order to decipher the decision making process of a black-box model you can use the eXplainable Artificial Intelligence (XAI) view. The view works for machine learning classifiers for binary and multiclass targets. The component generates an interactive dashboard view visualizing explanations for a set of instances you provide, as well other charts and Machine Learning Interpretability (MLI) techniques.\r\n\r\nThis component computes SHAP explanations, Partial Dependence Plot (PDP), Individual Conditional Expectation (ICE) curves and surrogate decision tree view. \r\n\r\n- SHAP values help in explaining the prediction by computing the contribution of each feature to the prediction. The sum of all SHAP values adds up to the difference between the prediction value and the average prediction in the provided sample dataset. Each explanation in the view is represented as a bubble and the aggregated sum of multiple explanations values in a violin plot.\r\n\r\n- A Partial Dependence Plot (PDP) denotes the relationship between the target and a single feature in a cartesian graph as a filled area. Individual Conditional Expectation (ICE) curves in the PDP show the reaction of a single prediction when changing a single feature.\r\n\r\n- Surrogate Decision Tree View is the result of overfitting a Decision Tree on the predictions of the original model instead of using the actual ground truth target. By committing the same mistakes of the original model, a view of the tree explains the black box model as a hierarchical decision process.\r\n\r\nThe dashboard is interactive, select explanations bubbles to see the same predictions highlighted in the other views. If the component is used as a nested component you can also add additional charts to visualize its output in other ways.\r\n\r\nThe user needs to provide a sample of the dataset used to train a model, the model and a set of instances (rows) from the test set. \r\n\r\nDATA INPUT REQUIREMENTS\r\n- The two input data tables (top and bottom ports) need to have exactly the same columns (Table Spec) beside the target column which can be omitted in the bottom port as you might need to explain instances for which the ground truth is not available.\r\n\r\n- The bottom input with instances to be explained can be at max 100 rows. More instances would clutter the visualization and take even more time to compute.\r\n\r\nBLACK-BOX MODEL REQUIREMENTS \r\nWe recommend using the \"AutoML\" component to test the “XAI View”, but any model could be explained by the component as long as it behaves as a black box and it is captured with Integrated Deployment. Precise requirements are listed below.\r\n\r\n- The model should be captured with Integrated Deployment and have a single input and single output of type Data.\r\n\r\n- All features columns have to be provided at the input.\r\n\r\n- Any other additional columns that are not features can be provided at the input.\r\n\r\n- The output should store all the input data (features and non-features) and present attached the output predictions columns.\r\n\r\n- The output predictions should be one String type and “n” Double type, where “n” is the number of classes in the target column.\r\n\r\n- The String type prediction column should be named “Prediction([T])” where [T] is the name of your target class (e.g. “Prediction (Churn)”).\r\n\r\n- The Double type prediction columns should be named “P ([T]=[C1])”, “P ([T]=[C2])”, …, “P (T=[Cn])”, where [Cn] is the name of the class that probability is predicting (e.g. “P (Churn=not churned)” and ”P (Churn=churned)” in the binary case).\r\n\r\nAdditionally, if you are not using the AutoML component, you need to provide a flow variable called “target_column” of type String with the name of your ground truth / target column in the top input of the XAI View component.",
      "name": "XAI View",
      "id": "*rra6HfaJgd0kKDLp",
      "type": "Learner",
      "inPorts": [
        {
          "description": "Provide the table that contains feature and target column (Dataset Sample).",
          "name": "Sampling Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Provide the model table from the top output of &#34;AutoML&#34; Component.",
          "name": "Models",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Workflow Port Object"
        },
        {
          "description": "Provide the table with predictions that have to be explained (Explainable Instances) .",
          "name": "Explainable Instances",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "The instances (second input) is rendered with attached the SHAP explanations and predictions.",
          "name": "Explanations",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAf0lEQVR4nGNgGJTAwMBAgCIDjI2N5xsaGsqTbYCRkdEEIC4gSzPQ+Q4mJiYOIFeQa3sDiAYZAsLIckD+eaINAAUkjA1zGdBV6/GGDcz56IbB2FBDMcMGpAmkAFkDujdgciADQGx07+H1ErrLSAJQl00gSzMIUBSlMEBx0qYpAAAehidos81u4QAAAABJRU5ErkJggg==",
      "description": "A component to download a set of FASTQ files under a certain project/study/experment by providing an accession ID from the European Nucleotide Archive (ENA).  The component works by first getting a summary table of samples belonging to the provided accession number. In this summary table are paths (ftp) to zipped FASTQ files of individual samples. \nUsing these paths, zipped FASTQ files are downloaded and stored under a directory named data/<accessionID> inside <KNIME-workspace>\n\nSupported accession types are Projects, Studies, BioSamples,  Samples, Experiments, Runs and Analyses. Refer to https://ena-docs.readthedocs.io/en/latest/submit/general-guide/accessions.html to see details. The component is able to handle both single and paired library layouts in a seamless fashion. \n\nNote:\nFiles will not be downloaded if their up-to-date version already exists under data/<accessionID>. ",
      "name": "Download FASTQ files from ENA",
      "id": "*NeHc15LUn8kG7zwr",
      "type": "Other",
      "inPorts": [],
      "outPorts": [
        {
          "description": "Table containing the list of files that have been transferred and if they have been transferred or were already up to date. If files are allowed to fail there is an additional column, that will indicate if the transfer was successful or did fail.",
          "name": "Downloaded Files",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAcElEQVR4nGNgoDUwMDAQMDEx6TcyMmoA4gJyDFAAakwAsUGGDFIDQH6D+hHDn2gGTICqmWBsbByAbEADNjYuFyCLYWgCmrwfxAfS88kyAMbGpniYG5AAi0Zg4K2H0TDFoABFlsOIRooBUiIiCVPFcgAwM2Hob2VycwAAAABJRU5ErkJggg==",
      "description": "This component serves the purpose of visually representing and analyzing the outcomes of a topic model. It is compatible with any topic modeling model as long as they generate the topic-term matrix and the topic-document matrix. We recommend using this component downstream from the Topic Extractor (Parallel LDA) node [kni.me/n/w7Vr1wY8Bu8Gfpv7] or the Topic Extractor (STM) component [kni.me/c/DFANPa0NHnZb9tSV]. For more details see port documentation below.\r\n\r\nThe component interactive view proves valuable in validating a chosen topic model solution and offering insights into the similarity between different extracted topics.\r\n\r\nThe Topic Explorer View offers two modes:\r\n\r\n- Explore by Topic: explore the topics (second input) in a similarity bubble chart, select topics and visualize coherence and exclusivity scores from the Topic Scorer component (kni.me/c/5_W2h2g6hBY_M0Bc) and the associated tag cloud. Additionally you can scroll through topics represented as small bar charts.\r\n\r\n- Explore by Document: explore the documents (first input) in a similarity bubble chart, select topics and visualize the preview or the full length of documents where the terms inside the topics are highlighted.\r\n\r\nBoth modes provide a similarity bubble chart, where topics or documents with higher semantic similarity are positioned closer to each other on the graph in 2-dimensional space. This is achieved through a combination of distinct analytics techniques:\r\n\r\n1) For the “Explore by Topic” mode, we utilize a Word2Vec model (kni.me/n/QPMbC4vyfvPkfV8F) to calculate the distances between all words within the documents. These distances are then used to construct a distance matrix, representing the similarity among all topics by averaging the distances of the words associated with each specific topic.\r\n\r\n2) The distance matrix generated by Word2Vec is further processed using Multidimensional Scaling (MDS) (kni.me/n/SCgPuzvfM-9t325D), which decomposes it into two dimensions. These two dimensions serve as the coordinates of each topic in a 2-dimensional space. Additionally, the size of the points representing topics directly corresponds to their frequency among the documents.\r\n\r\n3) The size of the bubble represents the mean probability of input documents to belong to that topic.\r\n\r\n4) When adopting the “Explore by Document” mode, each bubble represent a different document as we perform a similar approach using the documents bag of words instead of the topic models output terms\r\n\r\nDISCLAIMER: When dealing with a large number of documents this data app slows down in performance. By default the top 250 rows from the top input and the top 10 terms per topic from the second input are considered. You can increase these numbers in the component dialogue. To not face performance issues, it is advisable to employ stratified sampling on the first input using the assigned topic column in a Row Sampling node (kni.me/n/3o-UY2qMENf5piCd) before the component.\r\n\r\nThis component can be utilized as a data app, running either on a local environment or on KNIME Server and KNIME Business Hub.",
      "name": "Topic Explorer View",
      "id": "*IHLj9P4znjRaN35J",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "Table with the document column (not necessarily pre-processed for readability) and the topic label assigned by the model. This is usually the first output from the &#34;Topic Extractor (Parallel LDA)&#34; node or &#34;Topic Extractor (STM)&#34; component. Each row should be a document and the following columns should be available: the document column (from KNIME Textprocessing), the assigned topic, the probability columns for each topic.",
          "name": "Table with original text document",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Second output table from &#34;Topic Extractor (Parallel LDA)&#34; node or &#34;Topic Extractor (STM)&#34; component. For the second input each row should be a term and the following columns should be available: the term (String type), the topic id and the weight.",
          "name": "Top Terms by Topic",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAOZJREFUOI3lkMFtwkAQRf9+++CjO4ASViMXQAmUkHQQOqAEOoASSAVx7pa9JUAHPlrWeocLrJzgxEQcM6fVn9n3/wzwZJnboyiKVQhhDaCdHDRmMQzDxjn3pR8BIvKiqh9N05ynACKyU9VcVd/GED4alaSq6i5Jkr21Nr/p6ffB6yqrsVbX9dZ7/07SquonyTWAwyTAe98COI2kIwA450oAsNYuSUaDOwCAU5Zlcceu635d7Q6Qpqnt+z46kASA7U+A2SOGEA5/SlBVVQmgnAM/nOAfAOIRjTEtgFcRmfuTkzw+axzrAh/eURiwzXlhAAAAAElFTkSuQmCC",
      "description": "Document Preprocessing applies a common sequence of preprocessing steps to clean and prepare text for subsequent analysis and comparison with other text. As input, a column containing documents is expected and as output, the newly preprocessed documents is produced.\r\n\r\nThe Component requires the following extensions:\n- KNIME Textprocessing \nhttps://hub.knime.com/knime/extensions/org.knime.features.ext.textprocessing/latest",
      "name": "Document Preprocessing",
      "id": "*jF2hQUWIhVKjJ9un",
      "type": "Source",
      "inPorts": [
        {
          "description": "The input table which contains the documents to preprocess.",
          "name": "Documents Input Port",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Documents which have passed through the preprocessing steps.",
          "name": "Automatically Preprocessed Document",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAsklEQVR4nGNgoBUwMDBwMDIyakDGIDFiNAqAFJuYmGAoBoonAPEEoBoFilwHNLyeaEMMIEABTUzA2Nh4PooA0Gn12JwN8jc2cZAYWBxoUgBQcwGQnoBiKgEDYGEFF4CGsgIooIgxAKYHOweLTegGE20AkkEGQC+uRzNgApwDDxQiAchFGOpRTMTvGlA0YqqFBmIBIc2wAMelQAFo+n5s6R4kBrKZqFQITR8omYmUMCIaAAD0RELelYkiBgAAAABJRU5ErkJggg==",
      "description": "Decomposes selected Time-Series or IoT signal into Trend, 2 Seasonal Components, and the remaining Residual.\n\nSignal = T + S1 + S2 + R\n\n[T] Trend Component: is calculated by fitting a regression model through the data with degree 2.\n[S1] Seasonal Component 1: is calculated as the first major spike in auto-correlation.\n[S2] Seasonal Component 2: is calculated as the first major spike in auto-correlation after the diferencing of the first seasonality.\n[R] Residual: is what remains after trend and the two Seasonalities have been differenced.\n\nThe interactive displays shows the first 1000 records fpr the above outputs as well as the ACF plot for the detrended signal and both subsequent series after seasonality one and two are removed.\n\nIf you encoutner errors please verify that \nPreferances > KNIME > Python (labs) > Python environment configuration\nis set to bundled",
      "name": "Decompose Signal",
      "id": "*HMHmnCexBpdncu-N",
      "type": "Sink",
      "inPorts": [
        {
          "description": "Table containing signal column",
          "name": "Signal Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Original table with Trend, Seasonality 1, Seasonality 2, and Residual columns added.",
          "name": "Table with Decomposed Signal",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "The Regression model representing the Singal&#39;s Trend",
          "name": "Trend Model",
          "optional": false,
          "color": "#1469af",
          "portTypeName": "PMML"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAuklEQVR4nKVT2w3DMAjMCB7BIyA//j1CRvAI3aDeoNmgHTWQYAlFAbvtSZYicxxnIMtiAACcFR8CBUpKqfwjADlnmCU7rNZGvBBCQ67XRHw/KPYiMp9nL6ImSxFMeFzvYozvqadQxbt7aibG6s8Caowttz4u/N5GAuzmvpmaAy5UDfMnaO696yLZTTeRXVRMWKWr4fgE8dh/qggnfO+LuWzXJUGBD7lgN5vg+W/cEIo1WhW8fYcD67feARH/PpXMRyZ9AAAAAElFTkSuQmCC",
      "description": "\r\nThis Component generates a view monitoring the performance of a model captured by Integrated Deployment. The view works for machine learning classifiers for binary as well as multiclass targets.  The Component requires the deployment data with timestamps (dates) and target columns in order to showcase the performance over time. \r\n\r\nIn the Interactive View generated, the performance metric is plotted with respect to the time axis, and further, a trend line is plotted based on this performance.  A “Retrain” button has been provided in the view. Based on the model performance the user can decide if retraining is necessary. This retraining decision is given at the output of the component via a flow variable. Connect the flow variable output to the workflow branch which retrains the model. Such branch should execute only if the user checked the box in the view. \r\n\r\nCAPTURED MODEL REQUIREMENTS (Top Port)\r\nWe recommend using the \"AutoML\" component with this component. All you need is connect the two components via the black integrated deployment port. \r\n \r\nYou can also monitor a customly trained model with this component. When providing a model not trained by the “AutoML” component, you need to satisfy the below black box requirements:\r\n\r\n- The model should be captured with Integrated Deployment and have a single input and single output of type Data.\r\n\r\n- All features columns have to be provided at the model input.\r\n\r\n- Any other additional columns that are not features can be provided at the model input.\r\n\r\n- The model output should store all the model input data (features and non-features) and present attached the output predictions columns.\r\n\r\n- The model output predictions should be one String type and “n” Double type, where “n” is the number of classes in the target column.\r\n\r\n- The String type prediction column should be named “Prediction([T])” where [T] is the name of your target class (e.g. “Prediction (Churn)”).\r\n\r\n- The Double type prediction columns should be named “P ([T]=[C1])”, “P ([T]=[C2])”, …, “P (T=[Cn])”, where [Cn] is the name of the class that probability is predicting (e.g. “P (Churn=not churned)” and ”P (Churn=churned)” in the binary case).\r\n\r\nAdditionally, if you are not using the AutoML component, you need to provide a flow variable called “target_column” of type String with the name of your ground truth/target column in the top input of the “Model Monitor View“ Component.\r\n\r\nINPUT DEPLOYMENT TABLE REQUIREMENTS (Bottom Port)\r\n- All features columns that were used in the training of the captured model.\r\n- Availability of target column and timestamp column. Each record timestamp tracks the date in which the model was applied on that data row. The timestamp should be of “Date&Time” column Types. “Time” and “String” types are not supported. Use the “String to Date&Time” node. The timestamp column should be uniformly distributed across the sample: time ranges in between dates where samples are missing should be somewhat constant.",
      "name": "Model Monitor View",
      "id": "*gR-i2cxnqR7XUd1I",
      "type": "Learner",
      "inPorts": [
        {
          "description": "A model captured with Integrated Deployment.",
          "name": "Model",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Workflow Port Object"
        },
        {
          "description": "Deployment data with target/ground truth and timestamp:\r\n\r\n- A table of instances gathered after the deployment where the model was previously applied.\r\n- The collected afterwards ground truth (also called target) column should also be available. \r\n- The timestamp needs to be already converted to either &#34;Date&amp;Time&#34; Column Type or similar as long as it has a date and it is not String Column Type.",
          "name": "Deployment data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Flow variable to activate downstream workflow branch for retraining.",
          "name": "Retrain",
          "optional": false,
          "color": "#ff4b4b",
          "portTypeName": "Flow Variable"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoBYwMTFxMDIymgDEDdiwsbHxfAMDAwGcBgAVJRgaGsrjkZ8AlF+A0xBCBgBd2A/UbAB0yXqshsAMgHoFxfkgeaAmkHgCEBeAaJwGGEBAAhJGsQ3IVyBkgICFhYUCDJNsAC4vkG0ASANJBmBIoIFRA/AYAEyiAbgyEhqeAIopQhYRDQAHAltSvpTuDAAAAABJRU5ErkJggg==",
      "description": "Use the component to apply the model trained with the 'Topic Extractor (STM)' component. See the other component for more information.\r\n\r\nThis component integrates with the R implementation of Structural Topic Models (STM), following Roberts, Stewart and Tingley, Journal of Statistical Software (2019) (cran.r-project.org/web/packages/stm/vignettes/stmVignette.pdf), via the R library 'stm' (cran.r-project.org/web/packages/stm). \r\n\r\nOn its first execution the component is set up to automatically install R and all the required libraries. For this to work you need to install Conda (we recommend via \"docs.conda.io/en/latest/miniconda.html\"). KNIME Analytics Platform can automatically find the default path of where Conda is installed.  You can make sure KNIME Analytics Platform is using the correct path via \"File > Preferences > KNIME > Conda\". \r\n\r\nDISCLAIMER: this component won't work on Apple M1 systems as the 'stm' package is not available for 'osx-arm64' via 'conda-forge' (\"anaconda.org/conda-forge/r-stm\"). For Apple Intel systems manual installation of additional software might be required after the Conda Environment Propagation node executes. For details visit: docs.knime.com/latest/r_installation_guide",
      "name": "Topic Assigner (STM)",
      "id": "*JouC8XuiujXpquzd",
      "type": "Source",
      "inPorts": [
        {
          "description": "The R object with the trained model. Use the component &#34;Topic Assigner (STM)&#34; to apply this model to new documents.",
          "name": "R Model",
          "optional": false,
          "color": "#9b9b9b",
          "portTypeName": "R Workspace"
        },
        {
          "description": "Data table with the document collection to analyze in the KNIME Textprocessing column type (use the &#39;Strings to Document&#39; node first). Each row contains one document. Documents can be pre-processed (stopwords removal, stemming, ...).",
          "name": "Document Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "The document collection with topic assignments and the probability for each document to belong to a certain topic. Such probabilities are taken from the gamma/theta matrix returned by the &#39;stm_tidiers&#39; R function. Missing values are listed for rows with missing text or selected metadata fields/columns.",
          "name": "Document with Assigned Topics",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "description": "Loads a Model from the TensorFlow Hub and wraps it into a Network with the defined inputs and the outputs of the Hub model.\n\nSee https://tfhub.dev/\n\n* TensorFlow, the TensorFlow logo and any related marks are trademarks of Google Inc.",
      "name": "Load TensorFlow Hub Model",
      "id": "*sAM1zk8xmFiOKivc",
      "type": "Source",
      "inPorts": [],
      "outPorts": [
        {
          "description": "The TensorFlow 2 network holding the model from the TensorFlow Hub.",
          "name": "TensorFlow 2 Network",
          "optional": false,
          "color": "#ff3300",
          "portTypeName": "TensorFlow 2 Model"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAf0lEQVR4nGNgGJTAwMBAgCIDjI2N5xsaGsqTbYCRkdEEIC4gSzPQ+Q4mJiYOIFeQa3sDiAYZAsLIckD+eaINAAUkjA1zGdBV6/GGDcz56IbB2FBDMcMGpAmkAFkDujdgciADQGx07+H1ErrLSAJQl00gSzMIUBSlMEBx0qYpAAAehidos81u4QAAAABJRU5ErkJggg==",
      "description": "The PDB Data Extractor component receives PDB IDs as input and fetches additional data about the provided structures like sequences or references to other databases like UniProt or PubMed.\r\n\r\nThe component is using the PDB web service.\r\nMore information about the PDB database and the editable web service fields in the request can be found here: \r\nhttps://academic.oup.com/nar/article/28/1/235/2384399\r\nhttps://www.rcsb.org/pdb/results/reportField.do\r\n",
      "name": "PDB Data Extractor",
      "id": "*rx1xO0HDXb2BT54j",
      "type": "Other",
      "inPorts": [
        {
          "description": "Input table containing an PDB ID column",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Output table containing the PDB web service output",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAcElEQVR4nGNgoDUwMDAQMDEx6TcyMmoA4gJyDFAAakwAsUGGDFIDQH6D+hHDn2gGTICqmWBsbByAbEADNjYuFyCLYWgCmrwfxAfS88kyAMbGpniYG5AAi0Zg4K2H0TDFoABFlsOIRooBUiIiCVPFcgAwM2Hob2VycwAAAABJRU5ErkJggg==",
      "description": "The component receives aligned DNA sequences as input and creates an interactive view that contains a sequence logo created with the Generic JavaScript View and a Table View. \n\nThe sequence logo displays the nucleotides in each position and the size indicates their frequency in the sequences. \nBy selecting nucleotides from the logo the samples in which they occur get selected in the Table View. \n\nFor a more detailed description have a look at:\n\nhttps://www.knime.com/blog/motifs-and-mutations-the-logic-of-sequence-logos",
      "name": "Sequence Logo",
      "id": "*Jry3Nf72GrKq_rWu",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "Input table containing a column with DNA sequences.",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAOZJREFUOI3lkMFtwkAQRf9+++CjO4ASViMXQAmUkHQQOqAEOoASSAVx7pa9JUAHPlrWeocLrJzgxEQcM6fVn9n3/wzwZJnboyiKVQhhDaCdHDRmMQzDxjn3pR8BIvKiqh9N05ynACKyU9VcVd/GED4alaSq6i5Jkr21Nr/p6ffB6yqrsVbX9dZ7/07SquonyTWAwyTAe98COI2kIwA450oAsNYuSUaDOwCAU5Zlcceu635d7Q6Qpqnt+z46kASA7U+A2SOGEA5/SlBVVQmgnAM/nOAfAOIRjTEtgFcRmfuTkzw+axzrAh/eURiwzXlhAAAAAElFTkSuQmCC",
      "description": "The Document Similarity Learner develops a model for identifying a new documents most similar matches from an existing corpus of documents. It consumes already processed documents (refer to Document Preprocessing Component) as input and provides as output both the corpus of documents and a model for use with the Document Similarity Predictor Component.",
      "name": "Document Similarity Learner",
      "id": "*FpR0_672wm6R9iHk",
      "type": "Source",
      "inPorts": [
        {
          "description": "Documents which have already been preprocessed (via Document Preprocessing).",
          "name": "Preprocessed Documents",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "The reference corpus of documents for future comparison with new documents.",
          "name": "Corpus of Documents",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Model for creating document vectors on new documents in the appropriate, compatible format.",
          "name": "Document Vector Model",
          "optional": false,
          "color": "#9b9b9b",
          "portTypeName": "DocumentVectorPortObject"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAlElEQVR4nGNgoAUwMDAQMDIyKgDiBiguAIopEKUZpNjExKQBZAi6gcbGxvmENCfgswkkh9MQoKQByAAiXJgAdKEDNokGQpqR1E6g1ABMtYPCAKLiGqQGZ2ADo2g+EbZjBiCy6UBDJoBoUOIxNDRcgJygiHIlSAMoJYL8CTRsAbKrkA0jCkCTtQNJmpBtA6VOsjSTAgCY9TAwIZkx9AAAAABJRU5ErkJggg==",
      "description": "This component extracts the links tweeted for better keyword search analysis, mainly for SEO purposes. Its usage is fairly simple, add in the twitter authentication tokens obtained from dev.twitter.com, search query with necessary filters and number of tweets for search results. \r\nBy default all filters are disabled, please specify any necessary search filter you want in your search query and this component will do the rest for you. List of all possible search filters can be found at:\r\n\r\nhttps://developer.twitter.com/en/docs/twitter-api/v1/rules-and-filtering/search-operators\r\n",
      "name": "Twitter URLs Extractor",
      "id": "*BVBWr0GSIWg1XVRN",
      "type": "Learner",
      "inPorts": [],
      "outPorts": [
        {
          "description": "A column containing tweeted web addressses and corresponding tweet details.",
          "name": "table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAtUlEQVR4nK2S3Q3DIAyEM0JHYASLH4lHRsgIjJAROgIbtBt0hK4Wn2QkCwEFqSf5wST+zjo4jn/IWvtsi4geWwDdY9g59+6BdQ0BUAiB+DwvmfYAcn5xlZ47b/j9CZhpaYMqdjurs/c+LQM4TKPXlT7vABIc5VozMsE2Q4A41NByBeBbjNGgphnoAXb6cL1q32oEIAyp15iWAPLq8iSDS6AFGUiVHrgFGPzYu4UtYUhvsA2Y6QaZe2IxLfqnMAAAAABJRU5ErkJggg==",
      "description": "This component allows to filter columns by their index (i.e. position). An example can be: select the second and the last columns (e.g. with \"2,-1\"), or first five columns (e.g. with \"1:5\").\r\nConfiguration takes a string of column positions.",
      "name": "Column Filter (by Index)",
      "id": "*cULYeHRegHkyMadG",
      "type": "Manipulator",
      "inPorts": [
        {
          "description": "Input data table",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Table with the specified subset of columns",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoDYwMDBwMDIyaoBhID+AaM1ADQUmJiYOQE0CMDEQ39jYeD1QTIGgZlyKQAYaGhouwOdsA6ABCfgsABkOsgSX7Q14nUdI3cAbAAppEManGW8YQE2fgBx92GzHG5UgSWzxDTIUpBkUjfgsQLYpATklQtOHACwtEGUIHlcOIkMIxRrRAABplTOgJ4UUigAAAABJRU5ErkJggg==",
      "description": "This Component computes fairness metrics over an input classification model adopting the following metrics: demographic parity, equal opportunity and equalized odds. Use this component to flag models that might unfairly impact stakeholders before they are deployed. This practice follows responsible AI principles.\r\n\r\nConfigure the component based on your company policy. When a model is flagged by the component, please consider that with the current training data it cannot be guaranteed that the model built will not contain significant bias and that the best option is to first fix how data is collected rather than training your model differently.\r\n\r\nThe component works for any binary or multiclass model captured in a workflow object via the KNIME Integrated Deployment Extension. For testing this component we recommend connecting its input model port with the AutoML classification component output (kni.me/c/33fQGaQzuZByy6hE).\r\n\r\nThe metrics are calculated based on the “advantage class” [1], the desirable classification outcome of the model, and the “sensitive attribute” [2], a column in the input data categorizing the instances in the test set between “protected classes” [3] and “unprotected classes”.\r\n\r\nThe component computes fairness metrics and compares them with the desirable values in different tests. If one of the fairness metrics does not achieve the desirable value it means that the model failed the corresponding fairness test, at least based on the sample of data provided. Given the empirical nature of these fairness tests we provide a different epsilon (ε) parameter to relax each condition based on the user choice: the higher the epsilon the easier it is for the model to pass the tests. Please note that it is not possible to pass all tests as some of them are mutually exclusive.\r\n\r\nTerminology:\r\n\r\n[1] Advantage Class: the positive outcome for the stakeholders living the consequences of the model predictions. This information is also stored in the target column the model is trained on.\r\n[2] Sensitive Attribute : A column in the dataset, which should not be a feature, which is considered sensitive for the problem domain. A model is fair if it’s computing its prediction without using any feature highly correlated with this sensitive information.\r\n[3] Protected Classes: The categories in the sensitive attribute column that are related to a minority or a disadvantaged group in real world data. Similarly “Unprotected Classes” are all the other classes which in general are not known to be disadvantaged.\r\n\r\nTESTS\r\n\r\nFor all fairness tests we rely on two partitions splitted on the sensitive attribute classes: protected partition and unprotected partition.\r\n\r\nDemographic Parity Test:\r\n\r\nTest passed: Demographic Parity metric is within the range [1 - ε, 1 + ε]\r\nThe amount of advantage class predictions is independent of the protected class, as the advantage class prediction is in % close to equal in both partitions.\r\n\r\nTest failed: Demographic Parity metric is outside the range [1 - ε, 1 + ε]\r\nThere is “enough” evidence in the data that the model favors the unprotected class or the protected class: the advantage of class prediction is in % definitely higher in one of the partitions over the other.\r\n\r\nEquality of Opportunity Test:\r\n\r\nTest passed: Equality of Opportunity metric is within the range [1 - ε, 1 + ε]\r\nEach partition has a somewhat equal opportunity to be correctly classified with the advantage class.\r\n\r\nTest failed: Equality of Opportunity metric is outside the range [1 - ε, 1 + ε]\r\nThere is “enough” evidence that the two partitions have different “opportunities” as in one of the two it is easier to get misclassified by not getting the advantage class when deserved.\r\n\r\nEqualized Odds Test:\r\n\r\nTest passed: Equalized Odds metric is within the range [1 - ε, 1]\r\nEach partition has somewhat equal odds to be correctly classified with any class.\r\n\r\nTest failed: Equalized Odds metric is outside the range [1 - ε, 1]\r\nThere is “enough” evidence that the two partitions have different “odds” as in one of the two it is easier to get misclassified with any class.\r\n\r\nMETRICS\r\n\r\nIn each metric computation we rely on two confusion matrices (en.wikipedia.org/wiki/Confusion_matrix) based on two partitions splitted on the sensitive attribute classes: protected partition and unprotected partition. We denote the advantage class as the positive class and in the multiclass classification we also adopt a one-vs-all approach. Using the values and statistics from the two confusion matrices we compute the 3 metrics below. All 3 metrics are provided at the output of the component. It stands true for Demographic Parity and Equality of Opportunity fairness types that: \r\n\r\nIf the metric is > 1 + ε then the model favors the protected partition;\r\nIf the metric is < 1 - ε then the model favors the unprotected partition.\r\n\r\nFor the Equalized Odds metric it is not possible to detect which partition the model favors.\r\n\r\nIn general please notice that different metrics might give different fairness results.\r\n\r\nDemographic Parity Metric:\r\nA fairness metric that is satisfied if the results of a model's classification are not dependent on the sensitive attribute. For each of the two partitions, the technique computes the ratio of advantage class predictions over all predictions. The final metric is equal to the division between the two ratios (the protected one over the unprotected one). Please consider this metric totally ignores ground truth data.\r\n\r\nEquality of Opportunity Metric:\r\nA fairness metric that checks whether the classifier predicts with the same performance the advantage class for both the protected and unprotected classes when considering false negatives. This metric measures whether either of the two partitions is disadvantaged by a model that is more likely to commit false negatives than in the other partition. To compute the metric we take the True Positive Rate (TPR) from the confusion matrices and divide the protected one by the unprotected one. If this metric > 1 the protected class is advantage\r\n\r\nEqualized Odds Metric:\r\nA fairness metric that checks whether the classifier predicts with the same performance the advantage class for both the protected and unprotected classes regardless of the type of misclassification. While equality of opportunity only focuses on making sure the amount of false negatives are equally shared in % among the two partitions, here also false positives are taken into consideration. To compute the metric we take both the True Positive Rate (TPR) and True Negative Rate (TNR) from the confusion matrices. Then we compute the differences between TPRs and TNRs. Then we compute the Euclidean Distance and we normalize between 0 and 1. If the metric is close to 1 it means that TPR and TNR values do not vary between protected and unprotected partitions.\r\n\r\nSource: developers.google.com/machine-learning/glossary/fairness",
      "name": "Fairness Scorer",
      "id": "*i9V5blwrYopRR27C",
      "type": "Learner",
      "inPorts": [
        {
          "description": "Classification model Workflow Object captured with KNIME Integrated Deployment.",
          "name": "Input Model",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Workflow Port Object"
        },
        {
          "description": "Test data to compute the fairness of the trained model. It is vital this sample is representative of the distribution in order to get a correct fairness measure.",
          "name": "Input Data ",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Table with scores for fairness metrics and test results (&#34;passed&#34; vs &#34;failed&#34;) of the model with respect to the chosen epsilon value.",
          "name": "Output",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoDYwMDBwMDIyaoBhID+AaM1ADQUmJiYOQE0CMDEQ39jYeD1QTIGgZlyKQAYaGhouwOdsA6ABCfgsABkOsgSX7Q14nUdI3cAbAAppEManGW8YQE2fgBx92GzHG5UgSWzxDTIUpBkUjfgsQLYpATklQtOHACwtEGUIHlcOIkMIxRrRAABplTOgJ4UUigAAAABJRU5ErkJggg==",
      "description": "This Component can be used before the bottom input port of SHAP Loop Start. This technique will use k-means to summarize the validation set and create a sampling table to use when creating coalitions. \r\nThe created sampling table is large n rows, each row is a different prototype of the data. This n can be adjusted from the configuration dialogue of the Component. The n default value is 100. \r\nThe output sampling table has, for each of the n clusters created by k-means, a prototype row and a column \"SHAP Summarizer Sampling weight\" that can be used by the SHAP Loop Start node. \r\nThis Component can summarize data of the following domains: Number (integer), Number (double) and String. \r\n\r\nDISCLAIMER : the Component statistical sampling is not always guaranteed when you provide String columns in the input table. Current computer science research is still looking for a more solid solution than training k-means via one-hot encoding-decoding of categorical columns.",
      "name": "SHAP Summarizer",
      "id": "*B7voxnL0hnPZ0qkg",
      "type": "Learner",
      "inPorts": [
        {
          "description": "Data to be summarized containing all the features SHAP Loop Start needs.\r\nSupported domains: Numeric (double), Numeric (integer), String.",
          "name": "Validation Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "A table with a prototype for each cluster with all the features with average value of the belonging cluster. Additionaly a column called &#34;SHAP Summarizer Sampling weight&#34; that can be used by SHAP Loop Start as sampling weight.",
          "name": "Summarized Sampling Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAsklEQVR4nGNgoBUwMDBwMDIyakDGIDFiNAqAFJuYmGAoBoonAPEEoBoFilwHNLyeaEMMIEABTUzA2Nh4PooA0Gn12JwN8jc2cZAYWBxoUgBQcwGQnoBiKgEDYGEFF4CGsgIooIgxAKYHOweLTegGE20AkkEGQC+uRzNgApwDDxQiAchFGOpRTMTvGlA0YqqFBmIBIc2wAMelQAFo+n5s6R4kBrKZqFQITR8omYmUMCIaAAD0RELelYkiBgAAAABJRU5ErkJggg==",
      "description": "Removes seasonality trend in input data.\r\n\r\nRequired extensions: \r\nKNIME Quick Forms \r\n(https://hub.knime.com/knime/extensions/org.knime.features.js.quickforms/latest)\r\nKNIME Math Expression (JEP)\r\n(https://hub.knime.com/knime/extensions/org.knime.features.ext.jep/latest)",
      "name": "Remove Seasonality",
      "id": "*sMHAOfFmbz55gmQe",
      "type": "Sink",
      "inPorts": [
        {
          "description": "Data containing selected column for seasonality removal.",
          "name": "Input Table",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Extra column added to original table with value x(t) - x(t-lag) where lag is the value given by user in the configuration dialog.",
          "name": "Input data with removed seasonality",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "This table contains the removed seasonality column. This information would be needed to re-add the seasonality back into the data later.",
          "name": "The seasonality column",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAA3klEQVR4nL2S/Q2CQAzFGYERHOECx/+MwAhuABvIBt4GjuAIjuAIrGJ/5koewQ80xiYNba/v3fXRovilhRB2G7x8Cq7r+mreV1W1xy0+m188Nx/paZomrAhohj3GOGbCNoMGq7XUIOAi+6YFmCYOiGkmp9nPrXZUInotPujtEwDxyWpJ8sTTtQfMrIey+ys0ZxzNDdxZPizGoOBjwAypjDjPnDVYgoX55M9SDTx+KKAaYEhE2FJfoxe8IrkrbN+Qd6Hz2Ed8a/ors+K9irjJIGALWTBfro+NXcC/Av/NbnifZmUzsd9GAAAAAElFTkSuQmCC",
      "description": "This component formats data before analyzing recurring events, such as monthly or annually recurring revenue. In the input table, each record holds a time period, an ID, and some numeric value. These records could be, for example, contracts with different customers. In the formatted output table, each record holds a time point within the time period, ID, and value. This value is calculated by dividing the original value by the number of single time points within the time period.  \r\n\r\nThe granularity of the single time points can be set to \"Days\" or \"Months\".  \r\n\r\nRequired extensions:\r\n- KNIME Math Expression (JEP) \r\n(https://hub.knime.com/knime/extensions/org.knime.features.ext.jep/latest)\r\n- KNIME Quick Forms \r\n(https://hub.knime.com/knime/extensions/org.knime.features.js.quickforms/latest)",
      "name": "Calculate Recurring Values",
      "id": "*qmrFwOmt43yW9T_b",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "- Two columns of type Date&amp;Time that define the start and end date of the time period \r\n- Numeric or string column for the IDs that identify each record\r\n- Numeric column for the values that are assigned to each time period and ID\r\n",
          "name": "Contracts data ",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "- Column of type Date&amp;Time for the single time points that have been extracted from each time period\r\n- String or numeric column for the IDs of the records\r\n- Numeric column for the values assigned to each time point and ID",
          "name": "Recurring values",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAA3klEQVR4nL2S/Q2CQAzFGYERHOECx/+MwAhuABvIBt4GjuAIjuAIrGJ/5koewQ80xiYNba/v3fXRovilhRB2G7x8Cq7r+mreV1W1xy0+m188Nx/paZomrAhohj3GOGbCNoMGq7XUIOAi+6YFmCYOiGkmp9nPrXZUInotPujtEwDxyWpJ8sTTtQfMrIey+ys0ZxzNDdxZPizGoOBjwAypjDjPnDVYgoX55M9SDTx+KKAaYEhE2FJfoxe8IrkrbN+Qd6Hz2Ed8a/ors+K9irjJIGALWTBfro+NXcC/Av/NbnifZmUzsd9GAAAAAElFTkSuQmCC",
      "description": "This component computes the fraction of the year of the difference between two dates, similar to the YEARFRAC function in Microsoft Excel. \r\n\r\nThe component outputs two columns: \r\n\r\n- The \"YEARFRAC\" column contains the difference between the start date and the end date as a fraction, that is the number of whole days between the dates divided by the total days per year. \r\n\r\n- The \"Difference Value (in Months)\" contains the same difference, but given in months. \r\n\r\nSimilarly to Microsoft Excel YEARFRAC function, the output measures depend on the “basis”, a parameter which controls how many days make a financial year. ",
      "name": "Measure Fractional Years",
      "id": "*AgruPQCeGoCPdL0d",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "A table with at least two Date&amp;Time columns for the start and end date of time periods. Each row should describe a period in time for which fractional years can be measured.",
          "name": "Input Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Input data table with additional two columns: the measured fractional years and the same time difference measured in months.",
          "name": "Difference Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAlElEQVR4nGNgoAUwMDAQMDIyKgDiBiguAIopEKUZpNjExKQBZAi6gcbGxvmENCfgswkkh9MQoKQByAAiXJgAdKEDNokGQpqR1E6g1ABMtYPCAKLiGqQGZ2ADo2g+EbZjBiCy6UBDJoBoUOIxNDRcgJygiHIlSAMoJYL8CTRsAbKrkA0jCkCTtQNJmpBtA6VOsjSTAgCY9TAwIZkx9AAAAABJRU5ErkJggg==",
      "description": "This Component automatically trains supervised machine learning models for both binary and multiclass classification. The component is able to automate the whole ML cycle by performing some data preparation, parameter optimization with cross validation, scoring, evaluation and selection. The component also captures the entire end-to-end process and outputs the deployment workflow using the KNIME Integrated Deployment Extension.\r\n\r\nFor solving an ML regression task, check instead the “AutoML (Regression)” component (kni.me/c/5kzQcySUa8oukv0Y).\r\n\r\nSTEP-BY-STEP GUIDE:\r\n- Drag&drop the Component from KNIME Hub to KNIME Analytics Platform.\r\n- Connect with your data table of features and target column. Consider using a subsample first.\r\n- IMPORTANT! Execute all up-stream nodes.\r\n- Double click Component to open its dialogue.\r\n- Save your settings with “OK” and execute the Component.\r\n- Wait for models to train, tune, validate, etc. and the best one to be selected and exported.\r\n- Connect the Workflow Executor/Writer node to the Component output to reuse the model.\r\n- (OPTIONAL) Right click Component : “Component” > “Open” to inspect our implementation for you to customize.\r\n- (IF PREVIOUSLY ENABLED) Right click Component : “Open Interactive View: AutoML” to inspect all trained models. Selecting one manually (with “Apply&Close” in local View bottom right corner controls) unfortunately requires training all models again.\r\n\r\nDATA PREPARATION:\r\nBefore training the models the data is cleaned by replacing the missing values with the categorical column most frequent value or the mean for the numerical columns. Optionally the categorical data can be one-hot encoded and columns with too many unique values are removed based on a user-defined parameter. Numerical features are all converted to double, normalized using Z-score normalization. The data is automatically split into the two train and test partitions using stratified sampling technique on the target class and 80% split. The data preparation models are stored for deployment both for pre-processing and post-processing the data around the model predictor.\r\n\r\nMODEL TRAINING:\r\nEach model has a number of parameters to be tuned using cross validation and the user-defined evaluation metric on train data. The extent of the parameter optimization, the optimization strategy as well as other settings of the model can be changed directly in the Component.\r\n\r\n- Naive Bayes: trained with optimized parameter “Default probability”.\r\n- Logistic Regression: trained with optimized parameter “Step size”.\r\n- Neural Network: an Rprop Multi-layer Perceptron (MLP) trained with optimized parameters “Number of hidden layers” and “Number of hidden neurons per layer”.\r\n- Gradient Boosted Trees: trained with optimized parameter “Number of trees”.\r\n- Decision Tree: trained with optimized parameter “Min number records per node”.\r\n- Random Forest: trained with optimized parameters “Tree Depth”, “Number of models” and “Minimum child node size”.\r\n- XGBoost Trees: trained with optimized parameters “eta” and “max depth”.\r\n- Generalized Linear Model (H2O): trained with the KNIME H2O Machine Learning Integration with optimized parameters “lambda” and “alpha”.\r\n- Deep Learning (Keras): trained with KNIME Deep Learning - Keras Integration with no parameter optimization and two simple architectures for binary and multiclass classification determined by a few simple heuristics\r\n- H2O AutoML: trained with the KNIME H2O Machine Learning Integration and uses the H2O AutoML to train a group of models and select the best one\r\n\r\nMODEL SCORING AND SELECTION:\r\nAfter the training of the specified models is completed and all models are stored in a single table, the system applies the model to the test set. The predictions of all models are scored against the ground truth and several performance metrics are computed. The best model is selected using the performance metric specified by the user.\r\n\r\nDEPLOYMENT WORKFLOW:\r\nThe data pre-processing, the best model and the data post-processing are captured via the KNIME Integrated Deployment Extension. The end-to-end encapsulated workflow is provided at the output of the Component and it can be used to score raw new data in deployment. Connect to the Workflow Writer node or Workflow Executor node to reuse the trained model wherever needed.\r\n\r\nAUTOML OUTPUT METADATA:\r\nThe Component additionally outputs flow variables for advanced users.\r\n- \"metric_auto\" (String) : the name of the user-defined performance metric.\r\n- \"target_column\" (String) : the name of the user-defined target column.\r\n- \"positive\" (String) : the positive class used in binary classification.\r\n- \"exported_model\" (String) : the best model that was selected.\r\n- \"exported_model_params” (String Array) : list of the optimized parameters names and values for the exported model.\r\n- \"trained_models\" (String Array) : list of all the selected models that were successfully trained and ranked by \"metric_auto\" metric.\r\n- \"trained_metrics\" (Double Array) : list of the \"metric_auto\" metrics for all “trained_models”.\r\n- \"failed_models\" (String Array) : list of all selected models failed during training or testing.\r\n- \"static_prediction_models\" (String Array) : models always predicting the majority class are discarded and listed here.",
      "name": "AutoML",
      "id": "*PvbninqeDcEWBFYe",
      "type": "Learner",
      "inPorts": [
        {
          "description": "A KNIME Table with data rows with input features and ground truth.",
          "name": "Data to Train and Test Models",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "The best trained model stored in a Workflow Object port of KNIME Integrated Deployment Extension. Connect this output port to either the Workflow Writer or Workflow Executor node.",
          "name": "Trained Model",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Workflow Port Object"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAuklEQVR4nKVT2w3DMAjMCB7BIyA//j1CRvAI3aDeoNmgHTWQYAlFAbvtSZYicxxnIMtiAACcFR8CBUpKqfwjADlnmCU7rNZGvBBCQ67XRHw/KPYiMp9nL6ImSxFMeFzvYozvqadQxbt7aibG6s8Caowttz4u/N5GAuzmvpmaAy5UDfMnaO696yLZTTeRXVRMWKWr4fgE8dh/qggnfO+LuWzXJUGBD7lgN5vg+W/cEIo1WhW8fYcD67feARH/PpXMRyZ9AAAAAElFTkSuQmCC",
      "description": "This component can be used as a generic file upload for the KNIME WebPortal or locally in the KNIME Analytics Platform. The user can upload a file of different formats (.csv, .tsv, .xls, .xlsx and KNIME-native .table) and the component selects the correct node to read the data in. \n\nIf this component is executed locally in the KNIME Analytics Platform, the file can be selected via the configuration dialog of the component.\n\nThis component does not cover all edge-cases for complicated file formats.",
      "name": "Generic File Upload",
      "id": "*-WDg7MotOfG7707g",
      "type": "Learner",
      "inPorts": [],
      "outPorts": [
        {
          "description": "uploaded data from file",
          "name": "uploaded data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAuklEQVR4nKVT2w3DMAjMCB7BIyA//j1CRvAI3aDeoNmgHTWQYAlFAbvtSZYicxxnIMtiAACcFR8CBUpKqfwjADlnmCU7rNZGvBBCQ67XRHw/KPYiMp9nL6ImSxFMeFzvYozvqadQxbt7aibG6s8Caowttz4u/N5GAuzmvpmaAy5UDfMnaO696yLZTTeRXVRMWKWr4fgE8dh/qggnfO+LuWzXJUGBD7lgN5vg+W/cEIo1WhW8fYcD67feARH/PpXMRyZ9AAAAAElFTkSuQmCC",
      "description": "This Component creates an interactive view to filter and select columns for your model based on the relevance of the columns to the ground truth specified. It also captures the user specified columns by means of integrated deployment.\r\n\r\nSET COLUMN RELEVANCE FILTER\r\nColumn Relevance is an overall metric summarizing the metrics belows. Use the slider to select the input features based on their Overall Column Relevance.\r\nThe additional metrics calculated automatically and used to determine Overall Column Relevance include:\r\n\r\n- ID/Noise Test: measures how likely the column is a representation used to identify each row in your table. Row identifiers are uninformative for your model and should be removed.\r\n\r\n- Constant Value: Test measures how often the column contains the exact same value. Columns with just a constant value also carry no information. You should avoid using them.\r\n\r\n- Missing Value Test: measures the percentage of missing values in a column over the entire dataset. You should remove features with a percentage of missing values too high.\r\n\r\nBy using the slider, columns can be excluded from model training based on their column relevance. Furthermore you can use the linear correlation between each column and the column to predict to refine your input set.\r\n\r\n- Correlation with Target: measures the linear correlation with the column the model will predict: Income. It is important to keep in mind if a feature is highly or poorly correlated. If you have high correlation (close to + or - 100%) this will help the model to achieve a good performance, unless the column has too many unique values (e.g. an high ID/Noise Test). If instead you have low correlation (close to 0%), you might exclude the feature in exchange for a faster training of the model. Be aware that very highly correlated columns can also be the result of the target column.\r\n\r\nMANUALLY SELECT COLUMNS\r\nYou can use the Column Relevance Filter - but you don't have to. Alternatively, you can remove individual columns manually in the Data Explorer table in the lower part of this page. This table allows you to explore both numeric and nominal columns. Clicking on a column name will provide additional information about the data in that column, for example statistics and histogram showing their distribution. Remember that the final set of columns to be excluded will be the unique set produced by both the Column Relevance Filter and the Manually Select Columns.",
      "name": "Interactive Column Filter",
      "id": "*im10pNJ1ivkb9UFX",
      "type": "Learner",
      "inPorts": [
        {
          "description": "Data with input feature columns and ground truth for your model.",
          "name": "Input Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Data interactively filtered by the user.",
          "name": "Filtered Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Workflow captured with integrated deployment to automatically re-exclude those same columns in other workflows or branches of this same workflow.",
          "name": "Capture Workflow",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Workflow Port Object"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoDYwMDBwMDIyaoBhID+AaM1ADQUmJiYOQE0CMDEQ39jYeD1QTIGgZlyKQAYaGhouwOdsA6ABCfgsABkOsgSX7Q14nUdI3cAbAAppEManGW8YQE2fgBx92GzHG5UgSWzxDTIUpBkUjfgsQLYpATklQtOHACwtEGUIHlcOIkMIxRrRAABplTOgJ4UUigAAAABJRU5ErkJggg==",
      "description": "This component generates an interactive visualization to help the user understand their model’s behavior on a single example data point. It works in two main steps.\n\n\nCOUNTERFACTUALS\n1) The component synthetically oversamples the example dataset (data input 1) by shuffling features and deploying the SMOTE algorithm after that. This expanded dataset is then searched for nearby data points that when scored by the input model output the classification selected in the component configuration dialog. We call these data points that generate the desired classification Counterfactuals. \n\n*Nearby data points in this instance means as little numeric variation as possible. For example we might call <1,1> and <1,1.1> close but <1,1> and <17,23> distant.\n\n\nFEATURE IMPORTANCE FROM GLM\n2) Next we define a neighborhood around the original data point. This might mean, for example, all data points with less than 0.5 numeric variation from the original point. Specifically we use the Manhattan Distance on the normalized data points. We use the smallest neighborhood we can that includes examples of the desired class from the configuration dialog. On this set of data points we train a Surrogate GLM to mimic the input model. From this model we extract and normalize the coefficients and display these in a bar chart as a local feature importance measure.  \n\n* The Manhattan Distance between two vectors is the sum of the differences between each element. For example the Manhattan Distance between <1,2> and <1.5,1> is:\n|1.5-1| + |1-2|  =  0.5 + 1  =  1.5\n\n\nHOW TO USE\n1) Drag and drop the component into your workflow\n2) To the first input port connect a model captured by the integrated deployment framework, such as a model from the AutoML component\n3) To the second input port connect a sample set of data points. These will be used to generate artificial data points to be used as counterfactual candidates. \n4) To the third input port connect a table containing one row, the data point around which you want to generate model explanations and generate counterfactuals for.\n5) In the configuration dialog select the target column and the class desired in the counterfactuals, this must be different from the value in the data point from input 3.\n6) Feel free to tune the other configuration parameters. Higher oversampling and permutation rates will reduce sparsity in the data but increase processing time. If these settings are raised or if you are using a large sample set in input 2 it is recommended to increase the expansion rate parameter.\n",
      "name": "Local Explanation View",
      "id": "*4TMCHRecejauJgqd",
      "type": "Learner",
      "inPorts": [
        {
          "description": "Workflow port from model captured with integrated deployment functionality. Such as from AutoML component.",
          "name": "Integrated Deployment Port",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Workflow Port Object"
        },
        {
          "description": "Extra labeled samples. Must include some examples of the desired class.",
          "name": "Sample Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Individual data point that will be explained and act as the center point of the neighborhood.",
          "name": "Record to Explain",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Counterfactuals and distance to original sample point.",
          "name": "Counterfactuals",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Normalized coefficants from local regression surrogate model. ",
          "name": "Local Feature Importance",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAf0lEQVR4nGNgGJTAwMBAgCIDjI2N5xsaGsqTbYCRkdEEIC4gSzPQ+Q4mJiYOIFeQa3sDiAYZAsLIckD+eaINAAUkjA1zGdBV6/GGDcz56IbB2FBDMcMGpAmkAFkDujdgciADQGx07+H1ErrLSAJQl00gSzMIUBSlMEBx0qYpAAAehidos81u4QAAAABJRU5ErkJggg==",
      "description": "This component is intended to replace the MarvinSketch node, which is no longer openly available from the December 2020 release on. It is based on the Molecule Widget node, which uses the Ketcher web-based chemical structure editor.\r\nhttps://lifescience.opensource.epam.com/ketcher/\r\n\r\nTwo different output formats can be specified in the configuration window. Input SMILES are optional and can be given either in the configuration window or as flow variable. In case you provide the input SMILES as flow variable, please set it in the flow variables tab of the configuration window. \r\n\r\nIn case you draw a reaction in the sketcher, the output will only be one column (SDF, RXN or MOL). ",
      "name": "Molecular Sketcher",
      "id": "*do6qQ7e3Z6kwMPdL",
      "type": "Other",
      "inPorts": [],
      "outPorts": [
        {
          "description": "Molecule data in the format configured by the user",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAL9JREFUOI3NksENwjAMRe3f3mEDRsC1MkBGgBHYpBswAxswQgaoREZgBLi3SS8NClUrSg+Id3Til28rRH+JiGyX3sVUsSiKc1VVu9WCGOOTmY+rBCJiAVyZeb9KAMA2TeOY+WKMsfmZMeb2UZBo29aHEF4CEbExxvt4N2+CIb4jIvLeP8bJuq47jXeDIZpV1TrFz5pcPkaSqmqd6jw3QkJV6xCCK8uScvnkCHMAOEw1LxIAcMy8WfLQLN987d/TA7LzPNQeMwIBAAAAAElFTkSuQmCC",
      "description": "This component converts the coordinates between different assembly versions of the human genome. This is done using an endpoint from Ensembl's REST API  (http://rest.ensembl.org/documentation/info/assembly_map).",
      "name": "Convert Human Genome Assembly",
      "id": "*knTqQKRVo6yL03tG",
      "type": "Other",
      "inPorts": [
        {
          "description": "Input table with the coordinates to be mapped from one assembly to another.",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Output table with the mapped coordinates.",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAyklEQVR4nLVS2w3CMAzsCN2AjJCnlE9GYISMwAawCd2kIzBCR8gI4JNcKVAnaZGwZKVVfI+6Nwz/KGttcs7NdC5ofk5doNZaee+fANB5jjEqNL1fqCfqBTM18IgBAt5rArhjklGyfaPLR88lnNDsVoSZdY8AMzSbJfu5gpHE8sdnYDFwsJcAf8YYc2qzVordviRbs7icrXoSlx1C0OxClWpf6qqZBWZH+tI6DOLCejMnpQrSiAjnMjgr2a5ClEHQVWw5IfD1J/CRegMH4FAYUtBTpwAAAABJRU5ErkJggg==",
      "description": "DISCLAIMER: This legacy component only works with random forest \r\n and precise parameters names and ranges.  If you want to train a different classification model, you can still use this component as a starting point to create your own component. Despite this we recommend to adopt the more flexible \"Parameter Optimization (Table)\" component (kni.me/c/A_91QC387NtvJ6g8).\r\n\r\n---\r\n\r\nThis component optimizes the parameters of a random forest classification model that is applied to the input data. In the dialog, you can select the target column and the optimization strategy. Output will be a table with one row that contains the values of the optimized parameters. The overall accuracy is used as objective value and will also be in the output row.\r\n\r\nBy default, the component optimizes the \"number of models\" and \"maximum tree depth\" parameters of a Random Forest model. You can change the model and the parameters to optimize. Instructions are given inside the component.\r\n\r\nTo train a model on the complete dataset, use a Random Forest Learner node, or the Learner node of any other model for which you optimized the parameters, and configure it using the best parameters. This model can then be deployed.",
      "name": "Parameter Optimization",
      "id": "*3zr62Ri4x-5-8aMz",
      "type": "Learner",
      "inPorts": [
        {
          "description": "A table that contains at least one nominal column that can be used as target and one or several additional feature columns.",
          "name": "Input Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "A table that contains one row with the best parameters found during the optimization process and the corresponding accuracy.",
          "name": "Best Parameters",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgoBYwMTFxMDIymgDEDdiwsbHxfAMDAwGcBgAVJRgaGsrjkZ8AlF+A0xBCBgBd2A/UbAB0yXqshsAMgHoFxfkgeaAmkHgCEBeAaJwGGEBAAhJGsQ3IVyBkgICFhYUCDJNsAC4vkG0ASANJBmBIoIFRA/AYAEyiAbgyEhqeAIopQhYRDQAHAltSvpTuDAAAAABJRU5ErkJggg==",
      "description": "This component allows you to query the News API (newsapi.org) in order to return the current top headlines for a particular country.\r\n\r\nThe component can be used for finding articles related to a specific topic, company, or combination of search terms. The results can be used for text analysis models, business applications, and web scraping projects.\r\n\r\nPlease notice that a valid API Key for the News API is required.\r\n\r\nAlso notice that this component works best together with the other News API components available on the KNIME Hub (hub.knime.com/knime/spaces/Examples/latest/00_Components/Text%20Processing).\r\n\r\nSee newsapi.org/docs for additional documentation for the News API.",
      "name": "News API Headlines",
      "id": "*MHjAleOCwp4jv9Rz",
      "type": "Source",
      "inPorts": [],
      "outPorts": [
        {
          "description": "Current headlines from the News API.",
          "name": "Headlines",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "description": "",
      "name": "First level component",
      "id": "*dvkc9lChVQo0_T9d",
      "type": "Other",
      "inPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,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",
      "description": "Reads the contents of a P2 Update Site.",
      "name": "Update Site Reader",
      "id": "*JZQ2HQuqIz4r2T91",
      "type": "Source",
      "inPorts": [],
      "outPorts": [
        {
          "description": "Update Site Contents",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "name": "A Beautiful Component (WIP)",
      "id": "*mpsGQjumSmR4_J9i",
      "type": "Other",
      "inPorts": [],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAlElEQVR4nGNgoAUwMDAQMDIyKgDiBiguAIopEKUZpNjExKQBZAi6gcbGxvmENCfgswkkh9MQoKQByAAiXJgAdKEDNokGQpqR1E6g1ABMtYPCAKLiGqQGZ2ADo2g+EbZjBiCy6UBDJoBoUOIxNDRcgJygiHIlSAMoJYL8CTRsAbKrkA0jCkCTtQNJmpBtA6VOsjSTAgCY9TAwIZkx9AAAAABJRU5ErkJggg==",
      "description": "This Component automatically trains supervised machine learning models for both binary and multiclass classification. The component is able to automate the whole ML cycle by performing some data preparation, parameter optimization with cross validation, scoring, evaluation and selection. The component also captures the entire end-to-end process and outputs the deployment workflow using the KNIME Integrated Deployment Extension.\r\n\r\nFor solving an ML regression task, check instead the “AutoML (Regression)” component (kni.me/c/5kzQcySUa8oukv0Y).\r\n\r\nSTEP-BY-STEP GUIDE:\r\n- Drag&drop the Component from KNIME Hub to KNIME Analytics Platform.\r\n- Connect with your data table of features and target column. Consider using a subsample first.\r\n- IMPORTANT! Execute all up-stream nodes.\r\n- Double click Component to open its dialogue.\r\n- Save your settings with “OK” and execute the Component.\r\n- Wait for models to train, tune, validate, etc. and the best one to be selected and exported.\r\n- Connect the Workflow Executor/Writer node to the Component output to reuse the model.\r\n- (OPTIONAL) Right click Component : “Component” > “Open” to inspect our implementation for you to customize.\r\n- (IF PREVIOUSLY ENABLED) Right click Component : “Open Interactive View: AutoML” to inspect all trained models. Selecting one manually (with “Apply&Close” in local View bottom right corner controls) unfortunately requires training all models again.\r\n\r\nDATA PREPARATION:\r\nBefore training the models the data is cleaned by replacing the missing values with the categorical column most frequent value or the mean for the numerical columns. Optionally the categorical data can be one-hot encoded and columns with too many unique values are removed based on a user-defined parameter. Numerical features are all converted to double, normalized using Z-score normalization. The data is automatically split into the two train and test partitions using stratified sampling technique on the target class and 80% split. The data preparation models are stored for deployment both for pre-processing and post-processing the data around the model predictor.\r\n\r\nMODEL TRAINING:\r\nEach model has a number of parameters to be tuned using cross validation and the user-defined evaluation metric on train data. The extent of the parameter optimization, the optimization strategy as well as other settings of the model can be changed directly in the Component.\r\n\r\n- Naive Bayes: trained with optimized parameter “Default probability”.\r\n- Logistic Regression: trained with optimized parameter “Step size”.\r\n- Neural Network: an Rprop Multi-layer Perceptron (MLP) trained with optimized parameters “Number of hidden layers” and “Number of hidden neurons per layer”.\r\n- Gradient Boosted Trees: trained with optimized parameter “Number of trees”.\r\n- Decision Tree: trained with optimized parameter “Min number records per node”.\r\n- Random Forest: trained with optimized parameters “Tree Depth”, “Number of models” and “Minimum child node size”.\r\n- XGBoost Trees: trained with optimized parameters “eta” and “max depth”.\r\n- Generalized Linear Model (H2O): trained with the KNIME H2O Machine Learning Integration with optimized parameters “lambda” and “alpha”.\r\n- Deep Learning (Keras): trained with KNIME Deep Learning - Keras Integration with no parameter optimization and two simple architectures for binary and multiclass classification determined by a few simple heuristics\r\n- H2O AutoML: trained with the KNIME H2O Machine Learning Integration and uses the H2O AutoML to train a group of models and select the best one\r\n\r\nMODEL SCORING AND SELECTION:\r\nAfter the training of the specified models is completed and all models are stored in a single table, the system applies the model to the test set. The predictions of all models are scored against the ground truth and several performance metrics are computed. The best model is selected using the performance metric specified by the user.\r\n\r\nDEPLOYMENT WORKFLOW:\r\nThe data pre-processing, the best model and the data post-processing are captured via the KNIME Integrated Deployment Extension. The end-to-end encapsulated workflow is provided at the output of the Component and it can be used to score raw new data in deployment. Connect to the Workflow Writer node or Workflow Executor node to reuse the trained model wherever needed.\r\n\r\nAUTOML OUTPUT METADATA:\r\nThe Component additionally outputs flow variables for advanced users.\r\n- \"metric_auto\" (String) : the name of the user-defined performance metric.\r\n- \"target_column\" (String) : the name of the user-defined target column.\r\n- \"positive\" (String) : the positive class used in binary classification.\r\n- \"exported_model\" (String) : the best model that was selected.\r\n- \"exported_model_params” (String Array) : list of the optimized parameters names and values for the exported model.\r\n- \"trained_models\" (String Array) : list of all the selected models that were successfully trained and ranked by \"metric_auto\" metric.\r\n- \"trained_metrics\" (Double Array) : list of the \"metric_auto\" metrics for all “trained_models”.\r\n- \"failed_models\" (String Array) : list of all selected models failed during training or testing.\r\n- \"static_prediction_models\" (String Array) : models always predicting the majority class are discarded and listed here.",
      "name": "AutoML",
      "id": "*4v4w8gjmGn39nZWZ",
      "type": "Learner",
      "inPorts": [
        {
          "description": "A KNIME Table with data rows with input features and ground truth.",
          "name": "Data to Train and Test Models",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "The best trained model stored in a Workflow Object port of KNIME Integrated Deployment Extension. Connect this output port to either the Workflow Writer or Workflow Executor node.",
          "name": "Trained Model",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Workflow Port Object"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAABHNCSVQICAgIfAhkiAAAAOZJREFUOI3lkMFtwkAQRf9+++CjO4ASViMXQAmUkHQQOqAEOoASSAVx7pa9JUAHPlrWeocLrJzgxEQcM6fVn9n3/wzwZJnboyiKVQhhDaCdHDRmMQzDxjn3pR8BIvKiqh9N05ynACKyU9VcVd/GED4alaSq6i5Jkr21Nr/p6ffB6yqrsVbX9dZ7/07SquonyTWAwyTAe98COI2kIwA450oAsNYuSUaDOwCAU5Zlcceu635d7Q6Qpqnt+z46kASA7U+A2SOGEA5/SlBVVQmgnAM/nOAfAOIRjTEtgFcRmfuTkzw+axzrAh/eURiwzXlhAAAAAElFTkSuQmCC",
      "description": "The Document Similarity Learner develops a model for identifying a new documents most similar matches from an existing corpus of documents. It consumes already processed documents (refer to Document Preprocessing Component) as input and provides as output both the corpus of documents and a model for use with the Document Similarity Predictor Component.",
      "name": "comp12",
      "id": "*33FMGK8Mml49uplR",
      "type": "Source",
      "inPorts": [
        {
          "description": "Documents which have already been preprocessed (via Document Preprocessing).",
          "name": "Preprocessed Documents",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "The reference corpus of documents for future comparison with new documents.",
          "name": "Corpus of Documents",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "Model for creating document vectors on new documents in the appropriate, compatible format.",
          "name": "Document Vector Model",
          "optional": false,
          "color": "#9b9b9b",
          "portTypeName": "DocumentVectorPortObject"
        }
      ]
    },
    {
      "description": "",
      "name": "Copy workflow",
      "id": "*YYF6314BkFJPWspK",
      "type": "Other",
      "inPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAYAAABzenr0AAAABGdBTUEAAK/INwWK6QAAABl0RVh0U29mdHdhcmUAQWRvYmUgSW1hZ2VSZWFkeXHJZTwAAALvSURBVHjaYvz//z8DIbBuwybG169fSzGQAERFRZ8FBfgRNJyRkAMKi4ofrV+7RpaBDKCppcWwfft2RnxqWAgZcuTQQbDlgcEhj0mxHKTv+rVrDDNnz5VOT01+SrYDTp85w0iO74kNORZccX740MGHb16/JinobezsZfD5ligHtLZ11M2eOb2RHF8DHf0ESJHkCKwhYGtnz6ChqVUPTETNxBoEjO9akMNvXL92HMiVI9sB1VUVTUCqiVTfr2NgADm2kdRoY4EF+4Z1axqBeZ2BxLzOEBAUUg91NFkA7ADkOAflXRKCneHI4YNAvRQ4AJRPkQWAcf+4v6+XqDj09PT8D3IEJYAJOeGBghSUd0F5GGuxyciIjJXu3bvH8OnTJxDbBV0dCPz584ehoqw0C8gvB2JjNP2oDhARFX1cWVPHRMgRUGAMxGdu3brF8P7DBxB/FTZFILkPH95XAZkdIPVAnIYzBEAAVHkQ6QiQgYJkhDiGPiZ0FUQ6Ah7kXFxcICodm238fHwMvLy800CBARUShIYebgeQGBIMoiIiIGo1ujhIHxsbG8Pnz5+zgdyzJFdG0Lqcqb2l6R+0UnlESgkHKyNqqitJL4pxOaKgsOjRhP4+ohxx5uxZRiAmPhvicwRydIAcgasuoKgcIMYRfMBEtXD+PKxlPbASaoRVyQSMS0NOiEzEuhTkiMtXrryH5nswADkIuS0AdKRMRloKtqoYOS5CoWWCMVEtIjSAkod//foFZ+OwGF4m4TKLBdR6hbXhCJR+DB4enm8fPnrIDoxvHhD/x48fxDrcBS00QNl2D7xVHBsb9x/YmiE6GB4+QrgTmCgfE5EzdiM5whVmOchueLOclLY/MLifINc9RGjB6QAwQSxGAv+RMAORDoCph0cHyEwmhgEG1HAAKF8r4ck1oXjkyY6Cu2jRcBeH8TPR1P1HdgwlaSAUi8GE4v4/tD2A4nkWMoMdlI/DoA4RhKVqLKATib0HjU9c75jWACDAAL9Fu8WXgXTPAAAAAElFTkSuQmCC",
      "description": "Extracts metadata for all installed nodes in JSON format.",
      "name": "Installed Nodes Extractor",
      "id": "*tnsFYATrhqeTPomV",
      "type": "Source",
      "inPorts": [],
      "outPorts": [
        {
          "description": "Table containing each installed node&#39;s metadata as a JSON document.",
          "name": "Node Metadata",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "description": "This is something nice\n",
      "name": "This is a nice component",
      "id": "*3_O71FPVp0HoBdav",
      "type": "Other",
      "inPorts": [
        {
          "description": "No description available",
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "No description available",
          "name": "Port 2",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    },
    {
      "description": "",
      "name": "Component",
      "id": "*5i_QxvM9YAdowKnC",
      "type": "Other",
      "inPorts": [],
      "outPorts": []
    },
    {
      "name": "Shared Component",
      "id": "*TetsXr7OBcIx3Oq2",
      "type": "Other",
      "inPorts": [],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAi0lEQVR4nGNgGAwgFojfAvF/EjFITzQDmZph+A0DFsFTQHyaBENQOHORvDYPSbwKzduquAxIRlKUTI4LzgOxIhArQdkw8etAvAoJ78ZmwF8g3oOkaC9UDCS3EIhDkXAmNgNiGDBBHCle4MBiAAcpLtiN5s9VUC9hC4M9yAZQnJCioQxyNEdh8TadAQDVxJhWF43WoQAAAABJRU5ErkJggg==",
      "description": "Extracts the current authorization header from a KNIME Hub connection.",
      "name": "Hub Authorization Header Extractor",
      "id": "*GdjG15JHYRZFWQcO",
      "type": "Other",
      "inPorts": [
        {
          "description": "Hub connection",
          "name": "Hub Connection",
          "optional": false,
          "color": "#4386f7",
          "portTypeName": "KNIME Hub Credentials"
        }
      ],
      "outPorts": [
        {
          "description": "Flow variables",
          "name": "Flow Variables",
          "optional": false,
          "color": "#ff4b4b",
          "portTypeName": "Flow Variable"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAYAAACtWK6eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEwAACxMBAJqcGAAAEm1JREFUeJztnXu8HVV1x7/3JuTeBAghIeRlCERAeSiPkIA2auUVJQS1in40Flqq1aqgPAy2QvuxhWoFpVIVBBQpaZUqIkRUlJqUolJNwkPkFQgEQxIIAZKQx829N6d/rHM85x5mnzMzZ2b2zOT3/XzWBz6Te/as2XvWzJ61114LhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQuy6DPOtQERGA68D9ge6gU1etRFh6MLG61BgX2AL0OdToTLyNmAxsBOoNMjTwNeAOUCPN+1EM73A24GrgNUMHbNB4E7gRG/alYge4HqGdrBLNgPfB84A9vGh7C7OeOBM4GbgZcKN2bXACB/KloFu4IeE6+hmGQTuAi4ADs5a8V2ELuC1wALgbl75dg8r38PGWkTkk8Tr8CB5BLgMeBMwPMuLKBnDgTcDlwOPkdz4/E2WF1EGeoH1JDcAjfI8cAPwbmDPrC6owIwGTgduBDaQzpisQ1OtSJyGuzOfAx5s8e9RpA/4CfAxYGomV1YM9gM+DtwB7CCZvn4Aezi5/n1OJlcWkbxON45xHL8HOAHYCkwCTsWM6UTsrROVEZiH7G2YN+xe4Laq3IsNXCf0AAcB0zFX5zRgIjABcySMrsoobCx2q55zoCpbMVf2JuzmehZ72q4CngJWAivo3G3aDRwNzMP688gO2wPYBvwcWAT8CNN7d2AJweN7DGaQIgRfJfgp8ynH34/CBvY67CZK4om3Gvg65q4MY3zjgFOAi4BbsBt3MCFdWskg9j3wA+CzmLGPDaFvb1Xfq4FnEtJlLeaZmoeNSRALHL+9IoTOospXiGYgjXQDxwGXAr9ztBNVXsbcl2dSdyHvjc3NrwZ+n9B5kpQHsXWIdwNjqjqPB/4CM6YtCZ3nfuASYBbhvFGfdrRzeYjfiiqXE9yJC2K0dQBwDrY41e9oN+oT+2GyeTskJQNVneO6YhulH5s6nY1NG6PyWUe7n4/RVurk9Ruk33F8txhtPQlcWZUx2BRkHja9GNPidy66Mf9/kRhGZzq/CPwY+za7A9jYQVuuMXSNuVd2BQNp5CXgu1XZDZiNGcs7sA9pUedx6g6LX2JvoSSQgSRAWgbSfI7FVTkfOAT70J8HvAFbKU6CtdhH9ErsbfYM5tF5DjPYTdj3QD/1m7Dm0doD83KNwQL9JgJTsGnjdCxKYGJCelaAX1E3ikerx5JGBpIAWRhIIxXgoap8AbsZ52IGczJuj0wzT2Cu6KXAMuzj/YUY+uyoyhbMK9eKccBhwAxgJuagOCDkebZgU6bbsCnU+hi6RqVQBpJXzif4Q86HK7CVO3Qt8C3g/diTPS+8CpiPBXo2u72juq+TxuXCP8eDLoXlHII78as+lcKmXTOAD2ALa0UIsutmqM5JTR3j8g2CxzaX8ViaYkWjgk2dlnnWIwo7yZfOhZpi5fUJmFcDEZ0jA0mAHY7jMpDi4xpD15h7Ja8GojdIedEbJAFkIOVFBpIAMpDyIgNJABlIeZGBJIAMpLzIQBJABlJeZCAJ4OosbewvPq4xlIFEQG+Q8qI3SALIQMqLDCQBZCDlRQaSADKQ8iIDSQAZSHmRgSSADKS8yEASQAZSXmQgCSADKS8ykATQfpDyov0gCaA3SHnRGyQBZCDlZBjBSSNqKV1zR14NpJb3tpkuileZV9Qp1NsD8msgXfhPTyOSR2OaEGMJzp201adSomO6sPSqQWO7h0e9nOT1DXKo4/gzmWohkqYCrHH82yFZKhKWvBqIq8j8w5lqIdLgIcdx15h7JY8GMgyr5BTEL7NURKTCrx3HzyKf92PueCfu6kaHedRLJMPRuMf3FI96FYafEtx5S30qJRKjC6trGDTGt3rUqxC8CncdPde0SxSPD+GupbivR71yj6sC6gb81LIQ6TAKq3MYNNaf8KhX7vkNwZ12pU+lRCpcTfBY/49PpfLMZNwfbzM96iXSYTbBYz2IlZXLBXkqoDPHcXwVfj/QR2El1k7GvpG2AsuBG4EHPeoVhdcDHwSOAkYCf8BqE34X2O5Jp19hJewmNR3vxvr6O5lrlHMWEvxE+ZpHnY7Havq53mxXAT3etGtPL3Atbv1XAW/yph1c49DrWo865ZZVBHfWaZ70OQnbxOO6uWryI/IZYTwMt8u8UbYDb/Gk43scOj3iSZ/cMoHgjtoJ7O1Bn714ZXXYVpLHCq0XEF7/Z4DdPeg4voVOYzzok1veTnAnueJ20uY8hz4uWUO+3iLDiWbgPt2rjzv0+VNP+gwhL7EvrhCS+zLVos7ciH8/CTgyDUVicgzRF9x8hXksdxw/PFMtHOTFQA50HP99plrUmRbjN/snrUQHFEl/1xgfnKkWDuK6efcFTq3+/32YuzNuVoph2BQriCdittkpfRn9Ji2KpP8Kx/G5wKew79A49GBvoSOrbSwCno/ZViSOBV5i6HxxB1ao/hrgI9jCXtjQkDm458WujVNp850WOrlkPy+aBjOd6Pp/24eiwBEtdDohZBu9wCzgo5iLeDmv9EC+gE09U2cZ4Tq8H7gXuA74GGZYIwPa+w/H7/8vzYtow6kOnVxylx81W3IP0a7hJD9q0oXd0EE6XR/w9yOB44CPA9/EZjD9jt83i2svSmJ0h1TEJQPAA9iFfwJbpNrs+Nuz0r6YFnQBdzr0CrqmY/2o2ZLZuPd/N8vtnnSs8VGC9XoJu0fOxt5wDxD+moIkk2nkYx0oGFa2AntmcTEtGA/8jtZ6DuLXkNvxYeoplFyyHD9rTY2MwW7etO+rB7K4mLmEf6XFlZ3Y/vOFwLnAm/FjMHsAVwDbAnRcij2l885bCJ7CbAG+iMWaZc3oql7nYVPsRwL0S1r6sBivSMTNU3Qo8AHso2cGsE/MdqJQwd5eyxrkXmBTBufeCzOGqdiNtRxbxKxkcO6kOBwLVhwFPA38L/ByBucdjW2zndEgB5FNjqz12H2ylLohRiIJJbuwKNcZTZLFzrAK5iasdcIPgZUZnFe4ORB4B/X7IKv1jGcZ+vBchoXQdPQQS8uKu4ApvPLJMTGl89XYgQXALUr5PCKYP8NC6NPOobyWoYawHAv3SfyNnnUqyMnUjWUeZkBJswabCsVdYBLxGI71/fgU2l6KRU3XDGJtCucIJOsNU2uqsghbQQ8ykD4622MxGduRtr6DNtLiKEy/uA+mCrY/5f7ENEqOiXRuHDuAEQHHbwUu6bDtwnEjwd6Gj2CdfQpwMXAL9lEZ1luxjnxF1oJ9j91Nch6ZJeRoW2qV3bBQjrDXsAr4AXARFmo0Ads2EPS312V4HbnhvwnuDFdc1ngsLOXvgJuBJwN+OwCcnqrW8bid5N2Wt2R6BeGYT/C6y0rg+8DfYq5W15vmXQG/reBxIdNnOvr7sDicZmYSfg/6OGzacjQ2LbuF/O0TH0c6QXK1zWRZuLmjcATmxdqGueGXY3FQYZiNuZ+b+TXwxkS0KxCuFfnX+FQqBaaS3uJX2l7BrDmS4Ov09s3lcz+I69xl8z6tJp2w/Yex760y4Rp7b/epTwMZcBwvWx3CChbNnKSPfiflzEAY5MECjyXafBqIK8xhr0y1yIafAV9IsL1LgF8k2F5eGO04nkVITCA+DWSD43hZkxdfjLl6O2UJ8LkE2skjExzHXfdK6vg0EFc5tWmZapEdg1iGxk4G+zksSLRs32k1XLsyM1s5b8angbiCCsvmxWpkNXAG8b5HKsCf4/FmyQBXYONTWSqRF04n2KUXtczaSGw/8mzynQa0kS8S3aV7qRdNo9OL7QKcSfAW61YsJfja5yWpYFE4mODO2IbbmzEKWzA6G9u227wFcxWWqDnvDMeSN4c1jrvIX/hMEEdhibEbIxvuB76Fed3egHuD1kjcG/HKOu1uSTe2whrUIbOxVJh/gsXn3ICtkLfbPlrBjKYIBev3w75H2l3PemzrQN7pwtZm2l3PALaV+dvYg+6NmNEc7/j7dRRjPFPhNoI75XnCGYNL8hbI5+I0Wl/HTtyxaXljEvHHaxB3oOPNWV5EHhiDPS0uwGJ14naqS7bgnqLlEVfaowr+clXFYSSWKT7p8VyG3StvpYRrZHtjyb8WADfhTlScpFyUyZUlx324r+W3HvWKwz+S/viuwHYtfhp70BYmC/xY4ETgQuC/sPijtDurJuuwkOj5FGu+2qomfE2KMsUC6/szgB8TPbt8J/I49gBegD2QE0tjFPdm6sFS8dSymswgu+THa6jvQ27cglnJ6PxJMRUrWtouInc15sYu2vpHF0O3WNfyEzSXXEuLJ6nfH7/Fwujj5o+OxMHYIl8WT4aNWKaSi7EdhmUJ755B8IYvlzwGvM6LpskzCcut9vfY2G4im3tpBZazOHWWZHRBFcyzUZYPs2GY2/oG4qXP7MeSg88iP2UrOmUsbld/GnJHVAWjTrG6scHtdJ7/NEPTtmwHFjv+9l+Az3R4vqw5FVv97cXWc6ZgRYLaZYfcifVtu/7diNXVWIN57bZiuyl/Hl9lL3wJy67YTAXLvLgHQ9NGTe3wfH2ErzoQm1ZVX4PkSYbuR3ZlYbzJ8fvt5Ku0QDsWEP8JdyE2nYz7+zzWSnQxHXeR1IWO3zTnJXjK8XuXZJJU8KwWCjyBebAuxDxaYyO0eyj2BA1q91aK4Z0aiT3R49zc/9DQzqUx29hEMdaAujBPV9A1DGCpScMyDivd8Bnge7T+Pp6fjPrtOQmbSy+k7o9OwrXWatHszATaT5tpRL+pXwTeF9DWfGwqFbW9yalcWbJ8GLf+1yfQfuP620LsXj0+gXa9MwW3V2Mj+Z9qdTM0WK+VbAeuwr1JCMzjcw3hSwOsJP9v2unYDkHXw6IsnsrUqO3fDpK7yP8U4gTcT/5NwE+xyNYoWQgnAJ/Etu66bq4XsDDzPNOLpfBxje9f+VMtmDw+bbqxRR1XHqRrqFckyivjsFd6Lxa+vwH7oFxF57sBu4EDsLfpOCwSdiuWiO/FDttOky4stuwMx78voR7RK9pwCK0/dsuY0aPsXIB7PDcT7cNcYB+prg4dwLL3iWLwXtweygr5TBdbCL6Ou1N3YOEnIt+8k9aRA1f4U6349GDloFt5giLXnROZMRf3YmAFyz9QtkSBmTOB1vtItmNVpUS+eD+t3dOPkE6xnV2S6dRD2oNkJxbTk0ev3K5GF7aq3Wq9ZjX5X9MqHK/HCsu36vgr0SvbJyOAb9B6jDZgYUUiBWbRPhPI3VjVXZEt04B7aD0267GoXJEih1Ev7+uS5ynWVtWicxq2SNlqTJ4GXutLwV2N/bEdYq0GpAJ8BdtTINJhNK1d8Y0f5PrmyJgJWEhKu8F5CrmC02Au4QIzFyNvlTdGAP9G+0GqYCHPWSUMKDNTgP8kXJ9/mexLjYsAziRc0rKXsY1Ju/tRs9DsCfwTFhjZrp+3YmUaRI44AkuUHObJtgbbtJP30Pk80INFT68jXN8uBw73oqloSw/wz4TP67saOBd9yAexJ3A+7T2GNRnAKl/poVMAjsM8J2EGtoKtrXyOYmRRT5up2FQqSjqeh7B6IKJA9GB7kjcTfqAHsQQRcylGPY6kGI6tZSwiWlb9jViIj94aBWYStpMt7KDX5A/AZdjqfRljvLqxN+2XCD+NapRv0no/vSgYs4CfEP1GqGBbZb+M7fkucqzXCCwh278SPrlEs9yO5WQWJeVY3DmZwshm7CY5F8uXm+c0oN1YkOd52DXHzdlVwYodyTB2IWZiicbi5Mltnof/AivM+V7g1fgxmm7gQCzH1mXYCnaniaH7sVocR2d4HbmijHPrqEwB/roqSeVk6sOyTK6oyuPY2stzDbIlYpu7A/s2yGQs0cFBmGG8muSq/K7BwtavpXhlFxJFBlJnBPAuLC3NyaQfIrENW9nfjhlUX/X/wdIF9VSlF1uniVpSOSr9WPbzf8fKEvSnfD5RYPbB3iiLaZ2No+gyCNwJfIhoeZSF+COTsYTdN5FtLYu0ZAP2XfGXKM1nWzTFisYwzJMzB6vlPov8F/h5CSv1djc2hVqGvTlECGQgnVHzHB2LGctRwGtw10BJm/XAo1h57d9gKZNqGWFEDGQg6TAWq+VYk8nYqnOjRF1w3IF5v55tkDVY/cJHq//Nc27eQiID8UMX5pmqeakaBcyb1Sh91LO6CyGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBBCCCGEEEIIIYQQQgghhBAiE/4fNIVXaOmrZUcAAAAASUVORK5CYII=",
      "description": "Wibble wobble wubble flob\n",
      "name": "Test Stuff",
      "id": "*AXajI4B24JafAiSo",
      "type": "Manipulator",
      "inPorts": [
        {
          "description": "It&#39;s special",
          "name": "Special Port",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "description": "it&#39;s really special",
          "name": "Extra Special Port",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Stuff comes out",
          "name": "Out Port",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "name": "Normalize images (train)",
      "id": "*VBxBTtBai57IJzGO",
      "type": "Other",
      "inPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#ff4b4b",
          "portTypeName": "Flow Variable"
        }
      ],
      "outPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        },
        {
          "name": "Port 2",
          "optional": false,
          "color": "#1eb9dc",
          "portTypeName": "Normalizer"
        }
      ]
    },
    {
      "name": "Predictions",
      "id": "*InbyZQDnjtfYuwKa",
      "type": "Other",
      "inPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#1469af",
          "portTypeName": "PMML"
        },
        {
          "name": "Port 2",
          "optional": false,
          "color": "#1eb9dc",
          "portTypeName": "Normalizer"
        },
        {
          "name": "Port 3",
          "optional": false,
          "color": "#1469af",
          "portTypeName": "PMML"
        },
        {
          "name": "Port 4",
          "optional": false,
          "color": "#1469af",
          "portTypeName": "PMML"
        },
        {
          "name": "Port 5",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAeElEQVR4nGNgGBTAwMBAAZ1NrBh1DKAYGBsb5xsZGTXAsImJST+QLiBWngEkiOQ0AaCG+UA8gVh5uAKYJIgG2QKkHUAYKD8BXR7ZULAByJJQsQlAQxxAGGQbFnmEASDbkCXRFRCSB3EKQLagBVQBsfKUg2GQEikBAHs7UQG1hi5oAAAAAElFTkSuQmCC",
      "description": "This Component should be nested within another Component to generate a flow chart header at the top of the Composite View.\r\n\r\nSuch flow chart will help the business analyst on the KNIME WebPortal to understand the guided analytics application steps.\r\nOpen the dialogue settings to define the flow chart nodes and labels.",
      "name": "Header",
      "id": "*VXeMp8zbkD_eNeXT",
      "type": "Visualizer",
      "inPorts": [],
      "outPorts": []
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAlklEQVR4nGNgGN7AwMBAAIQJiYEFjY2N1xsaGsojixsZGRUAcQOaWAK6GFwC3QCgwQogQ7CIYRoAdEEAutOAYhNABqO7ysTEBMVQ6gBo4CiQIwZ2PhCfBzqtAYgdoArBfgU5GSSPLgZTB/MXWCOQrgcqng/iI8cKiA0Tg4UTSkCCTAZKLgBhmAIQDbWtAeZkbGKjgIEBAO1pOxyxBHgHAAAAAElFTkSuQmCC",
      "description": "This Component should be nested within another Component to generate a flow chart header at the top of the Composite View.\r\n\r\nSuch flow chart will help the business analyst on the KNIME WebPortal to understand the guided analytics application steps.\r\nOpen the dialogue settings to define the flow chart nodes and labels.",
      "name": "WebPortal Header",
      "id": "*xhACwFadXA_2XcVi",
      "type": "Visualizer",
      "inPorts": [],
      "outPorts": []
    },
    {
      "description": "This component visualizes the outlier airports and other airports on a map of US. The interactive view of the component shows statistics of the outlier airports, such as the average arrival delay.",
      "name": "MapViz",
      "id": "*QUEey4ajlBnuecdf",
      "type": "Visualizer",
      "inPorts": [
        {
          "description": "Data containing statistics of airports, their geocoordinates, and a flag true/false determining the outlier status of each airport",
          "name": "Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "description": "Map of US showing the outlier airports and other airports by separate colors and shapes. The bigger the marker, the longer is the average arrival delay time at the airport.",
          "name": "Map",
          "optional": false,
          "color": "#41be78",
          "portTypeName": "Image"
        },
        {
          "description": "Data containing the names and geocoordinates of the outlier airports and the average arrival delay in them",
          "name": "Data",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "icon": "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAo0lEQVR4nGNgGBTAyMioH4gbkLGxsfF5IA4wMDAQQJeDygcgG9AAY0M1FABxAggT64IGqGYFoMnzQTQIgwzA5gIU22EGABU6oLlEgWgXAE1cD/IzUFMCDMO8AXIBsjgSdoAbAFJkYWGhgI5B4iB5fHJwA2D+hmFkF6LLoWiGKnCAhToMwwyBBiK6nAMDVQEoWrAlFqjXCCckmrgALQxoaDulAADYHGWxRfczCAAAAABJRU5ErkJggg==",
      "description": "This Component should be nested within another Component to generate the styled body of the Composite View.\r\n",
      "name": "WebPortal Body",
      "id": "*xUK25P0ZC8KovY1y",
      "type": "Visualizer",
      "inPorts": [],
      "outPorts": []
    },
    {
      "name": "Normalize images (test)",
      "id": "*15B64vo-TGFKj8W5",
      "type": "Other",
      "inPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#1eb9dc",
          "portTypeName": "Normalizer"
        },
        {
          "name": "Port 2",
          "optional": false,
          "color": "#ff4b4b",
          "portTypeName": "Flow Variable"
        }
      ],
      "outPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ]
    },
    {
      "name": "Predictions - Optimization",
      "id": "*hjNq1W7tNipf4eqj",
      "type": "Other",
      "inPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#1469af",
          "portTypeName": "PMML"
        },
        {
          "name": "Port 2",
          "optional": false,
          "color": "#1eb9dc",
          "portTypeName": "Normalizer"
        },
        {
          "name": "Port 3",
          "optional": false,
          "color": "#1469af",
          "portTypeName": "PMML"
        },
        {
          "name": "Port 4",
          "optional": false,
          "color": "#1469af",
          "portTypeName": "PMML"
        },
        {
          "name": "Port 5",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#ff4b4b",
          "portTypeName": "Flow Variable"
        }
      ]
    },
    {
      "name": "Download dataset and convert to CSV",
      "id": "*QJ4Hj8V_jiSF_kFr",
      "type": "Other",
      "inPorts": [],
      "outPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#ff4b4b",
          "portTypeName": "Flow Variable"
        }
      ]
    },
    {
      "name": "Copy workflow",
      "id": "*g8c9zn9zDOOwXTSR",
      "type": "Other",
      "inPorts": [
        {
          "name": "Port 1",
          "optional": false,
          "color": "#000000",
          "portTypeName": "Table"
        }
      ],
      "outPorts": []
    }
  ]
}
